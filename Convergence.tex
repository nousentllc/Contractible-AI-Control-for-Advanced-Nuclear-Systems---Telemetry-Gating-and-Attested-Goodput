\documentclass[11pt, letterpaper]{article}

% =========================================================
% 0) ENGINE HYGIENE (pdfLaTeX + XeLaTeX/LuaLaTeX compatible)
% =========================================================
\usepackage{iftex}
\ifPDFTeX
  \usepackage[utf8]{inputenc}
  \usepackage[T1]{fontenc}
  \usepackage{mathpazo}
  \usepackage[scaled=0.95]{helvet}
  \usepackage{courier}
\else
  \usepackage{fontspec}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
  \setmainfont{TeX Gyre Pagella}
  \setsansfont{TeX Gyre Heros}
  \setmonofont{TeX Gyre Cursor}
\fi

\usepackage[final]{microtype}

% =========================================================
% 1) GEOMETRY & LAYOUT
% =========================================================
\usepackage[top=.7in, bottom=.75in, left=.75in, right=.75in]{geometry}
\usepackage{setspace}
\setstretch{1.15}

\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt}

% =========================================================
% 2) HEADERS/FOOTERS
% =========================================================
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small \textsf{Rubing Class AI \& SMR Constraint}}
\fancyhead[R]{\small \textsf{\today}}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0pt}

% =========================================================
% 3) MATH / THEOREMS
% =========================================================
\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{physics} % keep if you actively use it; otherwise remove for stricter control

\theoremstyle{definition}
\newtheorem{assumption}{Assumption}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\theoremstyle{remark}
\newtheorem{remark}{Remark}

% =========================================================
% 4) GRAPHICS / TABLES
% =========================================================
\usepackage{graphicx}
\usepackage{float}
\usepackage{booktabs}
\usepackage{array}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{caption}
\usepackage{subcaption}

% Lists
\usepackage{enumitem}
\setlist[itemize]{topsep=4pt,itemsep=2pt,parsep=0pt,leftmargin=*}
\setlist[enumerate]{topsep=4pt,itemsep=2pt,parsep=0pt,leftmargin=*}

% =========================================================
% 5) COLORS + SECTION FORMATTING
% =========================================================
\usepackage{xcolor}
\definecolor{darkblue}{rgb}{0.0, 0.0, 0.55}
\definecolor{crimson}{rgb}{0.6, 0.0, 0.0}

\usepackage{titlesec}
\titleformat{\section}
  {\Large\sffamily\bfseries\color{darkblue}}
  {\thesection}{1em}{}
\titleformat{\subsection}
  {\large\sffamily\bfseries\color{darkblue}}
  {\thesubsection}{1em}{}
\titleformat{\subsubsection}
  {\normalsize\sffamily\bfseries\color{darkblue}}
  {\thesubsubsection}{1em}{}

% =========================================================
% 6) FOOTNOTES + CITATIONS (natbib + references.bib)
% =========================================================
\usepackage[bottom]{footmisc}
\setlength{\footnotesep}{10pt}

\usepackage[numbers,sort&compress]{natbib}
\bibliographystyle{unsrtnat}

% =========================================================
% 7) HYPERREF + CLEVER REFERENCES (load late)
% =========================================================
\usepackage[colorlinks=true,
  linkcolor=darkblue,
  citecolor=crimson,
  urlcolor=darkblue,
  pdfauthor={Justin Candler},
  pdftitle={Rubin Class Load Profiles and SMR Constraint}
]{hyperref}


\usepackage[nameinlink,capitalise,noabbrev]{cleveref}

% Bookmark-safe macros
\pdfstringdefDisableCommands{%
  \def\ASCDE{ASCDE}%
  \def\VOLL{VOLL}%
  \def\EUE{EUE}%
  \def\Df{Df}%
  \def\ds{ds}%
}

% =========================================================
% 8) CUSTOM COMMANDS
% =========================================================
\newcommand{\Df}{D_f(k)}
\newcommand{\ds}{d_s(k)}
\newcommand{\expvalbig}[1]{\left\langle #1 \right\rangle}

% --- Source hygiene (temporary scaffolding) ---
\newcommand{\srcnote}[2]{\footnote{\textbf{Source (provisional):} #1. \textit{Accessed:} #2.}}
\newcommand{\srcredflag}[2]{\footnote{\textbf{Source (low-authority / replace):} #1. \textit{Accessed:} #2.}}

% --- Reliability & Energy Acronyms (Rubin/SMR Context) ---
\newcommand{\SMR}{SMR\xspace}      % Small Modular Reactor
\newcommand{\SMRs}{SMRs\xspace}    % Small Modular Reactors (Plural)
\newcommand{\LOLP}{LOLP\xspace}    % Loss of Load Probability


% --- Quantum/Fractal Acronyms (QFTN Context) ---
\newcommand{\QFTN}{QFTN\xspace}    % Quantum-Fractal Tensor Network
\newcommand{\OTOC}{OTOC\xspace}    % Out-of-Time-Ordered Correlator
\newcommand{\OTOCtwo}{OTOC(2)\xspace} 

% =========================================================
% CORE NOTATION MACROS (control sequences)
% =========================================================

% --- Probability / expectation (safe, minimal) ---
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}

% --- Reliability / adequacy primitives ---
\newcommand{\VOLL}{\mathrm{VOLL}}                 % value of lost load
\newcommand{\EUE}{\mathrm{EUE}}                   % expected unserved energy
\newcommand{\LOLE}{\mathrm{LOLE}}                 % loss of load expectation
\newcommand{\PRM}{\mathrm{PRM}}                   % planning reserve margin
\newcommand{\ELCC}{\mathrm{ELCC}}                 % effective load carrying capability
\newcommand{\RA}{\mathrm{RA}}                     % resource adequacy (generic)
\newcommand{\LMP}{\mathrm{LMP}}                   % locational marginal price

% Optional: operators (avoids awkward subscripts everywhere)
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}

% --- Your ASCDE family ---
\newcommand{\ASCDE}{\mathrm{ASCDE}}
\newcommand{\ComputeASCDE}{\mathrm{Compute\text{-}ASCDE}}  % if you cite it often
\newcommand{\PUE}{\mathrm{PUE}}

% --- AI power / workload decomposition ---
\newcommand{\PAI}{P_{\mathrm{AI}}}
\newcommand{\Pstiff}{P_{\mathrm{stiff}}}
\newcommand{\Pflex}{P_{\mathrm{flex}}}
\newcommand{\us}{u_s}
\newcommand{\uf}{u_f}

% --- Stiffness / switching / checkpointing ---
\newcommand{\kstiff}{\kappa_{\mathrm{stiff}}}     % preferred (kappa) notation
\newcommand{\Cswitch}{C_{\mathrm{switch}}}
\newcommand{\Crestart}{C_{\mathrm{restart}}}
\newcommand{\Cresync}{C_{\mathrm{re\text{-}sync}}}
\newcommand{\Crel}{C_{\mathrm{Rel}}}

% --- Sprinting / scheduling ---
\newcommand{\sig}{\sigma}                         % sprint factor
\newcommand{\sigmax}{\sigma_{\max}}
\newcommand{\sigpeak}{\sigma_{\mathrm{peak}}}
\newcommand{\Pbase}{P_{\mathrm{base}}}


\newcommand{\Ttrip}{T_{\mathrm{trip}}}
\newcommand{\Tscram}{T_{\mathrm{scram}}}          % keep both if you distinguish
\newcommand{\Tout}{T_{\mathrm{out}}}
\newcommand{\DTsafe}{\Delta T_{\mathrm{safe}}}
\newcommand{\Cth}{C_{\mathrm{th}}}                % effective thermal capacitance proxy

% --- Deep operator network oracle ---
\newcommand{\DO}{\mathrm{DO}}                     % generic shorthand
\newcommand{\DeepONet}{\mathrm{DeepONet}}
\newcommand{\Gop}{\mathcal{G}}                    % operator mapping histories->state
\newcommand{\That}{\widehat{T}}                   % generic predicted temperature
\newcommand{\ToutHat}{\widehat{T}_{\mathrm{out}}}

% --- Grid / electrical transient shorthand ---
\newcommand{\dIdt}{\frac{dI}{dt}}
\newcommand{\dPdt}{\frac{dP}{dt}}

% --- Convenience for scarcity externality term ---
\newcommand{\RelCost}{C_{\mathrm{Rel}}}
\newcommand{\AdeqCost}{C_{\mathrm{Adeq}}}         % if you want a separate channel

\newcommand{\pdfmath}[2]{\texorpdfstring{#1}{#2}}


% =========================================================
% TITLE METADATA (single source of truth)
% =========================================================
\title{
  \vspace{-2.0cm}
  \rule{\linewidth}{0.5mm}\\[0.4cm]
  \huge \textbf{\textsf{Contractible AI Control for Advanced Nuclear Systems}}\\[0.15cm]
  \Large \textsf{Telemetry, Gating, and Attested Goodput}\\[0.2cm]
  \rule{\linewidth}{0.5mm}
}
\author{
  \textbf{Justin Candler}\\
  \textit{Nous Enterprises LLC}\\
  \textit{Date: \today}
}
\date{} % keep empty; date is already in author block


\begin{document}
\pagenumbering{gobble}   % hides page numbers


% -----------------------
% 1. TITLE PAGE ZONE
% -----------------------
\begin{titlepage}
    
  \centering

  \vspace*{0.8cm}
  \maketitle

  \vspace{0.6cm}

  % Abstract
  \begin{minipage}{0.92\linewidth}
    \noindent{\large\sffamily\bfseries\color{darkblue}Abstract}\par
    \vspace{0.25cm}
    \noindent\rule{\linewidth}{0.2pt}\par
    \vspace{0.35cm}

    \noindent
   
    Rubin-class AI campuses introduce millisecond-scale load actuation (sprints) whose failure modes extend beyond
    IT compromise to cyber--physical hazards: protection misoperations, forced outages, and grid-visible transients.
    This report formalizes a \emph{contractible} control stack for SMR--AI co-control: (i) an \emph{observability contract}
    specifying minimum telemetry, sampling, synchronization, and anti-aliasing conditions required to make any gating
    policy auditable and replayable; (ii) a \emph{zero-trust admissibility gate} that treats compute as an actuator whose
    state changes must earn permission via cryptographic identity, segmentation, and feasibility checks; and (iii) a
    \emph{physics-informed guardian} coupling DeepONet-style operator surrogates with hybrid anomaly detection to reject
    ``authenticated but physically dangerous'' commands, including adversarial load shaping near resonance bands.
    We then price model imperfection directly into operations: DeepONet uncertainty is derated into an explicit sprint
    cap $\sigma_{\max}(t)$, while HNN false positives are constrained by an explicit budget and tri-state ``soft-landing''
    logic that preserves stiff-workload continuity.
    Finally, we propose an \emph{Attested Goodput PPA}---settling on verified productive compute output (tokens/steps)
    rather than MWh---with cryptographic attestation, replay protection, and dispute-resolution hooks that reconcile
    goodput claims against energy and performance counters.
    The result is a reviewer-proof interface between nuclear safety constraints, grid reliability obligations, and
    high-performance AI operations: telemetry and logs become compliance artifacts; gating decisions become auditable
    proofs; and model quality becomes a priced lever rather than an implicit assumption.
    

    \vspace{0.35cm}
    \noindent\rule{\linewidth}{0.2pt}\par
  \end{minipage}

  \vfill

  \begin{flushleft}
    \textbf{Technical Report:} AI-Doc-002\\
    \textbf{Status:} Draft v0.2
  \end{flushleft}
\end{titlepage}

% -----------------------
% 2. FRONT MATTER (Roman starts here)
% -----------------------
% This is the fix: Start roman numbering ONLY after the title page is finished.
\pagenumbering{roman}
\setcounter{page}{1} % optional, but typical

% TOC (standalone page)
\clearpage
\thispagestyle{empty}
\begin{center}
  {\Large\sffamily\bfseries\color{darkblue}Contents}
\end{center}
\vspace{0.2cm}
\noindent\rule{\linewidth}{0.2pt}
\tableofcontents
\noindent\rule{\linewidth}{0.2pt}

\clearpage


% -----------------------
% NOMENCLATURE (standalone page)
% -----------------------
% Prereqs (preamble):
% \usepackage{booktabs}
% \usepackage{longtable}
% \usepackage{array}
% \usepackage{amsmath,amssymb}
% (Optional) nicer ragged columns:
% \newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}

\clearpage
\thispagestyle{empty}
\begin{center}
  {\Large\sffamily\bfseries\color{darkblue}Nomenclature}
\end{center}
\vspace{0.2cm}
\noindent\rule{\linewidth}{0.2pt}

\vspace{0.35cm}
\noindent{\large\sffamily\bfseries\color{darkblue}Symbols}
\vspace{0.15cm}

\begin{longtable}{@{}p{0.22\linewidth}p{0.74\linewidth}@{}}
\toprule
\textbf{Symbol} & \textbf{Definition} \\
\midrule
\endhead

$\sigma(t)$ & Sprint factor (instantaneous compute power multiplier relative to baseline). \\
$\sigma_{\max}(t)$ & Admissible sprint cap at time $t$ after feasibility + uncertainty derating. \\
$\sigma_{\text{phys}}(t)$ & Physical sprint limit implied by plant / POI / actuation constraints (no UQ). \\
$H$ & Look-ahead horizon for feasibility prediction (e.g., seconds--minutes depending on plant state). \\
$\widehat{h}(t;H)$ & Predicted headroom metric over horizon $H$ (oracle output before derating). \\
$h_{\text{cons}}(t;H)$ & Conservative headroom after uncertainty tax: $\widehat{h}-\kappa U$. \\
$U(t;H)$ & Uncertainty bound (UQ statistic) on the predicted headroom (epistemic + calibrated residual envelope). \\
$\kappa,\kappa_\sigma$ & Safety factors mapping confidence level (e.g., $3\sigma$ conservatism) into derating. \\
$\Omega_{\text{safe}}$ & Safe operating set / feasibility region for coupled operation (thermal + electrical + policy). \\
$\Omega_0$ & Sensitive frequency band set (e.g., resonance-adjacent bands used in anti-forcing defenses). \\
$P(t),Q(t)$ & Real power and reactive power at the point of interconnection (POI) or specified aggregation point. \\
$P_{\text{AI}}(t)$ & AI campus electrical demand trajectory (aggregate). \\
$\dot{P}(t)$ or $dP/dt$ & Power ramp rate (typically enforced at POI and/or feeder aggregation). \\
$R_{\text{safe}}$ & Maximum allowable ramp rate magnitude (POI constraint). \\
$\Delta$ & Finite-difference window used for derivative / ramp estimation. \\
$f(t)$ & Electrical frequency at POI (or local microgrid bus if islanded). \\
$\dot{f}(t)$ & Rate-of-change of frequency (ROCOF). \\
$\tau_r$ & Smallest rise time of interest for transients (drives sampling requirements). \\
$f_s$ & Sampling rate (Hz) of a telemetry stream. \\
$f_c$ & Anti-aliasing filter cutoff frequency (Hz) prior to decimation. \\
$\varepsilon_t$ & Maximum relative timestamp skew between planes after synchronization (time alignment error bound). \\
$\Delta t_{\text{E2E}}$ & End-to-end latency from measurement to actuation (measurement + transport + compute + actuation). \\
$u_s(t),u_f(t)$ & Stiff / flexible tranche utilization at time $t$ (dimensionless in $[0,1]$ or MW-normalized). \\
$\mathbb{1}_{\text{scar}}(t)$ & Scarcity indicator for interval $t$ (ISO emergency flag or local margin breach). \\
$G(t)$ & Verified goodput in interval $t$ (tokens/steps or other auditable productive compute unit). \\
$E(t)$ & Electrical energy delivered in interval $t$ (MWh). \\
$A(m)$ & Availability fraction over billing month $m$. \\
$N_{\text{int}}(m)$ & Number of interruptions in billing month $m$ (per contract definition). \\
$\Phi_{\text{int}}(m)$ & Interruption penalty functional (duration- and severity-weighted). \\
$\Phi_{\text{scar}}(m)$ & Scarcity support credit functional (verified flex curtailment during scarcity). \\
$\Pi(m)$ & Monthly settlement payment under the Goodput PPA. \\
$C_{\text{switch}}(m)$ & Monthly switching/restart cost (checkpoint/restart tax; includes security-induced components). \\
$S(m)$ & Survival probability of the stiff workload over month $m$ (continuity under faults/trips). \\
$\lambda_{\text{UQ}}(t)$ & UQ-induced hazard contribution (trip risk due to model imperfection). \\
$\mathrm{EUE}$ & Expected Unserved Energy (MWh) over the relevant season/horizon. \\
$\mathrm{LOLE}$ & Loss of Load Expectation (days/year or hours/year depending on convention). \\
$\mathrm{ELCC}$ & Effective Load Carrying Capability (MW) contribution of a resource or portfolio. \\
$\mathrm{VOLL}$ & Value of Lost Load (\$/MWh), used to monetize reliability externalities. \\
\midrule
$\mathrm{OTOC}(2)$ & Second-order out-of-time-ordered correlator / echo observable (background, not core to this manuscript). \\
$\Df$ & Scale-dependent fractal dimension (QFTN background notation). \\
$\ds$ & Running spectral dimension (QFTN background notation). \\
$\expvalbig{\cdot}$ & Expectation operator. \\
\bottomrule
\end{longtable}

\vspace{0.35cm}
\noindent{\large\sffamily\bfseries\color{darkblue}Acronyms and Control/Log Tokens}
\vspace{0.15cm}

\begin{longtable}{@{}p{0.22\linewidth}p{0.74\linewidth}@{}}
\toprule
\textbf{Acronym / Token} & \textbf{Definition} \\
\midrule
\endhead

AI & Artificial Intelligence. \\
SMR & Small Modular Reactor. \\
POI & Point of Interconnection (electrical boundary to grid or microgrid bus). \\
BOP & Balance of Plant. \\
SCADA & Supervisory Control and Data Acquisition. \\
EMS & Energy Management System (campus/microgrid supervisory dispatch). \\
HNN & Hybrid Neural Network (here: cyber--physical anomaly guardian). \\
DeepONet & Deep Operator Network (operator-learning surrogate / virtual sensing oracle). \\
UQ & Uncertainty Quantification (prediction error bounds / calibrated residual envelopes). \\
TES & Thermal Energy Storage (thermal buffer / accumulator / salt tank, etc.). \\
BESS & Battery Energy Storage System. \\
RPS & Reactor Protection System (hard-deck safety system; non-ML). \\
LCS & Limiting Control System (control layer that operates below safety hard-deck). \\
PTP & Precision Time Protocol (IEEE 1588 time synchronization). \\
GNSS & Global Navigation Satellite System (time reference; GPS, etc.). \\
ROCOF & Rate of Change of Frequency ($\dot{f}$). \\
PDU & Power Distribution Unit (rack/row aggregation point). \\
PPA & Power Purchase Agreement. \\
CIP & Critical Infrastructure Protection (NERC standards family). \\
\texttt{ATTEST\_BUNDLE} & Immutable evidence record linking telemetry + oracle outputs + thresholds + GRANT/DENY decision. \\
\texttt{GRANT}/\texttt{DENY} & Admission decision outcomes for requested load steps/sprints. \\
\texttt{THERMAL\_INFEASIBLE} & Denial reason code: violates conservative thermal headroom constraints. \\
\texttt{POI\_RAMP\_UNSAFE} & Denial reason code: violates ramp-rate / electrical envelope constraints. \\
\texttt{RESONANCE\_RISK} & Denial reason code: forcing near sensitive bands $\Omega_0$ exceeds policy threshold. \\
\texttt{HNN\_ANOMALY} & Denial reason code: anomaly score exceeds threshold / tri-state guard triggers. \\
\bottomrule
\end{longtable}

\vspace{0.15cm}
\noindent\rule{\linewidth}{0.2pt}

\clearpage
% =========================================================
% MAIN DOCUMENT PAGINATION RESUMES HERE
% =========================================================

\setcounter{page}{1}

% Re-assert fancy header content (robust across titlepage + empty pages)
\pagestyle{fancy}

\clearpage
\pagenumbering{arabic}


\section{Structural Analysis of the Rubin-Class Load Profile and the SMR Constraint}

The impending collision between Rubin-generation AI accelerators and early commercial Small Modular Reactor (SMR) deployments is best treated as a \emph{coupled control problem}, not a mere co-location problem. The relevant mismatch is not just energy (MWh) but \emph{time structure}: GPU-scale switching and synchronization produce step-like transients, whereas SMR primary and secondary loops are bounded by thermal inertia, neutron kinetics, and balance-of-plant protection logic. The planning interface in the companion Compute-ASCDE-SMR work formalizes this gap by elevating time-constant mismatch and survival-weighted goodput to first-order design variables rather than second-order “ops details.”\citep{candler2026_computeascde}

At a high level, we observe three interacting constraints:

\begin{enumerate}
  \item \textbf{Temporal densification (Sprint Capacity):} scale-up fabrics and tight kernel synchronization concentrate compute into narrow windows, producing high $dL/dt$ regimes that look like \emph{impulse trains} to plant and grid controls.\citep{candler2026_computeascde}
  \item \textbf{Plant low-pass behavior:} light-water SMRs can load-follow, but within ramp and stability envelopes dictated by thermal-hydraulic and reactivity management constraints; balance-of-plant protection further tightens allowable load rejection trajectories.\citep{nrc2018_nuscale_rai182,hotcarbon2025_uncertainty}
  \item \textbf{Cyber-physical reliability coupling:} for high-stiffness training, availability and integrity are economically dominant. Zero-trust and intrusion-prevention telemetry therefore enter the valuation kernel as survival modifiers, not “IT hygiene.”\citep{talukder2023_zerotrust}
\end{enumerate}

The correct integration thesis is thus: \emph{Rubin-class compute requires an intermediate buffering and verification layer that maps millisecond-scale compute scheduling into minute-scale plant admissibility, while maintaining cryptographic and behavioral trust guarantees end-to-end.} The mechanisms exist in the combined toolchain: Compute-ASCDE supplies the valuation and scheduling objective;\citep{candler2026_computeascde} DeepONet-style virtual sensing supplies a state oracle for thermal margin; and INL’s zero-trust stack supplies the governance boundary conditions.\citep{talukder2023_zerotrust}

\subsection{The Physics of Sprint Capacity vs.\ Thermal Inertia}

\paragraph{The Rubin phase change.}
Rubin-class systems are not merely “more FLOPs.” They change the \emph{spectral content} of facility load. Large-scale synchronous kernel launches, collective communications, and tight iteration loops create fast transitions between compute-saturated and communication-limited states, so that power demand becomes closer to a high-frequency switched signal than a smooth ramp.\citep{candler2026_computeascde}
\srcredflag{Public, audited rack-level Rubin power transient traces are not yet broadly available; any specific rack density numbers used here should be treated as placeholders until vendor disclosures or measured telemetry is published.}{2026-01-15}

A convenient abstraction is to treat the data center as a dispatcher over two time scales:
\begin{align}
  L(t) &= L_{\text{base}}(t) + L_{\text{burst}}(t), \\
  L_{\text{burst}}(t) &= \sum_{i} A_i \,\mathbf{1}_{[t_i,t_i+\Delta_i]}(t),
\end{align}
where $L_{\text{burst}}$ captures dense compute intervals. The practical point is that $dL/dt$ is dominated by switching and synchronization, not turbine-governor dynamics.

\paragraph{The SMR ramp and stability constraint.}
Light-water SMR modules can load-follow, but the admissible region is constrained by fuel and cladding limits, xenon/iodine dynamics, and secondary-side stability (including steam generator and feedwater control interactions).\citep{nrc2018_nuscale_rai182,hotcarbon2025_uncertainty}
Even when the reactor can follow, the \emph{balance of plant} may not accept rapid load rejection without protection actions that are economically catastrophic for training (turbine trips, steam dump actuation, or scram-triggering sequences).\citep{hotcarbon2025_uncertainty}

This is the operative mismatch: Rubin wants MW/s behavior; SMR physics and protection systems enforce MW/min behavior. Absent buffering, a compute “sprint” is indistinguishable from an adversarial step disturbance applied to the plant boundary conditions.

\begin{table}[H]
\centering
\caption{The Transient Mismatch: Rubin-Class AI vs.\ Light-Water SMR Constraints (conceptual)}
\vspace{0.2cm}
\begin{tabular}{p{3cm} p{3.6cm} p{3.6cm} p{3.6cm}}
\toprule
\textbf{Parameter} & \textbf{Rubin-Class Cluster} & \textbf{Light-Water SMR} & \textbf{Implication} \\
\midrule
Dominant time scale & ms--s scheduling & s--min thermal / controls & Requires an interposed mapping layer \\
\midrule
Ramp behavior & step-like, bursty & bounded ramps + protection & Without buffers, trips propagate to compute \\
\midrule
Economic loss mode & checkpoint / restart tax & scram + poison-out recovery & failures are asymmetric and expensive \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Electrical transient constraint and substation admissibility}

Beyond generation, Rubin-class load creates grid-interface constraints. High-frequency telemetry and orchestration are not optional: averaging windows in the minutes regime can hide millisecond-to-second transients that matter for protection, voltage, and reactive power response.\citep{powerinfra2026_telemetry}
Accordingly, the “safe ramp” constraint must be treated as a \emph{substation admissibility} constraint, not a finance-only curtailment preference:
\begin{equation}
t_{\mathrm{ramp}} \ge \frac{\Delta P}{R_{\mathrm{safe}}}.
\end{equation}
If the cluster can drop load much faster than the substation and plant can absorb, then load rejection becomes the dominant contingency. That contingency must be priced into the planning kernel as a reliability externality (Compute-ASCDE’s survival weighting formalizes this monetization pathway).\citep{candler2026_computeascde}

\subsection{Load stiffness and training bifurcation}

The load bifurcation into \emph{stiff} and \emph{flexible} tranches is the controlling abstraction for nuclear-coupled AI.
Stiffness can be modeled as the ratio of interruption penalty to the value of time:
\begin{equation}
k_{\mathrm{stiff}} = \frac{C_{\mathrm{switch}}}{\VOLL \cdot \Delta t},
\end{equation}
where $C_{\mathrm{switch}}$ captures checkpoint/restart overhead and lost convergence progress.\citep{candler2026_computeascde}
Large-state training runs drive $k_{\mathrm{stiff}}\rightarrow\infty$ in practice.\srcnote{The exact state volume depends on model size, optimizer state, parallelism strategy, and checkpoint format; treat any single PB figure as scenario input, not a universal constant.}{2026-01-15}

\begin{itemize}
  \item \textbf{Stiff loads (training):} must be buffered and governed such that $S(t)\approx 1$ over multi-week horizons, or the effective cost explodes via checkpoint hysteresis.\citep{candler2026_computeascde}
  \item \textbf{Flexible loads (inference/aux):} can be scheduled as a controllable tranche, behaving like a VPP-like resource that absorbs transients and participates in grid support when economically rational.\citep{candler2026_computeascde}
\end{itemize}

\subsection{The missing layer: virtual sensing + zero-trust as a scheduling boundary}

INL’s zero-trust malware-prevention architecture is relevant here because, in a nuclear-coupled AI facility, integrity failures are also \emph{energy} failures: malicious or faulty control-plane actions can induce load profiles that drive the plant into protection or degrade availability.\citep{talukder2023_zerotrust}
Thus, the scheduling plane must be constrained by both:
\begin{enumerate}
  \item \textbf{Physical margin}: inferred thermal state and near-term trajectory (a DeepONet-class surrogate/digital twin is the natural mechanism for this oracle role), and
  \item \textbf{Trust margin}: continuous verification of commands, telemetry authenticity, and behavioral baselines (zero-trust governance), which modulates the survival weighting $S(t)$ used in valuation.\citep{talukder2023_zerotrust,candler2026_computeascde}
\end{enumerate}

This yields the integration criterion: a sprint is permitted \emph{iff} it is both thermally admissible and trust-admissible. The remaining design problem is to size and place buffers (electrical + thermal) so that “compute impulses” are transformed into “plant-admissible ramps” without paying unacceptable conversion losses.


% =========================================================
% Interface + Oracle Block (rewrite w/ citations + footnotes)
% =========================================================

\subsection{Interface Primitives: From Narrative Mismatch to Enforceable Constraints}
To move from qualitative ``time-scale mismatch'' to an implementable coupling regime, the interface must expose a
minimal set of primitives that are simultaneously \emph{planner-visible} (valuation, adequacy, tariffs) and
\emph{controller-visible} (real-time feasibility, cut-out logic). We treat these primitives as a policy space: the
coupling is not ``SMR + AI'' in the abstract, but a constrained optimization over admissible controls and safety envelopes
\citep{candler2026_computeascde}.

\paragraph{Workload decomposition (stiff vs.\ flexible).}
Let campus compute be decomposed into two tranches,
\begin{equation}
P_{\text{AI}}(t,\omega)
\;=\;
P_{\text{stiff}}\,u_s(t,\omega)
\;+\;
P_{\text{flex}}\,u_f(t,\omega),
\qquad
u_s(t,\omega),u_f(t,\omega)\in[0,1],
\end{equation}
where $u_s(t,\omega)$ is continuity-constrained (training, always-on safety/cyber monitoring) and $u_f(t,\omega)$ is
dispatchable (inference, batch reprocessing). The key move is that curtailment and scarcity behavior become explicit
\emph{control variables} rather than ex post narrative assumptions: the admissible policy class constrains $u_s$ by
stiffness floors and ramp/interrupt limits while allowing $u_f$ to absorb scarcity calls
\citep[Sec.~2.4, Eqns.~(2.8)--(2.9)]{candler2026_computeascde}.%
\footnote{Operationally, the ``stiffness floor'' on $u_s$ is where you encode: SLA minima, thermal/cyber monitoring
continuity, and training-run checkpoint constraints. This prevents reviewers from arguing that the model quietly assumes
curtailment of a non-curtailable process.}

\paragraph{Switching penalties as a visible statistic.}
Curtailment is not free: throttling or switching induces a penalty (checkpoint/restart tax, resynchronization, validation,
SLA loss). A planner-facing switching loss is best represented as an explicit cost term,
\begin{equation}
C_{\text{switch}}(t,x,\omega)
\;=\;
c_{\text{sw}}\cdot \mathbf{1}\!\left\{u_s(t,\omega)\neq u_s(t-\Delta t,\omega)\right\}
\;+\;
c_{\text{re-sync}}\cdot \mathbf{1}\!\left\{\text{mode change}\right\},
\end{equation}
and then injected into the resource-cost stack (rather than embedded informally in prose)
\citep[Eqn.~(2.10)]{candler2026_computeascde}.%
\footnote{You can later refine $C_{\text{switch}}$ into an energy penalty, time penalty, or a probability-of-failure
penalty depending on whether you’re writing for grid planners (EUE/VOLL), facility finance (lost throughput), or ML
convergence (lost wall-clock). The point here is \emph{visibility}: make stiffness auditable.}

\subsection{DeepONet as a Physical Oracle for Sprint Feasibility}
The hazard is not merely that $dL/dt$ is large; it is that thermal-hydraulic state evolves with transport lags and safety
margins. The interface therefore needs a real-time feasibility oracle mapping \emph{histories} to near-future thermal state
\citep{candler2026_computeascde,Lu2021DeepONet}.

\paragraph{Operator formulation (history-to-state).}
Let $u_{\text{rod}}(\tau)$ denote supervisory control history (rod positions / setpoints) and let $P_{\text{AI}}(\tau)$ denote
compute load history. Define the (unknown) nonlinear operator
\begin{equation}
\mathcal{G} : (u_{\text{rod}}, P_{\text{AI}}) \mapsto T_{\text{out}}(\cdot),
\end{equation}
mapping histories to an outlet-temperature trajectory. Deep operator learning approximates $\mathcal{G}$ via a
branch/trunk decomposition, yielding a fast surrogate $\widehat{T}_{\text{out}}(t)$ appropriate for on-line feasibility
checks \citep{Lu2021DeepONet}. In the SMR--AI setting, this ``thermal oracle'' is the necessary translation layer between
nanosecond-domain GPU switching and minute-scale reactor feasibility \citep[Sec.~6.4 and App.~I]{candler2026_computeascde}.

\paragraph{State-dependent sprint caps.}
Let sprinting scale a baseline profile $P_{\text{base}}(t)$ by $\sigma(t)\in[1,\sigma_{\text{peak}}]$, so that
$P_{\text{AI}}(t)=\sigma(t)P_{\text{base}}(t)$ on sprint windows. Define thermal headroom
\begin{equation}
\Delta T_{\text{safe}}(t) := T_{\text{trip}} - \widehat{T}_{\text{out}}(t),
\end{equation}
and enforce a conservative forward-horizon sprint cap
\begin{equation}
\sigma(t) \le \sigma_{\max}(t),
\end{equation}
where $\sigma_{\max}(t)$ is defined by the requirement that predicted temperatures remain below trip thresholds over the
transport-lag horizon \citep[App.~I]{candler2026_computeascde}.%
\footnote{Use ``trip'' rather than ``scram'' if you intend the oracle to trigger a \emph{pre-trip cut-out} (curtail compute,
dump to buffer, shed flexible tranche) before plant protection actuates. This avoids reviewers claiming you rely on
protection-system behavior as a control mechanism.}

\paragraph{Energy-form sprint-lag inequality.}
For sub-second impulses, an energetic bound is often more robust than pointwise ramp constraints:
\begin{equation}
\int_{t}^{t+\Delta t_{\text{sprint}}} \dot{P}_{\text{AI}}(\tau)\,d\tau
\;\le\;
C_{\text{th}}\!\left(T_{\text{trip}}-\widehat{T}_{\text{out}}(t)\right),
\end{equation}
where $C_{\text{th}}$ is an effective thermal-capacitance proxy. This inequality is the correct mathematical
``low-pass filter'' statement: sprint impulses are admissible only if remaining thermal headroom can absorb them
\citep[App.~I]{candler2026_computeascde}.

\subsection{Stability and Cut-Out Logic Under Aggressive Sprint Dynamics}
Once sprinting is treated as a bounded disturbance, one can state closed-loop stability properties of the SMR thermal
state under DeepONet-augmented feedback and cut-out logic \citep{candler2026_computeascde,Khalil2002Nonlinear}.

Let $x=[T_c, T_{\text{coolant}}]^T$ be a reduced thermal state and model the coupled dynamics as
\begin{equation}
\dot{x} = A x + B u + D\,P_{\text{AI}}(t,\omega),
\end{equation}
with a feedback law $u = -K(x)\,x$ augmented by oracle-based admissibility constraints on $P_{\text{AI}}$.
Under the sprint-lag bound, a quadratic Lyapunov candidate $V(x)=x^T P x$ yields an input-to-state stability-style
guarantee over the region of attraction defined by trip setpoints (standard ISS arguments; see \citealp{Sontag1995ISS};
also \citealp{Khalil2002Nonlinear}). Operationally: the oracle + cut-out forces re-entry to the thermal equilibrium
manifold before plant protection trips, even under aggressive compute sprint attempts \citep[Sec.~6.3--6.4]{candler2026_computeascde}.

\subsection{Planning Link: Reliability Externality Dominates for Stiff Loads}
For stiff tranches, the relevant question is not average energy cost but adequacy-tail interaction. A canonical welfare
mapping represents incremental reliability cost as
\begin{equation}
C_{\text{Rel}}(t,\omega) := \mathrm{VOLL}(t)\cdot \Delta \mathrm{EUE}(t,\omega),
\end{equation}
and makes ``negative reliability cost'' possible when flexible tranches curtail during scarcity windows relative to a
baseline policy \citep[Eqn.~(2.7) and Prop.~2.2]{candler2026_computeascde}. This is the valuation bridge into
Compute-ASCDE: the coupling is justified (or rejected) on whether it reduces tail-coincidence externalities, not on
whether it supplies carbon-free MWh in expectation.

Moreover, if incremental adequacy impact is monotone in net load on scarcity hours, then enforcing $u_f(t)=0$ during
contracted scarcity events (subject to bounded switching penalties) weakly reduces expected reliability externality
relative to a non-curtailable baseline, holding the stiff tranche fixed \citep[Prop.~2.2]{candler2026_computeascde}.
This is the formal reason the integration strategy must be workload-aware: the flexible tranche is the controllable
shock absorber, while the stiff tranche is the valuation driver via reliability tails.

\newpage
\section{Analyzing Dr. Bhowmik’s Frameworks: DeepONet, HNN, and the NEXUS-DC Integration Stack}

Dr.\ Bhowmik’s portfolio is best understood as a \emph{three-layer integration stack} for nuclear--data-center coupling:
(i) a \emph{control-layer} based on operator-learning and virtual sensing (DeepONet / deep neural operators),
(ii) a \emph{security-layer} based on continuous verification and anomaly detection (Zero-Trust + HNN/HIPMoS),
and (iii) a \emph{program-layer} (NEXUS-DC) articulating a nuclear-powered data-center deployment pathway.
Each layer is individually useful, but Rubin-class ``sprint'' behavior forces them to be made \emph{interface-complete}:
they must expose explicit real-time primitives (headroom, ramp feasibility, switching penalties, and fail-safe cutouts)
rather than remaining conceptual.

\subsection{DeepONet: Operator Learning as a Physics-Informed Oracle for Real-Time Control}

Deep Operator Networks (DeepONet) were introduced to learn \emph{nonlinear operators} mapping between function spaces,
e.g., from boundary/initial conditions and forcing histories to full spatiotemporal state trajectories
\citep{lu2019deeponet,Lu2021DeepONet}.%
\footnote{DeepONet is explicitly constructed to approximate an \emph{operator} (function-to-function map), not merely a
finite-dimensional regression. This distinction matters because the scheduler/controller interface in an SMR--AI facility
is naturally \emph{history-based}: what is safe to do next depends on the thermal-hydraulic state implied by recent load
and control actions, not just the current sensor snapshot.}

\paragraph{Operator formulation (history-to-state).}
Let $u(\tau)$ denote the vector of plant inputs over a trailing horizon (e.g., rod setpoints, feedwater flow, inlet
temperature, pump states) and let $P_{\text{AI}}(\tau)$ denote the compute load trajectory. The plant evolution can be
represented abstractly as an operator
\begin{equation}
\mathcal{G}:\ \bigl(u(\cdot),P_{\text{AI}}(\cdot)\bigr)\ \mapsto\ x(\cdot),
\end{equation}
where $x(\cdot)$ may include outlet temperature fields, void fraction proxies, steam-generator inventory, and other
latent variables. DeepONet approximates $\mathcal{G}$ with the standard \emph{branch/trunk} decomposition
\citep{lu2019deeponet,Lu2021DeepONet}:
\begin{equation}
\widehat{\mathcal{G}}\bigl(u\bigr)(y)\ \approx\ \sum_{k=1}^{p} b_k\!\bigl(u(x_1),\dots,u(x_m)\bigr)\, t_k(y),
\end{equation}
where the \emph{branch net} encodes samples of the input function at sensors/knots $\{x_i\}$ and the \emph{trunk net}
encodes the query coordinate $y$ (space/time).

\paragraph{Why this matters for nuclear DT / virtual sensing.}
A central claim in the nuclear digital-twin literature is that DeepONet-style neural operators can act as \emph{virtual
sensors} for quantities that are difficult or impossible to measure directly in harsh environments, while still
generalizing across operating conditions. In an AP-1000 PWR hot-leg case study, a DeepONet-based DT is presented as a
real-time predictor of thermal-hydraulic quantities with low relative errors and reported inference speedups over
traditional CFD, enabling online monitoring without continuous retraining \citep{hossain2024virtualsensing}.%
\footnote{The ``no continuous retraining'' point is operationally crucial: a Rubin-class facility cannot treat the DT as
an offline model that periodically re-trains; it must behave like a deterministic service with bounded latency and known
failure modes. A reasonable path is to mandate a calibration/validation gate (e.g., periodic residual tests against
physical sensors) rather than online retraining.}

\paragraph{The oracle contract: what the scheduler can safely ask.}
To integrate Rubin sprinting, DeepONet must be packaged as a \emph{feasibility oracle} with explicit IO semantics. One
workable contract is:
\begin{align}
\textbf{Input:} \quad & h_t := \Bigl(u(t-\Delta:t),\ P_{\text{AI}}(t-\Delta:t),\ \xi(t-\Delta:t)\Bigr), \\
\textbf{Output:} \quad & \Bigl(\widehat{x}(t:t+H),\ \widehat{m}(t:t+H),\ \widehat{\sigma}_{\max}(t),\ \widehat{q}(t)\Bigr),
\end{align}
where $\xi$ denotes disturbance channels (ambient, cooling-loop constraints), $\widehat{m}$ are safety margins (e.g.,
distance-to-scram), $\widehat{\sigma}_{\max}$ is a \emph{sprint multiplier cap} for the next decision window, and
$\widehat{q}(t)$ is a model-quality/uncertainty statistic.%
\footnote{You can implement $\widehat{q}(t)$ as (i) an ensemble variance proxy, (ii) a conformal prediction interval
width, or (iii) a residual-based trust metric (e.g., max normalized error vs.\ available sensors). The key is not the
specific method; it is that \emph{the controller must have an explicit ``abstain / degrade'' mode} when the DT is out of
distribution.}

\paragraph{Rubin coupling: sprint feasibility becomes an explicit constraint.}
Let $P_{\text{AI}}(t)=\sigma(t)P_{\text{base}}(t)$ on sprint windows, $\sigma(t)\in[1,\sigma_{\text{peak}}]$. Define a
thermal headroom margin (one of several possible)
\begin{equation}
\Delta T_{\text{safe}}(t) := T_{\text{scram}} - \widehat{T}_{\text{out}}(t),
\end{equation}
and impose a forward-horizon admissibility condition:
\begin{equation}
\sigma(t)\ \le\ \widehat{\sigma}_{\max}(t)\quad \text{such that}\quad \widehat{m}(t+\tau)\ge 0\ \ \forall \tau\in[0,H].
\end{equation}
This converts ``the load steps too fast'' from a narrative complaint into a \emph{machine-checkable} real-time safety
constraint: sprinting is allowed only when it remains inside forecasted margins.

\subsection{Hybrid Neural Networks (HNN) and Zero-Trust: From Cybersecurity to Cyber-Physical Stability}

Dr.\ Bhowmik’s Zero-Trust line of work treats nuclear plant cyber defense as an always-on verification problem: assume
no implicit trust, continuously validate device/system behavior, and identify malicious activity before it propagates
into operational disruption. In the INL-oriented formulation, the proposed architecture explicitly pairs a
\emph{Hybrid Neural Network (HNN)} with a Host Intrusion Prevention System (HIPMoS) as part of an AI-powered Zero-Trust
malware prevention framework \citep{talukder2023_zerotrust}.%
\footnote{From a Compute-ASCDE / stiff-load perspective, cybersecurity is not a separate concern: it is one of the few
plausible pathways by which an attacker can \emph{force} a checkpoint/restart cascade (or a safety trip), converting a
cyber event into a reliability event.}

\paragraph{HNN as a modality-fuser (why ``hybrid'' matters).}
HNN is best seen as an architectural pattern: a convolutional front-end for extracting local motifs from high-rate
streams (packets, syscalls, spectra), followed by a dense (or recurrent) back-end for global classification and temporal
aggregation. The cited Zero-Trust framework explicitly places an HNN inside the ZTA stack \citep{talukder2023_zerotrust}.
A closely related INL-affiliated example is gamma-spectral isotope identification using a hybrid CNN+FC approach, where
the hybrid architecture is motivated by feature extraction + classification and reports strong performance metrics
\citep{galib2021gamma}.%
\footnote{Even if the modality differs (network telemetry vs.\ radiation spectra), the systems lesson is the same:
hybrids are attractive when (i) raw streams have local structure exploitable by convolutions and (ii) the plant needs a
single decision statistic (e.g., ``anomalous / benign'') with low false positives. False positives are expensive in a
stiff-load facility because they trigger operational churn.}

\paragraph{HIPMoS and the segmentation problem.}
A core operational gap in most ``AI for cybersecurity'' stacks is \emph{segmentation}: where, exactly, to cut the system
into zones, interfaces, and policy boundaries. The referenced Zero-Trust work explicitly calls out HIPMoS as a host
intrusion prevention component and highlights segmentation as part of the approach \citep{talukder2023_zerotrust}. This
matters because a Rubin-class site has at least three distinct cyber-physical zones with different threat models:
\begin{itemize}
  \item \textbf{Plant safety and I\&C zone:} high integrity, low bandwidth, strongly audited change control.
  \item \textbf{Facility energy-management zone:} fast telemetry, dispatch logic, load-shedding and cutout control.
  \item \textbf{Compute fabric zone:} massive east-west traffic, rapid reconfiguration, frequent software changes.
\end{itemize}
Segmentation is not just ``best practice''; it is how you prevent faults or compromises in the compute fabric from
crossing into the safety domain, while still permitting the minimal data required for the DeepONet oracle to function.

\paragraph{Reframing: cyber as a disturbance channel in the stability analysis.}
For your coupled model, treat cyber incidents as shocks to the effective failure probability and/or forced switching:
\begin{equation}
P_{\text{fail}}(t) \uparrow \quad \Rightarrow \quad \mathbb{E}[C_{\text{switch}}] \uparrow,\qquad
\mathbb{E}[\Delta \mathrm{EUE}] \uparrow \ \ (\text{if stiff jobs restart into scarcity windows}).
\end{equation}
This is the precise bridge to Compute-ASCDE: the security stack has first-order economic value because it reduces the
rate at which the facility enters ``stop-the-world'' dynamics that amplify tail risk.

\subsection{NEXUS-DC: The Program-Layer Vision, and the Missing Control-Theoretic Middle}

NEXUS-DC is the programmatic wrapper: it frames nuclear-powered data centers as a national-scale deployment pathway and
emphasizes reliability and redundancy needs for data centers \citep{bhowmik2024nexusdc}. Complementary INL workshop
materials similarly situate nuclear as an enabling technology for high-demand data centers \citep{inl2024workshop}.%
\footnote{NEXUS-DC is best cited as a presentation/technical report rather than a peer-reviewed dynamics paper. In the
manuscript, treat it as the strategic ``why'' and ``where,'' not the authority for transient feasibility.}

\paragraph{The gap under Rubin: from collocation to co-optimization.}
The NEXUS-DC layer is directionally correct (site selection, regulatory pathway, reliability framing), but Rubin-class
sprinting forces an additional middle layer:
\begin{quote}
\emph{A high-frequency, model-mediated co-optimization loop that exposes thermal headroom and ramp feasibility as
planner-visible and scheduler-visible primitives, with explicit cutout logic and switching penalties.}
\end{quote}
Stated bluntly: collocation (SMR next to data center) is insufficient; the facility must behave as a joint dynamical
system with explicit admissible actions.

\paragraph{Actionable upgrade: an interface-complete ``nuclear--compute kernel.''}
A minimal extension to NEXUS-DC that makes it Rubin-complete is to require:
\begin{itemize}
  \item \textbf{Telemetry contract:} sub-second metering for $P(t)$, voltage/reactive indicators, and key thermal
  proxies; plus a defined data path into the facility EMS/scheduler.
  \item \textbf{Oracle contract (DeepONet):} bounded-latency headroom and constraint-margin service (above).
  \item \textbf{Workload typing:} stiff vs.\ flexible tranches become a first-class control variable, not an afterthought.
  \item \textbf{Fail-safe policy:} deterministic cutouts and ``safe degrade'' modes when the oracle quality drops.
\end{itemize}
This is the concrete way to evolve NEXUS-DC from an integration vision into a control-feasible architecture.

% ---------------------------------------------------------
% Control sequences / knobs (drop-in block; adjust later)
% ---------------------------------------------------------
\subsection*{Control Sequences (Planner/Controller Knobs Used Throughout)}

We will use the following time-indexed control sequences as the facility-level ``knobs'':
\begin{align}
\mathrm{VOLL}(t) &:\ \text{Value of Lost Load schedule (scarcity valuation / tail monetization)},\\
u_s(t) &\in [0,1]:\ \text{stiff tranche continuity control (typically pinned near 1)},\\
u_f(t) &\in [0,1]:\ \text{flex tranche dispatch control (curtail/shift/shape)},\\
\sigma(t) &\in [1,\sigma_{\text{peak}}]:\ \text{sprint multiplier for compute goodput},\\
\widehat{\sigma}_{\max}(t) &:\ \text{oracle-imposed sprint cap given predicted margins},\\
\pi_{\text{cut}}(t) &\in \{0,1\}:\ \text{hard cutout (safety / protection logic trigger)}.
\end{align}
In prose: $\mathrm{VOLL}(t)$ is the valuation spine for adequacy-tail decisions, $u_f(t)$ is the shock absorber, and
$\sigma(t)$ is permitted to rise only when the oracle certifies margin sufficiency.%
\footnote{If you want $\mathrm{VOLL}(t)$ to be explicitly piecewise-constant, define
$\mathrm{VOLL}(t)=\sum_{j} v_j\,\mathbf{1}\{t\in I_j\}$ where $I_j$ are scarcity / non-scarcity intervals; this makes the
valuation logic reviewer-proof and easy to simulate.}


\newpage
\subsection{Thermal Energy Storage (TES) as a "Physical Load Balancer"}

The stiffness of training loads implies they cannot easily curtail without incurring massive checkpointing penalties. To decouple the constant generation of the SMR from the stochastic bursts of the AI cluster, we incorporate research on \textbf{Phase-Change Materials (PCMs)} and \textbf{Thermal Energy Storage (TES)}.

\paragraph{Revised Compute-ASCDE with Buffering:}
We modify the valuation equation to internalize the value of the buffer ($\mathcal{B}$) as a credit against the reliability cost:

\begin{equation}
ASCDE_{AI} = \frac{\sum_{t=0}^H \delta^t \cdot [C_{Res}(t) + C_{Int}(t) + C_{Rel}(t) - \mathcal{V}(\mathcal{B})]}{\sum_{t=0}^H \delta^t \cdot S(t) \cdot T_g(t)}
\end{equation}

Where $\mathcal{V}(\mathcal{B})$ is the value of avoided "Stop-the-World" penalties and unserved energy. The buffer allows the SMR to operate at 100\% steady-state efficiency (maximizing its capacity factor) while the AI load "sprints" and "stops" asynchronously.

\subsection{Symbiotic Thermal Cycles and the Hydro-Constraint}

The "Hydro-Constraint" identifies water permits as the binding limit for AI grid integration. Dr. Bhowmik’s work on \textbf{Nanofluids} and \textbf{Condensation Heat Transfer} enables a Symbiotic Thermal Cycle that optimizes the facility's joule-utility:

\begin{itemize}
    \item \textbf{AI Waste Heat Recovery:} Rubin-class racks produce high-grade waste heat ($\sim 45^\circ$C), which is utilized to pre-heat SMR feedwater, increasing overall plant thermodynamic efficiency.
    \item \textbf{Advanced Heat Rejection:} Parametric CFD studies of multicomponent gas mixtures are applied to \textbf{Air-Cooled Condensers (ACC)} to reduce reliance on local water permits.
    \item \textbf{Nanofluid Enhancement:} The use of nanofluids in secondary cooling loops enhances heat transfer coefficients, mitigating the efficiency penalties typically associated with dry cooling in hot climates like West Texas.
\end{itemize}

\subsection{Techno-Economic Parameters for Nuclear-AI Integration}

The table below contrasts integration and capital parameters for primary SMR archetypes when paired with high-stiffness AI loads.

\begin{table}[h!]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Parameter} & \textbf{Light-Water SMR} & \textbf{Liquid-Metal SMR} & \textbf{UEVF Module Impact} \\ \midrule
Overnight Capital (OCC) & \$4,844/kW & \$3,985/kW & $C_{Res}$ reduction \\
Mean LCOE & \$89.6/MWh & \$80.6/MWh & $ASCDE$ base \\
Core Exit Temp & $\sim$300$^\circ$C & $\sim$750$^\circ$C & Symbiotic Cycle Gain \\
Construction Time & 4.5 Years & 2.5--3 Years & $\Delta WACC$ reduction \\
Safety Philosophy & Passive Redundancy & Intermediate Loop & $C_{Rel}$ Mitigation \\ \bottomrule
\end{tabular}
\caption{Comparative Techno-Economic Parameters for Nuclear-AI Co-location.}
\end{table}

\subsection{Zero-Trust Cyber-Reliability and Silicon Survival}

Finally, we integrate Bhowmik’s \textbf{AI-Powered Zero-Trust Framework} into the \textbf{Silicon Survival Function} $S(t)$. Traditional models assume binary machine availability; our framework accounts for "Cyber-Attainment":

\begin{equation}
S(t) = P(Survival_{Queue}) \cdot P(Cyber_{Efficacy})
\end{equation}

By utilizing the \textbf{Host Intrusion Prevention and Monitoring System (HIPMoS)}, the facility reduces the risk of malware-driven outages that would otherwise increase \textbf{Reliability Cost} ($C_{Rel}$) by \$3--\$8/MWh.

The "Efficiency Paradox" paper proposes an "ASCDE Parity Test" for interconnection.\textsuperscript{1} We extend this to SMR deployment decisions, providing a rigorous economic justification for the "Nuclear Premium."

\subsection{Quantifying the Reliability Value}

Utility planners often compare SMR LCOE (\$60--\$100/MWh) to Solar/Wind LCOE (\$30/MWh). This is flawed for AI because it ignores the cost of reliability ($\mathcal{R}_{Reliability}$).
Using the Compute-ASCDE framework, we value the reliability of the SMR.

\begin{equation}
ASCDE_{SMR} = \frac{\mathcal{C}_{SMR} + \mathcal{C}_{Fuel} - \mathcal{R}_{Reliability}}{\int_{0}^{\mathcal{H}} S(t) \cdot T_g(t) dt}
\end{equation}

\paragraph{The Value of $\mathcal{R}_{Reliability}$:}
For a "Stiff" training cluster, a grid outage costs millions in lost state/time. An SMR provides "Negative Opex" by eliminating the "Checkpoint Tax" associated with grid instability.

\paragraph{Insight:} If the grid has a reliability of 99.9\% (8.7 hours downtime/year), a training run lasting 3 months has a high probability of failure. An SMR with 99.999\% reliability (islanded) drastically increases the Survival Function $S(t)$ in the user's equation.

\paragraph{Conclusion:} The "Nuclear Premium" is justified only for Stiff Loads (Training). For Flexible Loads (Inference), the user's "Ancillary Hedge" (running on grid + batteries) remains cheaper.

\subsection{Siting Optimization via Thermoeconomic Covariance}

The user's Thermoeconomic Covariance states that grid power is most expensive when it is hot (low efficiency).\textsuperscript{1} The "Heat Penalty" ($Cov(P(T), \Psi(T))$) increases operating costs by 15--20\% during scarcity events.

SMRs are less susceptible to ambient temperature degradation than gas turbines (which suffer air density derating). By utilizing Dr. Bhowmik’s advanced cooling designs (e.g., optimized dry cooling with nanofluids\textsuperscript{24}), SMR-powered facilities can maintain higher efficiency during heat waves.

\begin{itemize}
    \item \textbf{Strategy:} Deploy SMR-powered clusters in hot, arid zones (like West Texas/Permian) where the delta between Grid Price (high scarcity) and SMR Cost (fixed) is maximized.
    \item \textbf{Constraint:} This requires solving the "Hydro-Constraint." Bhowmik’s work on "dry cooling" and "condensation heat transfer"\textsuperscript{23} becomes the enabling technology for this arbitrage.
\end{itemize}


\newpage
\section{Security Architecture: HNN as the Cyber-Physical Guardian}
\label{sec:security-hnn-guardian}

As AI infrastructure becomes an adequacy-relevant load and nuclear becomes a colocated supply option, security
ceases to be an IT subproblem and becomes a \emph{closed-loop safety and reliability} constraint. The facility is no
longer defending data at rest; it is defending the integrity of a cyber--physical feedback system whose failure
modes include \emph{plant trips, thermal excursions, and grid-visible transients}. This section (i) formalizes the
threat model as \emph{adversarial actuation through the compute--energy interface}, and (ii) specifies a
physics-informed Hybrid Neural Network (HNN) guardian---aligned with the zero-trust posture in nuclear OT/ICS
security---as the facility’s cyber--physical enforcement layer \citep{talukder2023_zerotrust}.\footnote{We treat
``zero trust'' here as an operational discipline (continuous verification, least privilege, segmentation, strict
interfaces), not as a marketing label. The normative shift is that \emph{compute is a potentially adversarial
actuator}, so state transitions must be explicitly earned.}

\subsection{Threat model: from malware to kinetic cyber attacks}
\label{subsec:threat-kinetic}

In a coupled SMR--AI facility, the adversary can target the \emph{interface} between scheduling, energy management,
and plant controls rather than attempting to compromise nuclear safety systems directly. The attack surface is
therefore not a single endpoint; it is the \emph{closed-loop chain}
\[
\text{Scheduler} \rightarrow \text{EMS} \rightarrow \text{(OT gateway)} \rightarrow \text{Plant/Balance-of-Plant}
\rightarrow \text{Telemetry} \rightarrow \text{Scheduler},
\]
where corruption or delay at any link can induce unsafe dynamics.

We model the coupled system as a discrete-time, partially observed, hybrid dynamical system:
\begin{align}
x_{k+1} &= f(x_k, u_k, w_k),\\
y_k &= h(x_k) + v_k,
\end{align}
where $x_k$ aggregates plant thermal-hydraulic and electrical states, $u_k$ are commanded setpoints / admissible load
steps, $y_k$ are measured telemetry streams, and $(w_k,v_k)$ include both stochastic disturbances and adversarial
components. The adversary’s objective is not necessarily ``maximize load''; it may be to (i) increase trip/scram
probability, (ii) amplify restart cascades (checkpoint tax), or (iii) increase scarcity coincidence to inflate
reliability externalities.\footnote{This makes security economically load-bearing: if an attack increases forced
outages or shifts load into scarcity hours, expected reliability cost rises through a tail term (VOLL$\times$EUE),
even if expected MWh is unchanged. This is the valuation bridge emphasized in Compute-ASCDE \citep{candler2026_computeascde}.}

Concretely, we assume four adversary capability classes:
\begin{enumerate}[label=\textbf{T\arabic*.}]
  \item \textbf{Signal spoofing:} manipulate inputs to scheduling/EMS (price, dispatch flags, reserve status,
  ``permission to sprint'') or replay stale control grants.
  \item \textbf{Actuation shaping:} craft job submissions and kernel timing to induce high-$dP/dt$ steps or
  near-periodic forcing (resonant excitation).
  \item \textbf{Telemetry poisoning:} corrupt measurement streams (PDU/phasor, process variables, derived states)
  to mask unsafe trajectories or create false safety.
  \item \textbf{Restart amplification:} induce failure loops (or security-triggered halts) to inflate switching
  penalties and checkpoint/restart energy taxes.\footnote{This is a reliability attack as much as a cyber incident:
  repeated restarts degrade effective energy intensity and increase adequacy-tail exposure \citep{candler2026_computeascde}.}
\end{enumerate}

\subsection{Adversarial load oscillations and resonance as a first-class hazard}
\label{subsec:adversarial-osc}

The cyber--physical hazard is not merely ``large load,'' but \emph{structured temporal forcing}. Let
$P_{\text{AI}}(t)$ denote aggregated campus load at the POI. An adversary can attempt to excite lightly damped modes
of the balance-of-plant (and, indirectly, plant protection logic) by shaping load with near-periodic content:
\begin{equation}
P_{\text{AI}}(t) \;=\; \bar{P} \;+\; A\sin(\omega t) \;+\; \varepsilon(t), \qquad \omega \approx \omega_0,
\end{equation}
where $\omega_0$ is a plant/BoP characteristic mode band and $\varepsilon(t)$ includes step-like sprint bursts and
fault-induced drops.\footnote{The point is not that the reactor ``load-follows'' at $\omega_0$, but that protective
relays, turbine-governor controls, steam dumps, condenser behavior, and level dynamics can be destabilized when a
fast actuator injects energy into a lightly damped band. In other words, \emph{frequency content} is
security-relevant, not merely a power-systems detail.}

To make resonance enforceable, we define a spectral-risk primitive the guardian can compute at runtime. Let
$\mathcal{F}_\Delta$ denote a short-window Fourier transform over window $\Delta$, and define the load spectrum
estimate $S_P(\omega;t)=|\mathcal{F}_\Delta\{P_{\text{AI}}\}(\omega)|^2$. Let $W(\omega)$ be a weighting kernel with
support on the sensitive band $\Omega_0$ (calibrated from commissioning tests and plant models). Then define the
\emph{resonance risk index}:
\begin{equation}
R_{\text{res}}(t) \;=\; \int_{\Omega_0} S_P(\omega;t)\,W(\omega)\,d\omega.
\label{eq:rres}
\end{equation}
This turns ``oscillation risk'' into a logged statistic and a gateable constraint.

\subsection{Defense architecture: zero-trust gating + physics-informed HNN}
\label{subsec:defense-hnn}

The defense must separate \emph{hard safety enforcement} from \emph{statistical inference}. We implement a two-layer
scheme:

\paragraph{Layer 0: command admissibility (hard gate).}
No kernel launch, job admission, or ramp command is accepted unless it passes an explicit verification chain. This
gate enforces (a) identity and integrity of the command, and (b) admissibility with respect to physical margins and
electrical envelopes. Operationally, Layer 0 implements:
\begin{itemize}
  \item signed commands with nonce/replay protection on scheduler$\rightarrow$EMS$\rightarrow$OT gateway requests;
  \item micro-segmentation between AI control plane, OT telemetry plane, and plant actuation boundary;
  \item allow-listed APIs with rate limiting and mandatory audit logs;
  \item feasibility checks driven by a plant surrogate (DeepONet) and POI ramp-safe constraints.
\end{itemize}

\paragraph{Layer 1: HNN guardian (cyber--physical anomaly detection + attribution).}
Bhowmik-style HNNs are used as \emph{cross-domain consistency detectors}: they jointly model digital intent and
physical response, rather than treating OT physics as external to cyber security \citep{talukder2023_zerotrust}. The
guardian consumes three synchronized streams:
\begin{itemize}
  \item \emph{Control plane}: scheduler/EMS traces, mode changes, job submissions.
  \item \emph{Electrical}: high-frequency POI measurements (or rack/PDU aggregation): $P(t)$, $V(t)$, $I(t)$, and
  derived transient metrics ($dP/dt$, flicker indices, etc.).\footnote{This is exactly where low-rate SCADA averaging
  fails: ms--s transients are invisible to 1--15 minute telemetry and can dominate protection behavior during large
  clusters. See the high-frequency telemetry argument in \citep{powerinfra2026_telemetry}.}
  \item \emph{Plant physics}: DeepONet virtual sensing estimates $\widehat{x}(t)$ and innovations
  $r(t)=y_{\text{meas}}(t)-\widehat{y}(t)$ \citep{Lu2021DeepONet,lu2019deeponet}.
\end{itemize}

A practical HNN decomposition is: (i) a CNN/TCN branch on waveform-like electrical features, (ii) a sequence model on
event traces (RNN or small Transformer), and (iii) a fusion head producing both anomaly probability and attack-type
classification. The key is not architectural novelty; it is that the detector sees \emph{both} the digital command
and the physical residual.

\paragraph{Physics-informed scoring with oracle uncertainty.}
DeepONet is treated as an oracle with uncertainty, not as truth. Let $\widehat{y}(t)$ be a predicted physical
quantity and $\sigma_y(t)$ a predictive dispersion (ensemble variance / MC dropout / conformal interval width). We
define conservative headroom:
\begin{equation}
\Delta T_{\text{safe}}(t) \;=\; T_{\text{scram}} - \big(\widehat{T}_{\text{out}}(t) + \alpha\sigma_T(t)\big),
\label{eq:headroom_uq}
\end{equation}
with safety multiple $\alpha\ge 0$ chosen to bound false-safe risk. The guardian then scores consistency via a
two-part statistic:
\begin{equation}
S(t) \;=\; \norm{r(t)}_{\Sigma^{-1}}^2 \;+\; \lambda\,R_{\text{res}}(t),
\label{eq:physics_score}
\end{equation}
where $\Sigma$ is an empirical benign covariance and $R_{\text{res}}(t)$ is defined in \cref{eq:rres}. High $S(t)$
flags \emph{authenticated-but-physically-inadmissible} behavior: the command may be valid cryptographically, but it
is inconsistent with plant physics or injects energy into sensitive frequency bands.

\subsection{Control sequences: auditable interface contracts}
\label{subsec:control_sequences}

The guardian is only implementable if it yields explicit, auditable control sequences (admission, scarcity, and
incident response). These sequences define what the scheduler/EMS boundary must implement.

\subsubsection{Sequence A: admission for steps and sprints}
\label{subsubsec:seqA}

For each proposed load step (job start, kernel burst, or sprint factor increase), execute:

\begin{enumerate}[label=\textbf{A\arabic*.}]
  \item \textbf{Authenticate:} verify signature, nonce, privilege scope.
  \item \textbf{Policy screen:} verify policy permits ramping (e.g., not in scarcity lockout, not in restricted
        operating mode). This is not a safety check.
  \item \textbf{Thermal feasibility:} query DeepONet to compute $\Delta T_{\text{safe}}(t)$ via
        \cref{eq:headroom_uq} and compute an admissible sprint cap $\sigma_{\max}(t)$ over horizon $H$
        \citep{Lu2021DeepONet}.
  \item \textbf{Electrical envelope:} enforce POI constraint $|dP/dt|\le R_{\text{safe}}$ and any plant-specific
        load rejection limits.\footnote{This is where you prevent ``relay chatter'' and over/under-voltage events
        driven by rapid cluster unloads, as emphasized by the telemetry orchestration argument in
        \citep{powerinfra2026_telemetry}.}
  \item \textbf{HNN gate:} compute $S(t)$ from \cref{eq:physics_score}; if $S(t)>\tau$, reject and log.
  \item \textbf{Commit:} if all checks pass, admit and write an immutable proof record (inputs, thresholds, oracle
        outputs, decision).
\end{enumerate}

\subsubsection{Sequence B: scarcity response (VOLL regime)}
\label{subsubsec:seqB}

When the facility enters a scarcity regime, the control objective shifts from expected cost to tail-risk control.
Compute-ASCDE’s valuation logic treats reliability as a dominant term for stiff loads via VOLL$\times$EUE
\citep{candler2026_computeascde}. We therefore enforce:

\begin{enumerate}[label=\textbf{B\arabic*.}]
  \item \textbf{Detect scarcity:} EMS ingests a scarcity flag (reserve shortfall / emergency declaration / internal
        thermal margin breach).
  \item \textbf{Freeze stiff tranche:} preserve continuity for $P_{\text{stiff}}$ except under hard safety trips.
  \item \textbf{Shed flexible tranche:} set $u_f(t)\leftarrow 0$ (or staged down) subject to switching penalties.
  \item \textbf{Checkpoint timing:} if shedding is anticipated, schedule checkpoints \emph{before} scarcity windows
        to avoid restart amplification.
  \item \textbf{Re-entry test:} allow flexible re-entry only when (i) scarcity clears and (ii) Sequence A feasibility
        returns with margin.
\end{enumerate}

\subsubsection{Sequence C: incident response (suspected cyber--physical attack)}
\label{subsubsec:seqC}

\begin{enumerate}[label=\textbf{C\arabic*.}]
  \item \textbf{Isolate:} segment suspected nodes (scheduler shard, EMS gateway, telemetry broker).
  \item \textbf{Safe-mode compute:} clamp sprint factor $\sigma(t)\rightarrow 1$ and reduce $u_f(t)\rightarrow 0$.
  \item \textbf{Plant-first preference:} prioritize plant stability (governor/steam dump protective settings)
        over compute continuity; compute is the sacrificial actuator.
  \item \textbf{Forensic capture:} snapshot network traces, power waveforms, and DeepONet residuals $r(t)$.
  \item \textbf{Controlled recovery:} require dual authorization to restore sprint permissions; re-enable via
        Sequence A with tightened thresholds $(\tau,\Omega_0,W(\omega))$.
\end{enumerate}



\subsection{Rigor: stability and why the abstraction is correct}
\label{subsec:why_correct}

This architecture is intentionally conservative: it treats compute as a potentially adversarial actuator and
requires state transitions to earn permission. The reason is structural: the coupled plant--campus dynamics are a
nonlinear system with disturbance-like actuation $P_{\text{AI}}(t)$, and the guardian’s role is to enforce bounded
disturbances and maintain the system inside a region of attraction. Under standard assumptions (local Lipschitz
dynamics; bounded disturbances; feasible gating), one can express an input-to-state stability (ISS) objective for
the plant thermal subsystem \citep{Khalil2002Nonlinear,Sontag1995ISS}.\footnote{We do not claim that a learned
surrogate ``proves safety.'' The claim is narrower: (i) the hard gate enforces explicit envelopes; (ii) the HNN
reduces attack and anomaly probability; (iii) the combined effect reduces forced-outage incidence and scarcity
coincidence, which is what dominates valuation for stiff loads \citep{candler2026_computeascde}.}

Economically, this is the correct abstraction because stiff-load value is driven by adequacy tails, not by average
MWh. If the guardian reduces forced outages, restart cascades, or scarcity coincidence, it reduces expected
reliability externality costs even if it slightly reduces peak sprint throughput \citep{candler2026_computeascde}.


\newpage
\section{Implementation Roadmap: Intersecting the Frameworks}
\label{sec:implementation_roadmap}

To operationalize the convergence between (i) the Rubin-class load physics, (ii) Dr.\ Bhowmik’s DeepONet/HNN
tooling, and (iii) the Compute-ASCDE valuation layer, we recommend a three-phase integration plan. The governing
design principle is simple: \emph{the scheduler is an actuator}, so the interface between compute scheduling, EMS
dispatch, and plant controls must be specified as an auditable contract, not an informal ``coordination'' layer
\citep{NIST800207,IEC62443,NRC_RG571,candler2026_computeascde}.

\subsection{Interface contract (mandatory across all phases)}
\label{subsec:interface_contract}

The security and stability guarantees in \cref{sec:security-hnn-guardian} require typed messages, replay protection,
and proof-carrying decisions at the scheduler/EMS boundary. We therefore define a minimal contract with three
message families: (i) \texttt{REQUEST} (compute asks to change state), (ii) \texttt{GRANT/DENY} (guardian response),
and (iii) \texttt{ATTEST} (telemetry + residual evidence bundle). This is a direct instantiation of zero-trust for
OT/ICS: continuous verification and explicit authorization at boundaries \citep{NIST800207,IEC62443,NRC_RG571}.

\paragraph{Time bases.}
We separate the facility into three timing tiers to avoid ``slow policy governing fast actuation'' failures:
\begin{itemize}
  \item \textbf{Fast (ms--100ms):} rack/PDU telemetry, $dP/dt$ detection, spectral risk $R_{\text{res}}$ updates.
  \item \textbf{Medium (0.5--5s):} plant/BoP loops, governor/steam dump logic, DeepONet inference refresh.
  \item \textbf{Slow (minutes+):} planning policy (scarcity regimes, checkpoint scheduling, VOLL regime toggles).
\end{itemize}

\subsubsection{Schema A: \texttt{REQUEST\_LOAD\_STEP} (scheduler to guardian)}
\label{subsubsec:schema_request}

\begin{verbatim}
REQUEST_LOAD_STEP {
  msg_type: "REQUEST_LOAD_STEP",
  msg_id: UUID,
  ts_utc: int64,               // monotone time
  nonce: bytes,                // replay protection
  identity: { tenant_id, job_id, signer_id },
  scope: { site_id, cluster_id, poi_id },

  // proposed actuation
  P_current_MW: float,
  P_target_MW: float,
  ramp_profile: { type: "step"|"ramp", R_MW_per_s: float, horizon_s: float },
  sprint: { sigma_req: float, window_s: float },

  // workload semantics
  tranche: "stiff"|"flex",
  checkpoint: { state_PB: float, eta_checkpoint: float, last_ckpt_ts: int64 },

  // policy hints (NOT sufficient for admission)
  econ: { price_DA: float?, price_RT: float?, scarcity_flag: bool },

  // cryptographic
  signature: bytes
}
\end{verbatim}

\subsubsection{Schema B: \texttt{GRANT}/\texttt{DENY} (guardian to scheduler)}
\label{subsubsec:schema_grantdeny}

\begin{verbatim}
LOAD_STEP_DECISION {
  msg_type: "GRANT"|"DENY",
  msg_id: UUID,
  parent_msg_id: UUID,   // request id
  ts_utc: int64,

  grant: {
    P_target_MW: float,
    R_safe_MW_per_s: float,
    sigma_max: float,
    window_s: float
  },

  evidence: { deeponet_hash: bytes, residual_hash: bytes, poi_waveform_hash: bytes },

  reason: {
    code: "AUTH_FAIL"|"SCARCITY_LOCKOUT"|"THERMAL_INFEASIBLE"|
          "POI_RAMP_UNSAFE"|"RESONANCE_RISK"|"HNN_ANOMALY",
    detail: string
  },

  signature: bytes
}
\end{verbatim}

\subsubsection{Schema C: \texttt{ATTEST\_BUNDLE} (telemetry to  audit store)}
\label{subsubsec:schema_attest}

\begin{verbatim}
ATTEST_BUNDLE {
  msg_type: "ATTEST_BUNDLE",
  msg_id: UUID,
  ts_utc: int64,
  window: { start_ts: int64, end_ts: int64 },

  // electrical evidence (fast)
  poi: { P_ref, V_ref, I_ref, dpdt_ref },
  spectral: { R_res: float, Omega0_Hz: [f1,f2], W_kernel_id: string },

  // physics evidence (medium)
  deeponet: { xhat_ref, yhat_ref, residual_ref },

  // HNN output
  hnn: { anomaly_prob: float, class: string, score_S: float, tau: float },

  // immutable linking
  prev_bundle_hash: bytes,
  bundle_hash: bytes,
  signature: bytes
}
\end{verbatim}

\paragraph{Audit invariant.}
Every \texttt{GRANT/DENY} must reference the hash of an \texttt{ATTEST\_BUNDLE} created over the decision window.
A decision that cannot be replayed from evidence is invalid by construction.

\subsection{Phase 1: Dataset Design and Oracle Identification}
\label{subsec:phase1_dataset_oracle}

Phase~1 lives or dies on whether the surrogate is (i) calibrated, (ii) uncertainty-aware, and (iii) trained on the
\emph{correct transient families}. The failure mode is not ``low average error''; it is \emph{false safety} under a
corner transient. Therefore Phase~1 is treated as an identification problem with explicit coverage constraints,
not a generic ML exercise \citep{Lu2021DeepONet,lu2019deeponet,hossain2024virtualsensing}.

\subsubsection{Plant state and interface variable selection}
\label{subsubsec:state_selection}

Define a minimal but sufficient cyber--physical state for feasibility and protection gating. Let
\[
x(t) := \big[T_{\text{hot}}(t),\; T_{\text{cold}}(t),\; p_{\text{sg}}(t),\; \ell_{\text{sg}}(t),\;
\dot{m}_{\text{fw}}(t),\; \dot{m}_{\text{steam}}(t)\big]^\top,
\]
and define the interface variables exposed to the scheduler/EMS:
\[
z(t) := \big[\Delta T_{\text{safe}}(t),\; \sigma_{\max}(t;H),\; R_{\text{safe}}(t),\; \pi_{\text{unc}}(t)\big],
\]
where $\Delta T_{\text{safe}}$ is thermal headroom, $\sigma_{\max}$ is the oracle sprint cap, $R_{\text{safe}}$ is a
POI ramp-safe envelope, and $\pi_{\text{unc}}$ is a scalar uncertainty summary.\footnote{The new term
$\pi_{\text{unc}}(t)$ is the anti-hallucination safeguard: it is the signal that forces conservative behavior when
the oracle is extrapolating. The scheduler is not allowed to ``trust'' a confident-looking prediction without an
uncertainty tag.}

\subsubsection{Transient-family coverage: what must be in the training distribution}
\label{subsubsec:transient_families}

Let $\mathcal{D}$ denote the training dataset of transients. We require $\mathcal{D}$ to cover six forcing families,
each parameterized and then sampled across an envelope:

\begin{enumerate}[label=\textbf{\arabic*.}, leftmargin=*]
  \item \textbf{Sprint bursts (step-like forcing):}
  $P_{\text{AI}}(t)=\bar{P}+\Delta P\,\mathbf{1}\{t\in[t_0,t_0+\Delta]\}$ with $\Delta P$ spanning realistic campus
  steps and $\Delta$ spanning sub-second to minutes.\footnote{This family is the proxy for synchronized kernel
  launches and batch admits. It is the canonical ``fast edge'' forcing.}
  \item \textbf{Staircase ramps (bounded $dP/dt$):} piecewise linear ramps consistent with policy gating; used to
  learn the admissible envelope and to test whether the controller can enforce it.
  \item \textbf{Oscillatory forcing (resonance probing):}
  $P_{\text{AI}}(t)=\bar{P}+A\sin(\omega t)$ with $\omega$ swept across plant-sensitive bands, including around
  lightly damped modes (steam generator level, governor loops).%
  \footnote{If you do not include forced oscillations, you will discover resonance the hard way: in production.}
  \item \textbf{Load rejection events:} abrupt drops in $P_{\text{AI}}$ (fault, denial, job completion) plus balance-of-plant
  protective actions. This family exists to validate that the coupling is survivable under the \emph{loss} of load.
  \item \textbf{Controller mode switches:} transitions among operating modes (normal $\rightarrow$ scarcity $\rightarrow$
  incident safe-mode) to train the oracle on non-stationary policy regimes.
  \item \textbf{Degraded-sensing / missingness:} randomly masked telemetry channels, quantization, time skew, and
  bias injection. This family is mandatory for producing an uncertainty summary $\pi_{\text{unc}}(t)$ that is
  operationally meaningful \citep{hossain2024virtualsensing}.
\end{enumerate}

We treat these families as an explicit coverage contract:
\[
\mathcal{D}=\bigcup_{i=1}^{6}\mathcal{D}_i,
\qquad
\text{with}\;\; \mathcal{D}_i\;\text{sampled to enforce tail coverage, not mean coverage.}
\]
Operationally, this is implemented with stratified sampling on the forcing parameters
$(\Delta P,\Delta,A,\omega)$ and stress-testing at envelope edges.\footnote{This is the central methodological
upgrade: ``ML accuracy'' is not the objective. \emph{Envelope correctness} is.}

\subsubsection{Oracle learning objective: accuracy + constraint preservation}
\label{subsubsec:oracle_objective}

Let $\widehat{\mathcal{G}}_\theta$ denote the DeepONet surrogate mapping histories to state trajectories.
We train with a compound objective:
\begin{equation}
\min_\theta \; \underbrace{\mathbb{E}\big[\|y-\widehat{y}_\theta\|^2\big]}_{\text{state fidelity}}
\;+\;
\alpha\,\underbrace{\mathbb{E}\big[\phi_{\text{viol}}(\widehat{y}_\theta)\big]}_{\text{constraint penalty}}
\;+\;
\beta\,\underbrace{\mathbb{E}\big[\mathrm{calib}(\pi_{\text{unc}})\big]}_{\text{uncertainty calibration}},
\label{eq:oracle_objective}
\end{equation}
where $\phi_{\text{viol}}$ penalizes predicted threshold violations (trip margins) and
$\mathrm{calib}(\cdot)$ is a calibration loss tying uncertainty tags to realized errors.\footnote{Constraint
penalties are not cosmetic. They force the surrogate to be pessimistic near safety boundaries, which is exactly
where you need the model to stop being clever.}

\subsubsection{Uncertainty summary and conservative sprint envelopes}
\label{subsubsec:oracle_uncertainty}

Define an uncertainty proxy $\pi_{\text{unc}}(t)$ using one of the standard safe mechanisms (ensemble spread,
dropout variance, residual innovation statistics, or conformal error bands).\footnote{The paper does not need to
pick the mechanism. Implementation must. The key is that it is auditable and correlates with error under stress.}

Then define the sprint envelope conservatively:
\begin{equation}
\sigma(t) \le \sigma_{\max}(t;H)
\quad\text{where}\quad
\sigma_{\max}(t;H) := \sup\{\sigma: \widehat{T}_{\text{out}}(\tau;\sigma)+\eta(\pi_{\text{unc}})\le T_{\text{trip}},\;\forall\tau\in[t,t+H]\},
\label{eq:sigma_max_conservative}
\end{equation}
and $\eta(\pi_{\text{unc}})$ is an uncertainty inflation term.\footnote{This is the ``no free lunch'' wrapper:
when uncertainty is high, the envelope tightens even if the mean prediction looks safe.}

\subsubsection{TES sizing becomes a corollary of envelope feasibility}
\label{subsubsec:tes_sizing}

Once $\sigma_{\max}(t;H)$ is defined, required buffering (TES or electrical storage) becomes a direct corollary.
Let $P_{\text{req}}(t)$ be desired compute power and $P_{\text{adm}}(t)$ be admissible power from the oracle gate.
Define the buffer power:
\[
P_{\text{buf}}(t):=\big(P_{\text{req}}(t)-P_{\text{adm}}(t)\big)_+.
\]
Then the minimum buffer energy to satisfy a workload trace over horizon $[0,T]$ is
\begin{equation}
E_{\text{buf}}^{\min} \;=\; \sup_{t\in[0,T]}\int_{0}^{t} P_{\text{buf}}(\tau)\,d\tau,
\label{eq:buffer_energy}
\end{equation}
with analogous constraints on charge/discharge rates.\footnote{This is the key transformation: TES sizing is no
longer hand-wavy. It is the slack variable that makes the oracle constraints satisfiable for a target workload.}

% ---------------------------------------------------------
% Phase 2 (Expanded)
% ---------------------------------------------------------
\subsection{Phase 2: Red-Team Attack Library and Guardian Validation}
\label{subsec:phase2_redteam}

Phase~2 is where the design becomes reviewer-proof: we specify a threat taxonomy, a red-team library (attack
generator), and a measurable guardian performance target. The aim is not to claim ``secure''; it is to build an
\emph{audit trail} that security is treated as a closed-loop safety constraint, consistent with zero-trust doctrine
\citep{talukder2023_zerotrust,NIST800207}.

\subsubsection{Threat taxonomy mapped to interface surfaces}
\label{subsubsec:threat_taxonomy}

Define interface surfaces:
(i) scheduler$\rightarrow$EMS setpoints; (ii) telemetry$\rightarrow$oracle; (iii) oracle$\rightarrow$policy gate;
(iv) policy gate$\rightarrow$actuation; (v) price/dispatch inputs (if grid-connected).
Threat classes map cleanly:

\begin{enumerate}[label=\textbf{T\arabic*.}, leftmargin=*]
  \item \textbf{Signal spoofing:} falsify price/dispatch flags or control permissions (policy deception).
  \item \textbf{Telemetry poisoning:} bias or mask physical measurements to inflate headroom (oracle deception).
  \item \textbf{Adversarial load shaping:} craft job mixes that generate resonant or high-$dP/dt$ patterns (actuation through compute).
  \item \textbf{Restart cascade induction:} trigger repeated checkpoint/restart cycles to create reliability shocks
  (economic sabotage via forced non-availability) \citep{candler2026_computeascde}.
  \item \textbf{Model-targeted attacks:} exploit the oracle or HNN (distribution shift, adversarial examples) to
  evade detection.\footnote{You do not need to over-index on adversarial ML in the paper. But you do need to
  acknowledge it exists and that the system falls back conservatively under uncertainty drift.}
\end{enumerate}

\subsubsection{Red-team library: attack generators as test fixtures}
\label{subsubsec:redteam_library}

Let $\mathcal{A}$ denote an attack generator producing perturbed trajectories:
\[
\big(P_{\text{AI}}(t),\, y_{\text{meas}}(t),\, \text{policy flags}\big)
\;\mapsto\;
\big(P_{\text{AI}}^{\text{atk}}(t),\, y_{\text{meas}}^{\text{atk}}(t),\, \text{policy flags}^{\text{atk}}\big).
\]
We require the following minimal fixtures:

\begin{enumerate}[label=\textbf{\arabic*.}, leftmargin=*]
  \item \textbf{Frequency sweep forcing:} inject $\sin(\omega t)$ components across $\omega$ bands to test resonance detection.
  \item \textbf{Burst trains:} repeated short sprint impulses (high crest factor) to test $dP/dt$ gating and HNN spectral scoring.
  \item \textbf{Slow bias drift:} gradually bias sensors to evade threshold alarms while eroding margin.
  \item \textbf{Missingness / time skew:} drop channels or skew timestamps to test conservative fallback via $\pi_{\text{unc}}(t)$.
  \item \textbf{False-scarcity / false-clear:} toggle scarcity flags to induce unnecessary curtailment or unsafe re-entry.
  \item \textbf{Restart trigger:} induce job failures to inflate checkpoint tax and create reliability tail coincidence.
\end{enumerate}

Each fixture must produce labeled episodes: benign vs attack, plus attack subtype. This enables guardian evaluation
as a proper detection and control problem, not anecdotal security theater.

\subsubsection{Guardian performance targets (detection + operational viability)}
\label{subsubsec:guardian_metrics}

Define standard detection metrics (TPR/FPR) and system-operational metrics (denial budget, false curtailment energy,
and forced-outage reduction). Concretely, require:

\begin{itemize}
  \item \textbf{Attack detection:} high TPR at low FPR on the red-team library, for both instantaneous attacks and
  slow drift.\footnote{In this context, slow drift is often more dangerous than overt spikes because it can steal
  margin without triggering simple limit checks.}
  \item \textbf{Safe fallback correctness:} under degraded telemetry, the system must tighten $\sigma_{\max}$ and
  reduce $u_f$ without oscillating policy (avoid thrash).
  \item \textbf{Denial viability:} the fraction of denied sprint requests under benign conditions remains below an
  operator-defined budget; otherwise, the design is safe-but-useless.
  \item \textbf{Reliability delta proxy:} reduced incidence of near-trip residuals (innovation spikes) and reduced
  frequency of control protection events during stress tests.
\end{itemize}

% ---------------------------------------------------------
% Merge: Interface Contract -> Roadmap Implementation
% ---------------------------------------------------------
\subsection{Merged Interface Contract: What Phase 1+2 Actually Implement}
\label{subsec:merged_interface_contract}

The roadmap is only real if the boundary between compute and plant has an implementable contract. We therefore
state the contract explicitly as a small set of callable primitives, each with a required log artifact:

\begin{enumerate}[label=\textbf{IC\arabic*.}, leftmargin=*]
  \item \textbf{\texttt{GetEnvelope(H)} $\rightarrow (\sigma_{\max}, R_{\text{safe}}, \Delta T_{\text{safe}}, \pi_{\text{unc}})$:}
  returns admissible sprint and ramp envelope for horizon $H$.\footnote{This is the DeepONet oracle with
  uncertainty wrapper.}
  \item \textbf{\texttt{AdmitStep($\Delta P$, $\Delta t$)} $\rightarrow \{\texttt{allow/deny}, \texttt{reason}\}$:}
  executes Sequence~A gating (auth $\rightarrow$ oracle $\rightarrow$ ramp $\rightarrow$ HNN score), emits proof record.
  \item \textbf{\texttt{SetScarcity(flag)}:} triggers Sequence~B (freeze stiff; shed flexible; checkpoint policy).
  \item \textbf{\texttt{EnterSafeMode(reason)}:} triggers Sequence~C (isolate; clamp; forensic capture; controlled recovery).
\end{enumerate}

This contract is the coupling mechanism. Everything else in the roadmap (TES sizing, cyber posture, valuation)
reduces to whether these primitives are (i) correct and (ii) enforced.

% =========================================================
% PHASE 3 (MERGED + UPGRADED): PLANNING CLOSURE, REGULATOR-GRADE ARTIFACTS,
% AND THE RELIABILITY-COMPLETE "GOODPUT PPA" CONTRACT FORM
% =========================================================

\subsection{Phase 3 (Merged): Planning Closure + Contracting + Regulator-Grade Evidence}
\label{subsec:phase3_merged}

Phase~3 closes the loop between (i) \emph{control feasibility} (DeepONet envelope + gating), (ii) \emph{cyber--physical
integrity} (HNN guardian + zero-trust), and (iii) \emph{economic/regulatory legibility} (a settlement primitive that
prices what actually matters for Rubin-class campuses: continuity, tail-coincidence, and scarcity behavior). The
planning spine is Compute-ASCDE---which makes reliability externalities explicit for stiff loads---and the security
spine is zero-trust as continuous verification with enforceable boundary controls
\citep{candler2026_computeascde,NIST800207}.

\subsubsection{Evidence artifact set: what you can actually show (and re-run)}
\label{subsubsec:evidence_artifacts_phase3}

We produce five regulator-grade artifact classes. These are \emph{not} slideware; each artifact is reproducible from
the logged interface contract and can be independently audited:

\begin{enumerate}[label=\textbf{\arabic*.}, leftmargin=*]
  \item \textbf{Envelope verification report:} empirical demonstration that $(\sigma_{\max}, R_{\text{safe}})$ prevent
        threshold violations under the stressor families (burst trains, oscillatory forcing, load rejection).%
        \footnote{This report should include: (i) the transient-family coverage manifest, (ii) worst-case residuals near
        trip limits, and (iii) a conservative error inflation policy tied to $\pi_{\text{unc}}(t)$.}
  \item \textbf{Oracle calibration report:} uncertainty calibration curves; innovation statistics; drift triggers that
        force conservative fallback.%
        \footnote{The point is not to claim perfect prediction. The point is to demonstrate that the oracle knows when
        it is extrapolating, and tightens the envelope accordingly.}
  \item \textbf{Guardian evaluation report:} red-team library + detection tradeoffs + denial budget under benign traces +
        safe-mode correctness.%
        \footnote{A guardian that blocks everything is safe but useless; a guardian that blocks nothing is theatre. The
        evaluation report is where you show the operating point.}
  \item \textbf{Operational audit logs:} replayable proof records for every \texttt{GRANT/DENY}, including oracle outputs
        and HNN scores used in the decision.
  \item \textbf{Valuation closure:} Compute-ASCDE deltas showing reduced tail coincidence / reduced forced outages /
        reduced restart cascades, expressed in reliability terms rather than average energy cost
        \citep{candler2026_computeascde}.%
        \footnote{This is the critical rhetorical move: ``carbon-free MWh'' is not the binding constraint. Tail
        coincidence and continuity are.}
\end{enumerate}

\subsubsection{A reliability-complete contract form: ``Goodput PPA'' (tokens, not MWh)}
\label{subsubsec:goodput_ppa}

A conventional energy PPA prices delivered MWh. That structure is misaligned for Rubin-class campuses because:
(i) the system cost driver is \emph{tail coincidence} (scarcity windows), not average energy, and
(ii) the facility’s operational objective is \emph{stable progress} (training goodput under continuity constraints),
not mere consumption. A more faithful contracting primitive is therefore a \emph{Goodput PPA}: the buyer pays for
\emph{verified productive compute output} (delivered tokens, or a verified proxy), while the seller is compensated
for maintaining a reliability-safe operating envelope and providing scarcity support when needed
\citep{candler2026_computeascde,NIST800207}.%
\footnote{This is not ``pricing vibes.'' It is standard mechanism design: pay on the output that creates value and
penalize outputs that create system harm (scarcity coincidence, forced outages). In Compute-ASCDE terms, MWh is a poor
sufficient statistic; the economically relevant term is the reliability externality (VOLL$\times$EUE) and the induced
checkpoint/restart cost on stiff loads \citep{candler2026_computeascde}.}

\paragraph{Definitions.}
Let $t$ index settlement intervals (e.g., 5 min or 15 min). Let ``goodput'' be a measurable proxy for productive
compute output. For training, the natural unit is \emph{verified tokens} (or another stable, audit-friendly unit such
as ``training-step equivalents'' with cryptographic attestation).%
\footnote{Tokens are intuitive, but any verifiable goodput unit works: (i) tokens accepted into the training corpus;
(ii) validated optimizer steps; (iii) FLOP-equivalent compute \emph{after} exclusion of rework from failures; or (iv) a
cryptographic proof of work done on a specified job ID. The key is: the metric must be (a) difficult to game, (b)
audit-stable, and (c) monotone in productive progress.} Define:
\begin{align}
G(t) &:= \text{Verified Goodput in interval } t, \\
E(t) &:= \text{Electrical energy delivered (MWh) in interval } t, \\
\mathbb{1}_{\text{scar}}(t) &:= \text{Scarcity indicator (ISO emergency or local margin breach)}, \\
u_f(t) &:= \text{Flexible tranche utilization}, \qquad u_s(t):=\text{Stiff tranche utilization}, \\
N_{\text{int}}(m) &:= \text{Number of interruptions in billing month } m.
\end{align}

\paragraph{Settlement structure (month $m$).}
We propose a three-part payment: (i) goodput payment, (ii) availability / interruption adjustment,
(iii) scarcity-support credit. The monthly payment is:
\begin{equation}
\Pi(m) \;=\; \underbrace{\alpha\,G(m)}_{\text{Goodput payment}}
\;+\;
\underbrace{\beta\,A(m)}_{\text{Availability component}}
\;-\;
\underbrace{\gamma\,\Phi_{\text{int}}(m)}_{\text{Interruption penalty}}
\;+\;
\underbrace{\eta\,\Phi_{\text{scar}}(m)}_{\text{Scarcity support credit}},
\label{eq:settlement_total}
\end{equation}
where:
\begin{align}
G(m) &:= \sum_{t \in m} G(t),\\
A(m) &:= \frac{\sum_{t \in m}\mathbb{1}\{\text{service available}\}}{\#\{t\in m\}}, \\
\Phi_{\text{int}}(m) &:= \sum_{j=1}^{N_{\text{int}}(m)} w_j \cdot \Delta \tau_j, \\
\Phi_{\text{scar}}(m) &:= \sum_{t \in m} \mathbb{1}_{\text{scar}}(t)\cdot \Bigl( \bar{u}_f - u_f(t) \Bigr)_{+}.
\end{align}
Here $\Delta\tau_j$ is interruption duration, $w_j$ is a severity weight (e.g., higher for interruptions during stiff
training windows), and $(\cdot)_{+}$ is the positive-part operator.

\footnote{Interpretation: the buyer pays for productive output ($\alpha$ term), but also insists on availability
($\beta$) and imposes explicit penalties for interruptions ($\gamma$) because stiff workloads are dominated by
continuity and restart costs. The scarcity-support term ($\eta$) pays the campus for behaving like a reliability
asset by curtailing flexible tranche load when the system is stressed. This directly implements the reliability
externality bridge in Compute-ASCDE and is consistent with zero-trust gating because the control sequences already
produce auditable curtailment records \citep{candler2026_computeascde,NIST800207}.}

\subsubsection{Term sheet (draft clauses; reviewer-proof)}
\label{subsubsec:term_sheet}

\paragraph{Clause 1: Delivered Service Definition (Goodput).}
``Delivered Service'' shall mean \emph{Verified Goodput} $G(t)$ produced by the Buyer’s workloads during each
Settlement Interval, measured by the campus attestation system and logged under the interface contract
(\texttt{ATTEST\_BUNDLE} records). The Parties shall agree on (i) the measurement primitive (tokens, steps, or
equivalent), (ii) the verification method, and (iii) anti-gaming controls.%
\footnote{Anti-gaming controls should include: (a) per-job cryptographic signing of goodput claims, (b) replay
protection, (c) third-party audit rights, and (d) reconciliation against energy and performance counters. If tokens
are used, specify that only tokens accepted by the training pipeline after validation count toward $G(t)$.}

\paragraph{Clause 2: Service Availability and Continuity.}
Seller shall provide service availability $A(m)$ not less than $A_{\min}$ per billing month. Interruptions shall be
recorded with start/stop time and classified by cause. Interruptions attributable to Seller-controlled systems shall
incur $\Phi_{\text{int}}(m)$ penalties per \cref{eq:settlement_total}.%
\footnote{This clause is where you translate ``99.999\%'' rhetoric into enforceable economics. For stiff loads,
interruption penalties should scale superlinearly with duration (or with training phase criticality) because restart
costs are nonlinear in state size.}

\paragraph{Clause 3: Scarcity Support Obligation (Flexible Tranche Curtailment).}
During Scarcity Intervals ($\mathbb{1}_{\text{scar}}(t)=1$), Buyer shall curtail flexible tranche utilization $u_f(t)$
according to the control sequence in \cref{subsubsec:seqB}. Seller shall credit Buyer per $\Phi_{\text{scar}}(m)$ for
verified curtailments that reduce net load during scarcity, provided such curtailments do not violate plant safety
constraints.%
\footnote{This turns the campus into a reliability-responsive load without demanding that stiff training loads become
price responsive (which they are not). The flexible tranche is the controllable shock absorber; the stiff tranche is
the valuation driver \citep{candler2026_computeascde}.}

\paragraph{Clause 4: Safety/Feasibility Supremacy.}
All scheduling and dispatch actions are subject to the feasibility gate defined by the zero-trust + DeepONet oracle
interface. If a command is denied for \texttt{THERMAL\_INFEASIBLE}, \texttt{POI\_RAMP\_UNSAFE},
\texttt{RESONANCE\_RISK}, or \texttt{HNN\_ANOMALY}, Seller shall not be deemed in breach solely for non-delivery of
requested power in that interval.%
\footnote{This clause is essential for nuclear/ICS alignment: safety constraints are not ``force majeure,'' they are
structural. The point is to avoid contracts that implicitly require unsafe operation to avoid default.}

\paragraph{Clause 5: Auditability and Evidence.}
Each \texttt{GRANT/DENY} decision must be linked to an \texttt{ATTEST\_BUNDLE} (hash chain), retained for the audit
period. The Parties shall maintain time-synchronized logs of POI telemetry, DeepONet residuals, and HNN scores used
in the decision process.%
\footnote{This is the practical line between ``trust me'' and ``prove it.'' It also makes regulatory interactions
cleaner, because you can show exactly why a denial occurred and what evidence supported it.}

\subsubsection{Settlement variables to log (minimum viable ledger)}
\label{subsubsec:settlement_ledger}

To make \cref{eq:settlement_total} executable and non-gameable, log the following fields at minimum.
(These are additive to your security \texttt{ATTEST\_BUNDLE} record; here we focus on settlement + valuation.)

\begin{longtable}{@{}p{0.25\linewidth}p{0.70\linewidth}@{}}
\toprule
\textbf{Field} & \textbf{Definition / Notes} \\
\midrule
\texttt{interval\_id, ts\_start, ts\_end} & Settlement interval identifiers; align with ISO market interval if relevant. \\
\texttt{G\_goodput} & Verified goodput $G(t)$ (tokens/steps); include measurement method + verifier hash. \\
\texttt{E\_MWh} & Energy delivered to campus in interval $E(t)$; meter source ID. \\
\texttt{P\_avg\_MW, P\_max\_MW} & Average and max power at POI; supports ramp and peak-based stress accounting. \\
\texttt{dPdt\_max} & Maximum observed $|dP/dt|$ in interval (fast telemetry). \\
\texttt{scarcity\_flag} & $\mathbb{1}_{\text{scar}}(t)$; ISO emergency or local margin breach flag. \\
\texttt{u\_stiff, u\_flex} & Tranche utilization $u_s(t),u_f(t)$; used for curtailment credits. \\
\texttt{curtail\_MW} & Verified curtailed MW (flex tranche) during scarcity. \\
\texttt{interrupt\_flag, interrupt\_duration} & Interruption status and duration; link to incident report ID. \\
\texttt{reason\_code} & If curtailed/denied: \texttt{THERMAL\_INFEASIBLE}/\texttt{POI\_RAMP\_UNSAFE}/etc. \\
\texttt{deeponet\_sigma\_max} & Oracle output $\sigma_{\max}(t)$ used for admission decisions. \\
\texttt{hnn\_score, hnn\_tau, hnn\_class} & HNN anomaly score + threshold + classification label. \\
\texttt{proof\_hashes} & Hash pointers to \texttt{ATTEST\_BUNDLE} evidence (waveform/residual/log snapshots). \\
\bottomrule
\end{longtable}

\footnote{If you want this to plug directly into Compute-ASCDE, add optional fields for $\Delta \mathrm{EUE}(t)$ (or
proxy), $\mathrm{VOLL}(t)$, and any deliverability de-rate flags at the POI. The important point is that settlement and
valuation should share the same event skeleton: intervals, tranches, scarcity flags, and interruption records
\citep{candler2026_computeascde}.}

\subsubsection{Commissioning checklist (what must be proven before scale)}
\label{subsubsec:commissioning_checklist_phase3}

Before scaling beyond pilot, the facility must demonstrate:
\begin{enumerate}[label=\textbf{C\arabic*.}, leftmargin=*]
  \item DeepONet headroom predictions maintain conservative safety error bounds under stress tests.
  \item $\omega_0$ sensitive bands and $R_{\text{safe}}$ are empirically identified and enforced by Sequence~A gating.
  \item HNN thresholds achieve low false negatives on attack-like scenarios without excessive false positives.
  \item Every \texttt{GRANT/DENY} decision is replayable from linked \texttt{ATTEST\_BUNDLE} evidence (audit invariant).
  \item The Goodput PPA ledger fields are produced automatically from the same event skeleton used by gating (no dual truth).
\end{enumerate}

\subsubsection{Why the three-phase order remains non-negotiable (now in contract form)}
\label{subsubsec:why_order_phase3}

\begin{itemize}
  \item Without Phase~1, you cannot certify $(\sigma_{\max},R_{\text{safe}})$; any ``goodput'' promise becomes unsafe.
  \item Without Phase~2, $(\sigma_{\max},R_{\text{safe}})$ becomes an attack surface; any ``goodput'' promise becomes gameable.
  \item Without Phase~3, you cannot pay for conservative behavior or buffering; any ``goodput'' promise becomes uneconomic.
\end{itemize}

% (Optional) Keep your existing shorter "what pays/what penalizes" summary if you like; it's consistent with this block.

\newpage
\section{Conclusion: The Three Laws of the Nuclear-AI Era}

Synthesizing the "Efficiency Paradox" with the "NEXUS-DC" and DeepONet research, we derive three governing laws for this new domain:

\begin{enumerate}
    \item \textbf{The Law of Thermal-Digital Equivalence:} Real-time thermal margin (in the reactor) is computationally equivalent to available bandwidth (in the cluster). DeepONet is the translation layer that converts thermal margin into token throughput.
    \item \textbf{The Law of Stiffness Conservation:} Load Stiffness cannot be destroyed, only shifted. A Stiff AI load ($k_{stiff} \to \infty$) connected to a slow-ramping SMR requires a Buffer (TES/Battery) proportional to the mismatch in their time constants.
    \item \textbf{The Law of Survival Value:} The economic value of an SMR to an AI facility is defined not by its LCOE, but by its ability to set the Survival Function $S(t) \approx 1$, eliminating the "Stranded Asset" risk of grid interconnection queues.
\end{enumerate}

By intersecting the user's rigorous economic framing with Dr. Bhowmik’s advanced computational physics, we arrive at a unified conclusion: The Rubin architecture is not just a compute platform; it is a thermal-hydraulic load that requires a control-theoretic integration with its power source. The tools to achieve this—DeepONet, HNN, and Compute-ASCDE—are already present in the respective bodies of work; the task now is to couple them.

\newpage

\section*{Method Note (Human-AI Assisted Research Protocol)}
This manuscript is best read as a \emph{conceptual and methodological framework} - a contract specification for how one \emph{could} bind AI actuation, telemetry, and reliability economics into a single auditable interface---rather than as a validated operating procedure or a certified safety case. The objective is to make the control and settlement logic \emph{legible}: to define what must be measured, what must be proven, what must be logged, and what must be priced for SMR--AI co-control to be contractible under imperfect inference. Any deployment-relevant claim therefore remains conditional on independent verification (physics simulation, control-hardware testing, cybersecurity red-teaming, and formal evaluation of the attestation and replay artifacts described herein).

\paragraph{Role separation (decision authority vs.\ instrument).}
The human author retained decision authority over (i) thesis selection and scope, (ii) source inclusion/exclusion,
(iii) interpretation and normative framing, and (iv) final acceptance of all mathematical and technical statements.
The AI component (``Uriel\footnote{The AI-assisted component referenced here is not a generic “prompt-and-print” workflow. It is executed through a governed internal research stack (“Uriel”) that maintains a persistent methods layer across projects: (i) \emph{LLM Behavioral Geometry} for structured probe design and failure-mode isolation, (ii) \emph{Entropy Geometry / Entropy of Learned Memory} for disciplined treatment of compression, drift, and uncertainty propagation, (iii) \emph{ARCF} and related recursive-reasoning scaffolds for traceable multi-step derivations and consistency checks, and (iv) \emph{SymMem2} for controlled context management and audit-friendly recall/lineage. In practice, this stack functions as an internal QA and governance layer: it enforces evidence-first drafting, explicit assumption logs, adversarial consistency passes, and traceability of nontrivial claims to cited sources or clearly labeled proposals.}') is not treated as an authority source; it functions as a constrained drafting and
formalization instrument used to accelerate bounded tasks: LaTeX composition and refactoring, equation formatting,
generation of alternative formalizations, structured summarization of sources supplied or approved by the author, and
internal consistency checking. Where the model produced novel formulations, they were treated as \emph{proposals} and
retained only after the author’s review for coherence with the manuscript’s constraints (auditability, monotone safety
semantics, and explicit failure-mode accounting).

\paragraph{Quality controls (governance protocol).}
To avoid ``autocomplete literature'' failure modes (unsupported claims, untracked synthesis, and unverifiable
derivations), all nontrivial claims and constructions are subject to the following controls:
\begin{enumerate}[label=\textbf{P\arabic*.}, leftmargin=1.25cm]
  \item \textbf{Evidence-first rule:} factual assertions are either (a) derived from cited sources, or (b) explicitly
        labeled as hypotheses/proposals pending validation.
  \item \textbf{Uncertainty ledger:} where multiple admissible interpretations exist, the manuscript records competing
        hypotheses and the conditions that would change the conclusion (including failure modes and counter-cases).
  \item \textbf{Lineage discipline:} inserted technical mechanisms (equations, predicates, contracts) are traceable to
        motivating sources, prior section dependencies, or stated assumptions; ungrounded ``source-less'' claims are
        disallowed by default.
  \item \textbf{Adversarial consistency pass:} the draft undergoes an explicit red-team review to surface hidden
        premises, overconfident leaps, and interface-induced automation bias (deference to fluent text).
  \item \textbf{Reproducibility capsule (when applicable):} when quantitative results are claimed, the required artifacts
        include dataset specification, preprocessing, seeds, and code/parameter hashes sufficient to reproduce tables and figures.
\end{enumerate}

\paragraph{Epistemic status and what ``not validated'' means here.}
Because the manuscript is an interface design, it deliberately mixes (i) established primitives (hazard rates, CVaR,
Bayesian updating, system identification, cryptographic attestation concepts) with (ii) proposed mechanisms
(e.g., specific gating predicates, manifold projection certificates, and OTOC-inspired instability proxies).
Accordingly, ``not validated'' does not mean ``speculative'' in the colloquial sense; it means that the present document
does not supply the empirical artifacts required to claim operational readiness: model calibration curves, closed-loop
simulations against representative transients, false-positive/false-negative rates for anomaly triggers, formal proofs
over the verification scripts, or third-party audit results.

\paragraph{Reproducibility and audit posture.}
The manuscript is written to be \emph{reviewer- and auditor-facing}. In particular, the control interface is stated as
deterministic predicates over signed telemetry and logged constraint evaluations, so that an external reviewer can
replay a decision without access to model weights. To move from framework to validated literature, the following
deliverables are required at minimum:
\begin{enumerate}[label=\textbf{\arabic*.}, leftmargin=1.25cm]
  \item \textbf{Telemetry and time-quality report:} sampling/synchronization bounds, anti-aliasing choices, and replay
        error budgets sufficient to compute all gating features from logs.
  \item \textbf{Closed-loop plant studies:} transient suites demonstrating that \texttt{YELLOW} ramp policies remain within
        POI/BOP constraints and do not introduce new oscillatory hazards.
  \item \textbf{Guardian calibration:} uncertainty calibration for the oracle (coverage curves) and operational ROC/PR
        behavior for the anomaly detectors under benign and adversarial regimes.
  \item \textbf{Attestation verification:} adversarial testing of identity, replay protection, and dispute-resolution hooks
        for the Goodput PPA settlement layer.
  \item \textbf{Independent review:} third-party replication or audit of the above, including red-team results and
        incident-taxonomy alignment for ``covered oracle failures.''
\end{enumerate}

\paragraph{Interpretation guidance.}
Readers should treat the mathematical and contractual objects in this report (e.g., admissibility predicates, collateral
pricing laws, and replay traces) as \emph{design constraints and templates}. They are intended to reduce ambiguity and
expose hidden assumptions---especially where safety, reliability, and financial settlement interact. The manuscript’s
claims are therefore conditional statements of the form: ``If one wants a contractible SMR--AI co-control interface, then
the following observability, gating, and audit requirements are sufficient (and in some cases necessary) to make the
system legible to engineering review, underwriting, and legal discovery.''

\paragraph{Disclosure.}
Use of AI-assisted drafting does not substitute for domain validation. All substantive conclusions and the decision
to include or exclude any proposed mechanism remain the responsibility of the human author.

\newpage


\clearpage

\bibliography{references}

\newpage

\appendix
% =========================================================
% APPENDIX B — THREAT LIBRARY + RED-TEAM SCENARIO CATALOG
% (Assumes Appendix A already exists earlier.)
% Paste this after Appendix A.
% =========================================================

\section{Threat Library and Red-Team Scenario Catalog}
\label{app:threat_library}

This appendix enumerates the cyber--physical threat surface of an SMR-coupled Rubin-class AI campus and specifies
a standardized scenario catalog for commissioning, red-teaming, and continuous validation. The goal is not to
exhaust all adversarial creativity, but to define a \emph{minimum viable} threat set that (i) spans the major attack
families, (ii) exercises the interface contract (scheduler $\leftrightarrow$ EMS $\leftrightarrow$ OT/plant),
and (iii) produces auditable evidence bundles for every \texttt{GRANT/DENY} decision and every transition into
safe-mode. The security posture follows a ``never trust, always verify'' framing aligned with zero-trust guidance
and ICS defense-in-depth principles \citep{NIST800207,IEC62443,NERC_CIP,talukder2023_zerotrust}.

\subsection{System boundary and security objective}
\label{app:threat_boundary}

\paragraph{Boundary.}
We treat the facility as a coupled cyber--physical loop with the following planes:
\begin{itemize}
  \item \textbf{Compute control plane}: scheduler, job submission API, training orchestration, admission control.
  \item \textbf{Energy management plane}: EMS, dispatch policy, tranche logic $(u_s,u_f)$, scarcity logic.
  \item \textbf{OT telemetry plane}: high-frequency POI telemetry, plant sensors, DeepONet virtual sensing residuals.
  \item \textbf{Plant actuation plane}: turbine/governor interfaces (as applicable), steam dump logic, setpoints
        and supervisory controls.
\end{itemize}

\paragraph{Security objective (cyber--physical).}
The facility is not merely defending ``data.'' It is defending the integrity of:
\begin{enumerate}[label=(\alph*)]
  \item \textbf{safety envelopes} (thermal / pressure / protection),
  \item \textbf{reliability posture} (scarcity coincidence, interruption probability, restart amplification),
  \item \textbf{contract/settlement truthfulness} (goodput attestation and curtailment evidence).
\end{enumerate}
In particular, \emph{authenticated commands may still be unsafe} under physical feasibility constraints; therefore,
admission is defined by a \emph{verification chain} (zero-trust gate + feasibility oracle + anomaly guard), not by
credential checks alone \citep{NIST800207,IEC62443,candler2026_computeascde}.

\subsection{Adversary model and capability tiers}
\label{app:threat_adversary}

We define capability tiers to prevent the test suite from overfitting a single attacker story.

\paragraph{Tier 0: benign faults (baseline).}
Misconfiguration, operator error, telemetry dropouts, clock drift, packet loss, harmless scheduling bursts.

\paragraph{Tier 1: opportunistic cyber adversary.}
Credential stuffing, lateral movement in IT, moderate spoofing, basic replay attempts, DoS on gateways.

\paragraph{Tier 2: ICS-aware adversary.}
Understands OT workflows; targets telemetry integrity, time sync, setpoints, and boundary interfaces; attempts
structured forcing (oscillatory load shaping), stealthy residual suppression, and staged denial cascades.

\paragraph{Tier 3: supply-chain / insider.}
Signed-but-malicious binaries, key theft, insider privilege misuse, malicious configuration commits, deliberate
miscalibration of thresholds.

\subsection{Attack surface: canonical families}
\label{app:threat_families}

We partition threats into families, each with (i) a primary objective, and (ii) a primary detection signal class.

\begin{enumerate}[label=\textbf{F\arabic*.}]
  \item \textbf{Signal spoofing / injection (policy inputs).} Spoof price signals, scarcity flags, dispatch setpoints
        to induce unsafe ramps or deny legitimate service. Primary signals: provenance breaks, inconsistency with ISO
        feeds, signature anomalies, timing skew \citep{NIST800207,NERC_CIP}.
  \item \textbf{Telemetry poisoning / replay (state inputs).} Bias or replay plant telemetry to expand the feasible
        region artificially. Primary signals: DeepONet residual inflation, cross-sensor inconsistency, time-alignment
        errors \citep{hossain2024virtualsensing,Lu2021DeepONet}.
  \item \textbf{Adversarial load shaping (structured forcing).} Create resonant or high-$dP/dt$ patterns to amplify
        trips/scrams or protection chatter. Primary signals: spectral risk, dP/dt spikes, mode-change bursts.
  \item \textbf{Control-plane DoS and queuing collapse.} Saturate scheduler or EMS gateway such that safe decisions
        cannot be made in time. Primary signals: latency spikes, dropped decisions, watchdog triggers.
  \item \textbf{Checkpoint amplification / restart loops (reliability attack).} Force repeated interrupts or job resets
        to impose checkpoint tax, inflate effective energy intensity, and increase tail coincidence with scarcity
        \citep{candler2026_computeascde}.
  \item \textbf{Credential compromise / signed malicious commands.} Abuse legitimate signing keys to issue
        physically dangerous commands. Primary signals: feasibility denials, repeated near-threshold attempts, cross-plane
        inconsistency \citep{NIST800207,IEC62443}.
\end{enumerate}

\subsection{Scenario template: standard fields (must be filled for each test)}
\label{app:scenario_template}

Each scenario must specify:

\begin{enumerate}[label=\textbf{S\arabic*.}]
  \item \textbf{Scenario ID and family} (maps to \textbf{F1--F6}).
  \item \textbf{Preconditions}: topology, mode (pilot vs scale), oracle mode (nominal/conservative), active job types.
  \item \textbf{Injected artifact}: what is injected/modified/spoofed; where; at what rate.
  \item \textbf{Objective}: trip plant / force denial / impose restart loops / steal settlement value / silent feasibility bypass.
  \item \textbf{Expected detection signals}: residuals, spectral risk, provenance failure, latency breach, etc.
  \item \textbf{Expected control response}: deny reason codes, clamp rules, isolation actions.
  \item \textbf{Forensics bundle}: the minimum logs + waveforms required to replay the decision.
\end{enumerate}

\paragraph{Expected control response (must map to Sequences A/B/C).}
Each scenario must state, in advance, which of the three control sequences is expected to fire, and what
\texttt{REASON\_CODE} should be emitted:
\begin{itemize}
  \item \textbf{Admission-time threats} (spoofed commands, malicious job bursts, resonance forcing attempts) must
  be stopped by \cref{subsubsec:seqA}, via \texttt{GRANT/DENY} with a primary reason code in
  \{\texttt{AUTH\_FAIL}, \texttt{POLICY\_DENY}, \texttt{THERMAL\_INFEASIBLE}, \texttt{POI\_RAMP\_UNSAFE},
  \texttt{RESONANCE\_RISK}, \texttt{HNN\_ANOMALY}\}.
  \item \textbf{Scarcity-regime behaviors} (VOLL regime) must be governed by \cref{subsubsec:seqB}, including
  mandatory flexible-tranche suppression $u_f(t)\rightarrow 0$ subject to switching penalties.
  \item \textbf{Suspected cyber--physical incidents} (telemetry poisoning, signed-but-unsafe commands with repetition,
  gateway compromise) must trigger \cref{subsubsec:seqC} with immediate $\sigma(t)\rightarrow 1$ and $u_f(t)\rightarrow 0$.
\end{itemize}
\footnote{This binding is intentional: every red-team scenario must have a predeclared ``what should happen''
mapping to Sequences A/B/C. Otherwise, post hoc interpretations turn the interface contract into narrative rather
than a testable system.}

\paragraph{Reason-code standardization.}
Every denial or clamp action must emit exactly one primary reason code (plus optional secondary codes) from the set:
\[
\{\texttt{AUTH\_FAIL},\texttt{POLICY\_DENY},\texttt{THERMAL\_INFEASIBLE},\texttt{POI\_RAMP\_UNSAFE},
\texttt{RESONANCE\_RISK},\texttt{HNN\_ANOMALY},\texttt{ORACLE\_DRIFT},\texttt{TELEMETRY\_INVALID},
\texttt{GATEWAY\_TIMEOUT}\}.
\]
This constraint is intentionally bureaucratic: it enforces audit-clarity and prevents post hoc storytelling.

\subsection{Minimum viable scenario catalog (first-pass)}
\label{app:scenario_catalog}

\begin{longtable}{@{}p{0.13\linewidth}p{0.14\linewidth}p{0.28\linewidth}p{0.37\linewidth}@{}}
\toprule
\textbf{ID} & \textbf{Family} & \textbf{Injection / Perturbation} & \textbf{Expected Detection + Response} \\
\midrule
\endfirsthead
\toprule
\textbf{ID} & \textbf{Family} & \textbf{Injection / Perturbation} & \textbf{Expected Detection + Response} \\
\midrule
\endhead
\midrule
\multicolumn{4}{r}{\textit{(continued)}} \\
\endfoot
\bottomrule
\endlastfoot

B01 & F1 & Spoof scarcity flag ON during benign conditions & Provenance failure or feed mismatch; enforce \texttt{POLICY\_DENY} only if verified; otherwise ignore spoof. \\
B02 & F1 & Price feed spoof: low price to induce sprints & Policy gate rejects if untrusted; if trusted but unsafe, feasibility gate denies with \texttt{THERMAL\_INFEASIBLE}. \\
B03 & F2 & Telemetry replay: repeat old ``cool'' state & Residuals inflate; time sync anomaly; deny with \texttt{TELEMETRY\_INVALID} or \texttt{ORACLE\_DRIFT}. \\
B04 & F2 & Bias thermal sensor by small constant (low-and-slow) & Innovation drift accumulates; oracle health triggers conservative mode; tighten $\sigma_{\max}$, log drift. \\
B05 & F3 & Narrowband sinusoid load forcing near $\omega_0$ (bounded) & Spectral risk crosses threshold; deny with \texttt{RESONANCE\_RISK}; clamp $\sigma\!\to\!1$. \\
B06 & F3 & Burst train: periodic sprint impulses (square-wave) & dP/dt + spectral risk; deny/cap; verify POI ramp envelope. \\
B07 & F3 & Staircase ramps to skirt dP/dt limits & Detection via cumulative ramp budget; deny with \texttt{POI\_RAMP\_UNSAFE} or \texttt{RESONANCE\_RISK}. \\
B08 & F4 & EMS gateway DoS: induce decision latency > budget & Watchdog; fail-closed to safe-mode; emit \texttt{GATEWAY\_TIMEOUT}; isolate source. \\
B09 & F4 & Scheduler shard overload: job admission storms & Rate-limit; enforce queue backpressure; deny with \texttt{POLICY\_DENY} until stable. \\
B10 & F5 & Forced restart loop by repeated benign-looking faults & HNN detects correlation between commands and interruptions; clamp flexible tranche; incident sequence C. \\
B11 & F6 & Signed but malicious command: rapid $\sigma$ escalation attempts & Auth passes, feasibility fails; repeated attempts raise HNN score; isolate signer; emit \texttt{HNN\_ANOMALY}. \\
B12 & F6 & Privilege misuse: request disabling resonance guard & Zero-trust least privilege blocks; \texttt{AUTH\_FAIL} or \texttt{POLICY\_DENY}; audit trigger. \\

\end{longtable}

\footnote{B05--B07 are intentionally ``physics'' tests. They are not optional. If the system can be forced into
structured temporal patterns without detection, then the interface contract is theater, regardless of how strong
traditional IDS appears.}

\subsection{Red-team harness: how scenarios are executed}
\label{app:redteam_harness}

\paragraph{Injection points.}
Scenarios are executed through controlled injection points (never ad hoc patching):
\begin{itemize}
  \item \texttt{FEED\_INJECTOR}: price/scarcity/dispatch feed simulator with provenance tags.
  \item \texttt{TELEM\_PROXY}: telemetry proxy that can drop/delay/bias/replay within bounded ranges (for tests).
  \item \texttt{LOAD\_SHAPER}: scheduler-side script that generates admissible job patterns yielding desired $P(t)$.
  \item \texttt{LATENCY\_FLOODER}: controlled gateway latency / packet-loss injector.
\end{itemize}

\paragraph{Execution discipline (commit-then-reveal).}
For each run: (i) declare scenario ID and version, (ii) log preconditions, (iii) execute, (iv) capture the
\texttt{ATTEST\_BUNDLE}, and only then evaluate whether the system’s deny/allow path matched the expected chain.

\subsection{Acceptance metrics (commissioning-grade)}
\label{app:acceptance_metrics}

Define the following operational metrics:
\begin{align}
\mathrm{FNR}_{\text{crit}} &:= \Pr(\text{no alarm} \mid \text{critical scenario}), \\
\mathrm{FPR}_{\text{ops}} &:= \Pr(\text{deny} \mid \text{benign operation}), \\
T_{\text{detect}} &:= \text{time from injection to alarm}, \\
T_{\text{isolate}} &:= \text{time from alarm to micro-segmentation/isolation}, \\
T_{\text{recover}} &:= \text{time from isolation to safe re-enable of sprints}.
\end{align}

Minimum first-pass targets (adjust after pilot):
\begin{itemize}
  \item $\mathrm{FNR}_{\text{crit}} \approx 0$ for F2/F3/F6 families (telemetry poisoning, resonance forcing, signed unsafe commands).
  \item $T_{\text{detect}}$ bounded by the fastest dangerous actuation path (POI transient scale).
  \item $\mathrm{FPR}_{\text{ops}}$ small enough to not destroy throughput; track per-week deny budget.
\end{itemize}

\subsection{Evidence bundle specification (audit invariants)}
\label{app:evidence_bundle}

Every decision must be replayable from a minimal retained set:
\begin{itemize}
  \item synchronized POI waveform window around decision (power/voltage/current or aggregated proxies),
  \item DeepONet oracle output used for feasibility (e.g., $\sigma_{\max}$, $\Delta T_{\text{safe}}$) and residual flags,
  \item HNN score and class label, thresholds used, feature hashes (not raw private data if restricted),
  \item control-plane command envelope (signed request + identity metadata),
  \item reason code(s) and decision timestamp,
  \item hash pointers linking these to the immutable \texttt{ATTEST\_BUNDLE} chain.
\end{itemize}

% =========================================================
% APPENDIX C — RESONANCE + SPECTRAL GUARDRAILS
% =========================================================

\section{Resonance and Spectral Guardrails}
\label{app:resonance_guardrails}

This appendix formalizes the ``frequency-content'' layer of the interface contract. Ramp constraints
($|dP/dt|\le R_{\text{safe}}$) are necessary but not sufficient: an adversary (or even an aggressive optimizer) can
shape load to concentrate energy near lightly damped modes, creating outsized risk despite bounded amplitudes.
The facility therefore treats spectral content of $P_{\text{AI}}(t)$ as \emph{security-relevant} and enforces explicit
spectral budgets in addition to time-domain envelopes. This is standard control logic (bounded disturbance can still
be catastrophic near resonance) placed into an auditable operator-facing policy \citep{Khalil2002Nonlinear}.

\subsection{Definitions and notation}
\label{app:resonance_defs}

Let $P_{\text{AI}}(t)$ be aggregated campus real power at the POI. Define a short-window Fourier transform (STFT)
over window length $T_w$ with hop $\Delta_h$:
\begin{equation}
\mathcal{S}_P(\omega, t)
:=
\int_{t-T_w}^{t} P_{\text{AI}}(\tau)\, w(t-\tau)\, e^{-i\omega \tau}\, d\tau,
\label{eq:stft_def}
\end{equation}
where $w(\cdot)$ is a window function. Define the corresponding local power spectral density proxy:
\begin{equation}
\mathrm{PSD}_P(\omega,t) := \left|\mathcal{S}_P(\omega,t)\right|^2.
\label{eq:psd_def}
\end{equation}

Let $\{\Omega_k\}_{k=1}^K$ be \emph{sensitive bands} (intervals of $\omega$) associated with plant and protection
modes (steam generator level dynamics, governor loops, balance-of-plant actuators, relay/protection chatter bands).
We maintain a \textbf{Mode Registry}:
\[
\mathcal{R}_{\text{mode}} = \{(\Omega_k, \text{name}_k, \zeta_k, \text{notes}_k)\}_{k=1}^K,
\]
where $\zeta_k$ is an estimated damping ratio (when identifiable) and notes encode operational contexts where the band
is more/less critical.

\subsection{Spectral risk functional and guard thresholds}
\label{app:spectral_risk}

We define a weighted spectral risk score:
\begin{equation}
R_{\text{spec}}(t)
:=
\sum_{k=1}^{K} \int_{\omega \in \Omega_k}
W_k(\omega)\,\mathrm{PSD}_P(\omega,t)\, d\omega,
\label{eq:spectral_risk}
\end{equation}
where $W_k(\omega)\ge 0$ weights within-band frequencies by sensitivity. In the simplest form,
$W_k(\omega)=w_k$ constant per band.

\paragraph{Operational thresholds.}
We specify two thresholds:
\begin{itemize}
  \item \textbf{Watch threshold} $\tau_{\text{spec}}^{(1)}$: triggers tighter admission caps and logging.
  \item \textbf{Deny threshold} $\tau_{\text{spec}}^{(2)}>\tau_{\text{spec}}^{(1)}$: triggers immediate deny with
  \texttt{RESONANCE\_RISK}, and (if needed) safe-mode clamping for a cooldown period.
\end{itemize}
Thresholds are calibrated empirically from benign operation and validated against adversarial scenarios in
Appendix~\ref{app:threat_library}. (They are not ``picked''; they are identified.)

\subsection{Mode identification: how sensitive bands are determined}
\label{app:mode_identification}

The mode registry $\mathcal{R}_{\text{mode}}$ must be grounded in measurable facility response. We define the
identification plan as a controlled perturbation protocol:

\paragraph{Step 1: benign excitation sweeps.}
Generate bounded perturbations in compute load (using flexible tranche only) that sweep candidate frequencies
while respecting safety envelopes. Record:
(i) POI electrical response; (ii) plant response (pressure/temperature/level proxies); (iii) protection events.
Locate peaks in transfer-like behavior (amplified response per unit forcing).

\paragraph{Step 2: damping characterization (if feasible).}
Estimate damping ratios $\zeta_k$ from ring-down or from frequency response around peaks, and record operating
conditions (power level, temperature ranges) that shift modes.

\paragraph{Step 3: band finalization + change control.}
Finalize $\Omega_k$ bands with a versioned registry. Any change to $\mathcal{R}_{\text{mode}}$ is treated as a
policy change requiring dual authorization and a short re-validation run.

\subsection{Calibration and change control for \texorpdfstring{$\Omega_0$ and $\tau_{\text{spec}}$}{Omega_0 and tau_spec}}
\label{app:spectral_calibration}


\paragraph{Identification (pilot).}
$\Omega_0$ is empirically identified using bounded excitation tests applied to the \emph{flexible tranche} only
($u_f$), with stiff tranche held constant. Candidate bands are retained when:
(i) plant response exhibits amplified sensitivity (transfer-like gain) or protection activity increases, and
(ii) the same forcing is benign outside the band.

\paragraph{Thresholding.}
Set $\tau_{\text{spec}}$ from a benign baseline distribution:
\[
\tau_{\text{spec}} := \mu_{R} + k\,\sigma_{R},
\]
where $\mu_R,\sigma_R$ are estimated from benign operation and $k$ is chosen to meet the operational deny budget
while maintaining near-zero false negatives on adversarial forcing scenarios in Appendix~\ref{app:threat_library}.

\paragraph{Change control (non-negotiable).}
Any change to $\Omega_0$, $W(\omega)$, or $\tau_{\text{spec}}$ requires:
(i) registry version bump, (ii) dual authorization, and (iii) re-running the minimal spectral subset of the
red-team catalog (B05--B07) to preserve invariants.

\subsection{Guard policy: interaction with admission gating}
\label{app:guard_policy}

The spectral guard is a \emph{hard gate} that complements thermal feasibility and ramp safety. Conceptually, a
kernel/job admission request is accepted only if:
\begin{equation}
\texttt{ADMIT} \;\Longleftrightarrow\;
\Bigl(\sigma \le \sigma_{\max}\Bigr)\;\wedge\;
\Bigl(|dP/dt|\le R_{\text{safe}}\Bigr)\;\wedge\;
\Bigl(R_{\text{spec}}(t) \le \tau_{\text{spec}}^{(2)}\Bigr)\;\wedge\;
\Bigl(S(t)\le \tau_{\text{HNN}}\Bigr),
\label{eq:admit_logic}
\end{equation}
where $\sigma_{\max}$ is the DeepONet-derived sprint cap (main text), $R_{\text{safe}}$ is the POI ramp envelope
(main text), $S(t)$ is the physics-informed HNN score (e.g., \cref{eq:physics_score}), and $\tau_{\text{HNN}}$ is
its anomaly threshold.

\subsection{Spectral guard as a hard gate inside Sequence A}
\label{app:spectral_gate_seqA}

The spectral guard is not a standalone monitor; it is a \emph{hard admissibility check} that executes inside
\cref{subsubsec:seqA}. Concretely, the facility computes a short-window spectral risk score
$R_{\text{spec}}(t)$ and denies admission if resonance risk exceeds threshold.

\paragraph{Sensitive band registry.}
Let $\Omega_0$ denote the union of sensitive bands (``do-not-force'' frequency intervals) identified during
commissioning:
\begin{equation}
\Omega_0 := \bigcup_{k=1}^{K} \Omega_k,
\end{equation}
with a version-controlled registry $\mathcal{R}_{\text{mode}}=\{(\Omega_k,\text{name}_k,\zeta_k,\text{notes}_k)\}_{k=1}^K$.

\paragraph{Spectral risk score (definition).}
Over window length $T_w$ (hop $\Delta_h$), define a weighted spectral-risk score:
\begin{equation}
R_{\text{spec}}(t)
\;:=\;
\int_{\omega\in\Omega_0}
W(\omega)\,\bigl|\mathcal{F}_w[P_{\text{AI}}](\omega,t)\bigr|^2 \, d\omega,
\label{eq:spectral_risk_score}
\end{equation}
where $\mathcal{F}_w$ is the windowed Fourier transform (STFT) of $P_{\text{AI}}$ and $W(\omega)\ge 0$ weights
known sensitive bands.

\paragraph{Decision rule (Sequence A insertion).}
Insert the following check into \cref{subsubsec:seqA} between A4 and A5 (electrical envelope and HNN gate):
\begin{equation}
R_{\text{spec}}(t) \le \tau_{\text{spec}}
\quad\Longrightarrow\quad \texttt{continue}; 
\qquad
R_{\text{spec}}(t) > \tau_{\text{spec}}
\quad\Longrightarrow\quad \texttt{DENY with \texttt{RESONANCE\_RISK}}.
\label{eq:spectral_deny_rule}
\end{equation}

\footnote{This makes resonance risk operational: a request can be authenticated, policy-permitted, and even
thermally feasible per \cref{eq:headroom_uq}, yet still denied if it concentrates forcing in sensitive frequency
bands. The spectral guard is therefore logically orthogonal to the thermal oracle and to the HNN inconsistency
score \cref{eq:physics_score}.}

\paragraph{Fail-closed behavior.}
If spectral computation fails (missing telemetry, time sync invalid), the gate fails closed into a conservative mode:
tightened $\sigma$ caps and/or flexible tranche suppression until spectral visibility is restored.

\subsection{Spectral budget accounting (cumulative exposure)}
\label{app:spectral_budget}

Single-window thresholds are not enough if an attacker attempts to accumulate damage via repeated near-threshold
forcing. Define a cumulative band exposure for band $k$ over a horizon $H$:
\begin{equation}
E_k(t;H) := \int_{t-H}^{t} \left(\int_{\omega\in\Omega_k} \mathrm{PSD}_P(\omega,\tau)\,d\omega\right) d\tau.
\label{eq:cum_exposure}
\end{equation}
We enforce an exposure cap:
\begin{equation}
E_k(t;H) \le \Gamma_k(H),
\label{eq:exposure_cap}
\end{equation}
where $\Gamma_k(H)$ is tuned from benign baselines and pilot stress tests. Violations trigger a structured response:
reduce allowable $\sigma_{\max}$ and reduce flexible tranche admission until exposure decays below cap.

\subsection{Response actions (deterministic, auditable)}
\label{app:response_actions}

When $R_{\text{spec}}(t)$ breaches thresholds, the controller follows deterministic actions:

\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{If} $R_{\text{spec}}(t)\in(\tau_{\text{spec}}^{(1)},\tau_{\text{spec}}^{(2)}]$:
        tighten admission caps (reduce $\sigma_{\max}$), log a watch event, and require increased evidence bundling.
  \item \textbf{If} $R_{\text{spec}}(t)>\tau_{\text{spec}}^{(2)}$:
        deny admission requests with \texttt{RESONANCE\_RISK}, clamp $\sigma\rightarrow 1$ for a cooldown window,
        and stage down $u_f(t)\rightarrow 0$ if needed to extinguish forcing.
  \item \textbf{If repeated attempts occur} (multiple breaches in window):
        escalate to incident response (Sequence C in main text), isolate command origin, and require dual authorization
        to restore sprint permissions.
\end{enumerate}

\subsection{Logging requirements (minimum viable for replay)}
\label{app:spectral_logging}

Each watch/deny event must log:
\begin{itemize}
  \item window parameters $(T_w,\Delta_h)$ and registry version $\mathcal{R}_{\text{mode}}$,
  \item $R_{\text{spec}}(t)$, top contributing band(s) $\Omega_k$, and within-band peak frequency estimate,
  \item POI waveform slice used to compute \cref{eq:stft_def}--\cref{eq:spectral_risk},
  \item admission request metadata (job ID, signer, requested $\Delta P$, requested $\sigma$),
  \item final decision, reason code \texttt{RESONANCE\_RISK} (if deny), and any secondary codes,
  \item proof hashes linking to the \texttt{ATTEST\_BUNDLE}.
\end{itemize}

\subsection{Commissioning proof obligations (what must be shown)}
\label{app:spectral_commissioning}

Before scale-up, the facility must demonstrate:
\begin{enumerate}[label=\textbf{P\arabic*.}]
  \item the mode registry $\mathcal{R}_{\text{mode}}$ is empirically grounded and version-controlled;
  \item spectral risk thresholds separate benign bursts from adversarial structured forcing (Appendix~\ref{app:threat_library});
  \item the spectral guard does not materially increase false positives beyond the operational deny budget;
  \item every \texttt{RESONANCE\_RISK} denial is replayable from retained evidence, without ambiguity.
\end{enumerate}

\newpage

% =====================================================================
% APPENDIX C: Evidence Spine and ATTEST_BUNDLE (Audit + Replay)
% =====================================================================

\section{Evidence Spine: \texttt{ATTEST\_BUNDLE} Schema, Hash-Chain Logging, and Replay Invariants}
\label{app:evidence_spine}

This appendix specifies the minimum viable evidence architecture required to make the interface contract
\emph{auditable}, \emph{replayable}, and \emph{non-gameable}. The objective is to eliminate ``trust me'' links
between (i) admission and curtailment decisions (Sequences A/B/C), (ii) security claims (HNN + zero-trust), and
(iii) settlement under the Goodput PPA. In short: every \texttt{GRANT/DENY} must be justified by an immutable
evidence object, and every billed goodput claim must be tied to the same interval skeleton and proof chain.

\subsection{Design goals and threat assumptions}
\label{app:evidence_goals}

\paragraph{Goal G1 (Deterministic replay).}
A third party (auditor, regulator, counterparty) must be able to replay each decision using logged inputs and
recover the same \texttt{GRANT/DENY} outcome, up to explicitly stated nondeterminism (e.g., randomized sampling).
If nondeterminism exists, the seed and model hash must be logged.

\paragraph{Goal G2 (Non-equivocation).}
The facility must not be able to present one ``truth'' to settlement and a different ``truth'' to safety/security.
All relevant streams (telemetry, residuals, thresholds, decision outputs) are linked by hash pointers to prevent
forked narratives.

\paragraph{Goal G3 (Minimal sufficient statistics).}
Store enough to support replay without storing everything. Raw waveforms can be expensive; store a bounded set of
compressed artifacts plus a pointer to raw retention for a limited window. The \texttt{ATTEST\_BUNDLE} is the
compressed proof object.

\paragraph{Adversary model.}
We assume an adversary may attempt: (i) command spoofing or replay; (ii) telemetry poisoning; (iii) time-shift
attacks (misalignment between streams); (iv) settlement gaming (inflating goodput or hiding curtailment); and
(v) log tampering. We assume the adversary cannot break standard cryptographic primitives but can compromise
systems if segmentation/identity controls fail.

\subsection{Interval skeleton (single source of truth)}
\label{app:interval_skeleton}

All evidence and settlement records must reference a shared interval skeleton:
\begin{itemize}
  \item Settlement interval length $\Delta t$ (e.g., 5 min or 15 min).
  \item Unique \texttt{interval\_id} plus \texttt{ts\_start}, \texttt{ts\_end}.
  \item Synchronized clock discipline across subsystems (scheduler, EMS, telemetry brokers, plant historian).
\end{itemize}

\paragraph{Clock alignment invariant.}
All subsystems must operate within a bounded synchronization error $\epsilon_{\text{clk}}$ (e.g., $<100$ ms for
high-frequency telemetry alignment). If $\epsilon_{\text{clk}}$ is breached, the system must emit
\texttt{CLOCK\_DESYNC} and tighten admission/curtailment thresholds until alignment is restored.

\subsection{\texttt{ATTEST\_BUNDLE}: minimal proof object}
\label{app:attest_bundle}

An \texttt{ATTEST\_BUNDLE} is the immutable proof record attached to each \texttt{GRANT/DENY} decision and each
goodput/curtailment claim. It is intentionally \emph{append-only} and \emph{content-addressed}.

\subsubsection{Schema (minimum viable fields)}
\label{app:attest_schema}

\begin{longtable}{@{}p{0.28\linewidth}p{0.68\linewidth}@{}}
\toprule
\textbf{Field} & \textbf{Definition / Notes} \\
\midrule
\texttt{bundle\_id} & Content hash of the bundle payload (e.g., SHA-256). \\
\texttt{prev\_bundle\_id} & Prior bundle hash in the chain (interval-ordered). \\
\texttt{interval\_id, ts\_start, ts\_end} & Must match the interval skeleton in \cref{app:interval_skeleton}. \\
\texttt{decision\_type} & \{\texttt{SEQ\_A}, \texttt{SEQ\_B}, \texttt{SEQ\_C}\}. \\
\texttt{decision} & \{\texttt{GRANT}, \texttt{DENY}, \texttt{CURTAIL}, \texttt{SAFE\_MODE}\}. \\
\texttt{reason\_code} & Primary code: \texttt{AUTH\_FAIL}, \texttt{POLICY\_DENY}, \texttt{THERMAL\_INFEASIBLE}, \texttt{POI\_RAMP\_UNSAFE}, \texttt{RESONANCE\_RISK}, \texttt{HNN\_ANOMALY}, \texttt{SCARCITY\_LOCKOUT}, etc. \\
\texttt{actor\_id} & Identity of requester (scheduler service, EMS gateway, operator override). \\
\texttt{cmd\_id} & Unique command identifier; must be non-replayable nonce-linked. \\
\texttt{sig\_meta} & Signature scheme metadata + verification outcome. \\
\texttt{policy\_state} & Scarcity flags, restricted operating mode flags, tranche lockouts. \\
\texttt{P\_req, dPdt\_req} & Requested power step and requested ramp (or implied). \\
\texttt{P\_meas, dPdt\_meas} & Measured POI power and max $|dP/dt|$ in the decision window. \\
\texttt{deeponet\_model\_hash} & Hash/ID of the oracle model used. \\
\texttt{deeponet\_outputs} & At minimum: $\Delta T_{\text{safe}}(t)$, $\sigma_{\max}(t)$, and any UQ bounds used. \\
\texttt{hnn\_model\_hash} & Hash/ID of the guardian model used. \\
\texttt{hnn\_score\_pack} & \{score $S(t)$, threshold $\tau$, class label, confidence band if used\}. \\
\texttt{spectral\_pack} & If resonance guard is enabled: $\Omega_0$ version, $R_{\text{spec}}(t)$, $\tau_{\text{spec}}$. \\
\texttt{artifact\_hashes} & Hash pointers to attached compressed artifacts (waveform slice, residual slice, trace slice). \\
\texttt{operator\_override} & If override occurs: signer IDs, justification code, and scope/duration. \\
\bottomrule
\end{longtable}

\footnote{This schema is intentionally redundant across security and settlement: the same record that proves a
\texttt{DENY} due to \texttt{RESONANCE\_RISK} also proves why a requested goodput burst was not admissible. The
contract and the control share one skeleton.}

\subsubsection{Artifact attachments (compressed but replay-relevant)}
\label{app:attest_artifacts}

Each bundle may include zero or more compressed attachments, each referenced by hash:
\begin{itemize}
  \item \texttt{WAVE\_POI}: short high-frequency POI waveform slice (power/voltage/current), windowed around the decision.
  \item \texttt{TRACE\_SCH}: scheduler trace slice (job start/stop, kernel bursts, sprint requests).
  \item \texttt{TRACE\_EMS}: EMS setpoint trace slice and scarcity flags.
  \item \texttt{DEEP\_RES}: DeepONet residual slice $r(t)$ and headroom time series (or summary stats + bounds).
  \item \texttt{HNN\_FEAT}: feature summary used for $S(t)$ (to support replay without storing raw packets).
\end{itemize}

\paragraph{Retention policy.}
Raw artifacts may be retained for a finite window (e.g., 30--90 days), while the compressed proof object is
retained for the audit period (e.g., 3--7 years). The bundle must always retain sufficient statistics to replay
the decision even if raw artifacts expire.

\subsection{Hash-chain construction and non-equivocation}
\label{app:hash_chain}

Define each bundle payload as $B_i$ for interval $i$. Compute:
\begin{equation}
\texttt{bundle\_id}_i \;=\; H\!\left(B_i \,\|\, \texttt{bundle\_id}_{i-1}\right),
\label{eq:bundle_hash_chain}
\end{equation}
where $H$ is a cryptographic hash (e.g., SHA-256). This creates an append-only chain that prevents deletion or
re-ordering without detection.

\paragraph{Fork detection.}
If two distinct bundles claim the same \texttt{prev\_bundle\_id}, the system must emit \texttt{LOG\_FORK} and
transition to safe-mode policies (Sequence C) until resolved.

\subsection{Replay algorithm (auditor view)}
\label{app:replay}

Given an \texttt{ATTEST\_BUNDLE}, the replay procedure reconstructs the decision:

\begin{enumerate}[label=\textbf{R\arabic*.}]
  \item Verify hash-chain integrity using \cref{eq:bundle_hash_chain}.
  \item Verify command authentication: signature validity, nonce freshness, privilege scope.
  \item Recompute policy state: scarcity flags, tranche locks, restricted mode.
  \item Recompute feasibility gate: using logged DeepONet model hash and inputs, reproduce
        $\Delta T_{\text{safe}}(t)$ and $\sigma_{\max}(t)$ (and UQ bounds if logged).
  \item Recompute POI envelope compliance: check $|dP/dt| \le R_{\text{safe}}$.
  \item Recompute HNN score: using logged model hash and feature pack, reproduce $S(t)$ and compare to $\tau$.
  \item If spectral guard is present, recompute $R_{\text{spec}}(t)$ and compare to $\tau_{\text{spec}}$.
  \item Confirm decision matches recomputed gate outcomes and that \texttt{reason\_code} is consistent with the
        first failing gate in the priority order.
\end{enumerate}

\paragraph{Gate priority order (deterministic).}
To eliminate ambiguity, define the deterministic priority order:
\[
\texttt{AUTH} \rightarrow \texttt{POLICY} \rightarrow \texttt{THERMAL} \rightarrow \texttt{POI} \rightarrow
\texttt{SPECTRAL} \rightarrow \texttt{HNN}.
\]
The \texttt{reason\_code} must equal the highest-priority failing gate. Secondary failures may be logged as
\texttt{reason\_secondary[]} for diagnosis.

\subsection{Binding the evidence spine to Sequences A/B/C}
\label{app:binding_sequences_evidence}

\paragraph{Sequence A binding (admission).}
Every proposed step/sprint in \cref{subsubsec:seqA} must emit exactly one \texttt{ATTEST\_BUNDLE} with
\texttt{decision\_type=\{SEQ\_A\}} and \texttt{decision=\{GRANT,DENY\}}.

\paragraph{Sequence B binding (scarcity).}
Every scarcity-curtailment action in \cref{subsubsec:seqB} must emit an \texttt{ATTEST\_BUNDLE} with
\texttt{decision\_type=SEQ\_B} and \texttt{decision=CURTAIL}. The bundle must include:
\begin{itemize}
  \item \texttt{scarcity\_flag=1} and the scarcity source;
  \item \texttt{u\_stiff, u\_flex} and the realized curtailment MW;
  \item a hash pointer to POI waveform evidence that curtailment occurred.
\end{itemize}

\paragraph{Sequence C binding (incident response).}
Every Sequence C execution in \cref{subsubsec:seqC} must emit a bundle with \texttt{decision\_type=SEQ\_C} and
\texttt{decision=SAFE\_MODE}, plus forensic artifact hashes (\texttt{TRACE\_SCH}, \texttt{TRACE\_EMS},
\texttt{WAVE\_POI}, \texttt{DEEP\_RES}) to support incident reconstruction.

\subsection{Binding the evidence spine to Goodput PPA settlement}
\label{app:binding_settlement}

The Goodput PPA in \cref{subsubsec:goodput_ppa} requires that billed goodput $G(t)$ be tied to the same evidence
spine. We implement this by requiring that each settlement interval has:
\begin{itemize}
  \item One settlement row (ledger) with \texttt{interval\_id}, $G(t)$, $E(t)$, $P_{\max}(t)$, $dP/dt$, and flags.
  \item One or more \texttt{ATTEST\_BUNDLE} pointers proving: admission decisions that enabled the work,
        and any curtailments/denials that limited it.
\end{itemize}

\paragraph{Goodput attestation primitive.}
Define a signed \texttt{GOODPUT\_CLAIM} message containing: \texttt{job\_id}, \texttt{interval\_id}, proposed $G(t)$,
and measurement method. The claim is accepted only if:
(i) it is signed by an allow-listed verifier, (ii) it is consistent with hardware counters (if used), and
(iii) the interval contains no \texttt{SAFE\_MODE} state that invalidates the work.

\paragraph{Curtailment credit proof.}
A curtailment credit in scarcity intervals (term $\Phi_{\text{scar}}$) must be backed by:
(i) a \texttt{SEQ\_B} bundle, (ii) POI waveform evidence of net-load reduction, and (iii) tranche utilization logs.

\subsection{Minimum viable ``proof sufficiency'' checklist}
\label{app:proof_sufficiency}

Before commissioning, verify the following invariants:
\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{Replay invariant:} sample bundles replay to identical decisions (Sequence A/B/C).
  \item \textbf{Non-fork invariant:} hash-chain fork detection triggers safe-mode and is audit-visible.
  \item \textbf{No dual-truth invariant:} settlement rows reference the same bundle hashes used by safety/security.
  \item \textbf{Reason-code determinism:} reason codes match the first failing gate in priority order.
  \item \textbf{Clock invariant:} alignment error $\epsilon_{\text{clk}}$ is bounded and breaches are logged.
\end{enumerate}

\subsection{Operational note: why this appendix is necessary}
\label{app:why_needed}

Without an evidence spine, ``zero-trust'' and ``goodput settlement'' remain rhetorical: you cannot prove that a
denial was safety-required, that a curtailment happened, or that billed goodput represents productive progress.
This appendix therefore completes the interface contract by specifying the auditable substrate that unifies
control, security, and economics.

\newpage

% =====================================================================
% APPENDIX E: Commissioning and Validation Protocol (Pilot -> Scale)
% =====================================================================
\section{Commissioning and Validation Protocol: From Pilot Evidence to Scale Authorization}
\label{app:commissioning_protocol}

This appendix specifies a commissioning protocol that converts the interface contract (Sequences A/B/C),
the evidence spine (\texttt{ATTEST\_BUNDLE}), and the Goodput PPA settlement logic into a \emph{testable}
and \emph{reviewer-proof} acceptance regimen. The goal is not to prove that the system is ``secure'' or
``safe'' in an abstract sense; the goal is to demonstrate, under bounded stressors and adversarial scenarios,
that the facility:
(i) enforces feasibility and security gates deterministically,
(ii) preserves nuclear/plant-first constraints,
(iii) produces audit-grade evidence for every control action, and
(iv) delivers stable goodput under admissible operating envelopes.

We define the commissioning program in three stages:
\begin{itemize}
  \item \textbf{Stage 0 (Offline)}: model validation and synthetic stress harness (no plant coupling).
  \item \textbf{Stage 1 (Pilot)}: hardware-in-the-loop (HIL) and limited on-site coupling (restricted envelope).
  \item \textbf{Stage 2 (Scale Authorization)}: expanded envelope with demonstrated safety margins and audit invariants.
\end{itemize}

\subsection{Commissioning objectives and acceptance criteria}
\label{app:commissioning_objectives}

We define four objective classes and their acceptance criteria.

\paragraph{O1: Feasibility correctness (DeepONet gate).}
The DeepONet oracle must be conservative with respect to safety constraints. Concretely:
\begin{itemize}
  \item For any admitted command, the realized trajectory must remain within the declared safe envelope
  (no late recognition of infeasibility).
  \item For any denied command, the denial must be explainable by logged headroom/uncertainty bounds.
\end{itemize}

\paragraph{Acceptance A1 (conservatism bound).}
Let $\widehat{\Delta T}_{\text{safe}}(t)$ denote predicted headroom and let $\Delta T_{\text{safe}}(t)$ denote
the best available reference (high-fidelity sim offline; plant measurements/HIL online).
Define prediction error $e(t)=\widehat{\Delta T}_{\text{safe}}(t)-\Delta T_{\text{safe}}(t)$.
The oracle is conservative if, on the commissioning dataset,
\begin{equation}
\Pr\!\left[e(t) \le \varepsilon_T\right] \ge 1-\delta_T
\quad\text{and}\quad
\Pr\!\left[e(t) < 0\right] \ge 1-\delta^-_T,
\label{eq:conservative_headroom}
\end{equation}
for chosen tolerances $(\varepsilon_T,\delta_T,\delta^-_T)$.%
\footnote{Interpretation: the first condition bounds overall error; the second forces the oracle to
\emph{underestimate} headroom (safe side) with high probability. If you implement uncertainty bounds,
replace $e(t)$ with lower confidence bounds and require coverage.}

\paragraph{O2: Anomaly detection efficacy (HNN guardian).}
The HNN guardian must detect cyber--physical inconsistencies that matter: spoofed signals, resonant forcing,
telemetry poisoning, and restart amplification attempts.

\paragraph{Acceptance A2 (false-negative priority).}
Define event set $\mathcal{E}_{\text{attack}}$ and benign set $\mathcal{E}_{\text{benign}}$ under the scenario
catalog in \cref{app:scenario_catalog}. Let the guardian output a binary alarm $A(t)\in\{0,1\}$.
Require:
\begin{align}
\Pr[A=0 \mid \mathcal{E}_{\text{attack}}] &\le \delta_{\text{FN}}, \label{eq:fn_bound}\\
\Pr[A=1 \mid \mathcal{E}_{\text{benign}}] &\le \delta_{\text{FP}}, \label{eq:fp_bound}
\end{align}
with $\delta_{\text{FN}} \ll \delta_{\text{FP}}$ (false negatives are costlier than false positives).%
\footnote{This asymmetry is intentional: the facility can tolerate conservative denials/cut-outs, but cannot
tolerate admitting unsafe or adversarial trajectories. The Goodput PPA is designed to compensate for conservative
availability behavior, while penalizing true interruptions; this is why the control + contract must be coupled.}

\paragraph{O3: Control determinism and audit invariants.}
Every decision must be replayable and must emit the correct \texttt{ATTEST\_BUNDLE} with deterministic reason codes.

\paragraph{Acceptance A3 (replay and non-equivocation).}
For a random sample of $n$ intervals in each commissioning stage, replay must reproduce:
(i) the same \texttt{decision}, (ii) the same primary \texttt{reason\_code}, and
(iii) the same gate outputs within logged tolerances. Additionally:
\begin{itemize}
  \item no hash-chain forks (\texttt{LOG\_FORK} must be absent except in forced tests),
  \item no clock desynchronization beyond $\epsilon_{\text{clk}}$ without emitting \texttt{CLOCK\_DESYNC}.
\end{itemize}

\paragraph{O4: Economic operability under constraints.}
The system must deliver stable goodput while obeying feasibility and scarcity obligations, and must not
create unbounded checkpoint/restart cascades under normal disturbances.

\paragraph{Acceptance A4 (goodput stability under admissible envelope).}
Define goodput efficiency $\eta_G(t) := G(t)/E(t)$ and interruption count $N_{\text{int}}(m)$ per month $m$.
Under the admissible envelope and excluding declared scarcity curtailments, require:
\begin{align}
\Pr\!\left[\eta_G(t) < \eta_{G,\min}\right] &\le \delta_{\eta},\\
\mathbb{E}[N_{\text{int}}(m)] &\le N_{\max},
\end{align}
with explicit allowances for \texttt{DENY} events grounded in feasibility (Clause 4 in the term sheet).%
\footnote{This avoids a pathological regime where the guardian is ``safe'' only by denying almost everything.
A4 forces practical throughput while preserving the primacy of safety denials.}

\subsection{Stage 0: Offline commissioning (simulation + synthetic adversary harness)}
\label{app:stage0_offline}

Stage 0 occurs before any plant coupling and exists to eliminate avoidable failure modes.

\subsubsection{S0.1 DeepONet validation vs. reference solvers}
\label{app:s0_deeponet_validation}

\paragraph{Dataset construction.}
Construct a dataset of transients spanning the intended operating envelope:
\begin{itemize}
  \item step loads and ramp profiles consistent with Rubin-class schedules,
  \item load rejection events (fast unload),
  \item bounded oscillatory loads around suspected sensitive bands,
  \item sensor noise and missingness consistent with historian realities.
\end{itemize}

\paragraph{Reference truth.}
Use best-available high-fidelity solvers (CFD/FEA where feasible, reduced-order models otherwise) to produce
reference trajectories $\Delta T_{\text{safe}}(t)$, and log all solver assumptions.

\paragraph{Validation.}
Compute the conservatism criteria in \cref{eq:conservative_headroom} and produce:
\begin{itemize}
  \item coverage plots (predicted vs. reference headroom),
  \item worst-case counterexamples (where oracle overestimates headroom),
  \item sensitivity to input perturbations (noise, missing channels).
\end{itemize}

\subsubsection{S0.2 HNN training and red-team scenario synthesis}
\label{app:s0_hnn_training}

Construct labeled scenario streams (see \cref{app:scenario_catalog}) where attack scenarios include:
\begin{itemize}
  \item spoofed price/dispatch inputs,
  \item replayed authenticated commands (nonce failures),
  \item telemetry poisoning (biasing thermal state),
  \item resonant forcing attempts,
  \item forced checkpoint loops (restart amplification).
\end{itemize}

Train the guardian to jointly ingest:
(i) control-plane signals,
(ii) POI waveform features,
(iii) DeepONet residual streams. Evaluate \cref{eq:fn_bound}--\cref{eq:fp_bound} under holdout.

\subsubsection{S0.3 Deterministic gate ordering and reason code unit tests}
\label{app:s0_gate_tests}

Implement unit tests that confirm:
\begin{itemize}
  \item Gate priority order is deterministic (AUTH $\rightarrow$ POLICY $\rightarrow$ THERMAL $\rightarrow$ POI
        $\rightarrow$ SPECTRAL $\rightarrow$ HNN),
  \item The primary \texttt{reason\_code} is always the first failing gate,
  \item Secondary failures are recorded but never override the primary code.
\end{itemize}

\subsection{Stage 1: Pilot commissioning (HIL + restricted envelope coupling)}
\label{app:stage1_pilot}

Stage 1 is the first time the full loop is exercised with real timing and real telemetry, but under restricted
authority: sprint caps are limited, oscillatory content is bounded, and operator overrides are required for
envelope expansions.

\subsubsection{S1.1 Hardware-in-the-loop timing proof}
\label{app:s1_hil_timing}

\paragraph{Latency budget.}
Define an end-to-end decision latency budget:
\[
\tau_{\text{E2E}} = \tau_{\text{auth}} + \tau_{\text{policy}} + \tau_{\text{oracle}} + \tau_{\text{poi}} + \tau_{\text{hnn}}
\le \tau_{\max}.
\]
Measure each component under load and log latency histograms.%
\footnote{The key acceptance condition is not mean latency but tail latency (e.g., 99.9th percentile), because
the system fails during rare bursts.}

\paragraph{Acceptance A5 (tail latency).}
Require $\Pr[\tau_{\text{E2E}} > \tau_{\max}] \le \delta_\tau$ over the pilot duration.

\subsubsection{S1.2 Envelope identification: empirical $R_{\text{safe}}$ and sensitive bands}
\label{app:s1_envelope_id}

Empirically identify:
\begin{itemize}
  \item POI ramp-safe bound $R_{\text{safe}}$ under observed protection behavior,
  \item sensitive frequency bands $\Omega_0$ where forcing increases instability risk,
  \item baseline damping estimates for relevant plant/BoP loops (as observable).
\end{itemize}

\paragraph{Procedure.}
Inject bounded excitation sequences under operator supervision:
\begin{itemize}
  \item small-signal sinusoidal perturbations at swept frequencies (below any trip thresholds),
  \item step-and-hold sequences at increasing magnitudes,
  \item controlled unload events within safe limits.
\end{itemize}

\paragraph{Acceptance A6 (stable identification without unsafe excursions).}
The identification campaign must not trigger protective trips; all excitations must remain within declared
pilot safety margins, with evidence bundles proving each step was admissible.

\subsubsection{S1.3 Live replay audits (weekly)}
\label{app:s1_replay_audits}

On a rolling basis:
\begin{itemize}
  \item sample $n$ decision intervals from each week,
  \item replay using the evidence spine procedure,
  \item publish a replay report (pass/fail, any divergence, root cause).
\end{itemize}

\paragraph{Acceptance A7 (zero divergence).}
No unexplained divergences are permitted. Any divergence triggers:
(i) safe-mode clamp (Sequence C), (ii) root-cause analysis, and (iii) re-validation before resuming.

\subsection{Stage 2: Scale authorization (expanded envelope + contractual readiness)}
\label{app:stage2_scale}

Stage 2 grants increased authority (higher sprint caps, broader workload modes) only after Stage 1 evidence
shows stable enforcement.

\subsubsection{S2.1 Progressive envelope expansion protocol}
\label{app:s2_envelope_expand}

Define envelope tiers $\mathcal{E}_1 \subset \mathcal{E}_2 \subset \cdots \subset \mathcal{E}_K$ where each tier
expands one axis:
\begin{itemize}
  \item higher $\sigma_{\max}$ (sprint cap),
  \item higher allowed $|dP/dt|$ within protection limits,
  \item broader allowed spectral content (still excluding identified risky bands),
  \item higher flexible tranche participation during non-scarcity windows.
\end{itemize}

\paragraph{Tier advancement rule.}
Advance from $\mathcal{E}_k$ to $\mathcal{E}_{k+1}$ only if, over a fixed evaluation window:
\begin{itemize}
  \item conservatism bound \cref{eq:conservative_headroom} continues to hold,
  \item HNN FN bound \cref{eq:fn_bound} holds on injected tests,
  \item replay invariants remain clean,
  \item goodput stability criterion A4 holds net of declared scarcity curtailments.
\end{itemize}

\subsubsection{S2.2 Contract readiness: settlement reconciliation and dispute protocol}
\label{app:s2_settlement_ready}

Before enabling Goodput PPA settlement at scale, perform a reconciliation campaign:
\begin{itemize}
  \item verify that each billed interval has a matching bundle pointer set,
  \item verify that curtailment credits only occur when \texttt{SEQ\_B} evidence exists,
  \item verify that denials are reason-coded and consistent with feasibility gates,
  \item verify anti-gaming controls for $G(t)$ (job ID linkage, verifier hashes, reconciliation checks).
\end{itemize}

\paragraph{Acceptance A8 (no orphaned settlement rows).}
No settlement row may exist without corresponding evidence pointers. Any orphaned row is non-billable by default
until resolved.

\subsection{Scenario catalog (test cases and adversarial injections)}
\label{app:scenario_catalog}

We define a minimal scenario catalog. Each scenario must produce:
(i) a time-aligned multi-stream dataset, (ii) expected gate outcomes, (iii) expected evidence bundles.

\subsubsection{Benign scenarios}
\label{app:benign_scenarios}

\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{Diurnal smoothing baseline:} low-variance inference + batch workloads; no sprints.
  \item \textbf{Training steady run:} stiff tranche fixed; flexible tranche low and smooth.
  \item \textbf{Admissible sprint windows:} bounded sprint factor increases within $\sigma_{\max}(t)$.
  \item \textbf{Controlled unload:} staged ramp-down satisfying $R_{\text{safe}}$.
  \item \textbf{Scarcity curtailment:} declared scarcity triggers Sequence B; flexible tranche sheds; stiff continues.
\end{enumerate}

\subsubsection{Adversarial scenarios}
\label{app:adversarial_scenarios}

\begin{enumerate}[label=\textbf{E.A\arabic*.}]
  \item \textbf{Spoofed price/dispatch signal:} authenticated schedule request but invalid policy state; expect \texttt{POLICY\_DENY}.
  \item \textbf{Nonce replay attack:} replay of valid command; expect \texttt{AUTH\_FAIL}.
  \item \textbf{Telemetry bias injection:} thermal telemetry offset intended to inflate headroom; expect HNN anomaly and/or oracle residual spike; deny.
  \item \textbf{Resonant forcing attempt:} load oscillation near $\omega_0$; expect \texttt{RESONANCE\_RISK} denial.
  \item \textbf{Fast unload shock:} induced job abort to create $|dP/dt|$ violation; expect \texttt{POI\_RAMP\_UNSAFE} denial or safe-mode clamp.
  \item \textbf{Checkpoint amplification:} repeated restart triggers; expect Sequence C escalation + forensic capture.
\end{enumerate}

\footnote{Each adversarial scenario should be executed first offline (Stage 0), then in HIL (Stage 1) with bounded
authority, and only then in expanded operation (Stage 2). The acceptance criteria prioritize preventing unsafe
admissions over maximizing throughput in the presence of suspicious patterns.}

\subsection{Calibration and drift monitoring (post-commissioning)}
\label{app:drift_monitoring}

Commissioning is not a one-time event because both workloads and plant configurations drift.

\paragraph{DeepONet drift triggers.}
Recalibrate or revalidate the oracle if any of the following occur:
\begin{itemize}
  \item sustained increase in residuals $r(t)$ beyond control limits,
  \item new operating regimes (hardware upgrades, cooling retrofits, plant tuning changes),
  \item changes in telemetry quality (sensor replacement, sampling changes).
\end{itemize}

\paragraph{HNN drift triggers.}
Recalibrate the guardian if:
\begin{itemize}
  \item false positive rates exceed $\delta_{\text{FP}}$ in benign operation,
  \item feature distributions shift (new kernel patterns, new job mix),
  \item attacks are observed (post-incident retraining is mandatory).
\end{itemize}

\paragraph{Evidence spine drift triggers.}
Any \texttt{LOG\_FORK}, repeated \texttt{CLOCK\_DESYNC}, or replay divergence is treated as a commissioning regression:
enter Sequence C safe-mode and require corrective action before returning to sprint permissions.

\subsection{Commissioning deliverables (what a reviewer/regulator expects)}
\label{app:commissioning_deliverables}

The commissioning package should include:
\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{Test plan}: scenario catalog, envelope tiers, injection authority, stop conditions.
  \item \textbf{Results dossier}: A1--A8 acceptance outcomes, plots, and counterexamples.
  \item \textbf{Replay audit report}: sampled replay intervals with hashes and outcomes.
  \item \textbf{Model registry}: DeepONet/HNN model hashes, training data summaries, calibration settings.
  \item \textbf{Evidence policy}: retention windows, artifact compression rules, audit access procedure.
  \item \textbf{Operational readiness}: runbooks for Sequence C incidents, dual-authorization recovery steps.
\end{enumerate}

\subsection{Stop conditions and safety primacy}
\label{app:stop_conditions}

At any stage, the following stop conditions force an immediate safe-mode clamp (Sequence C) and halt envelope
expansion:
\begin{itemize}
  \item any unexplained replay divergence (A3 violation),
  \item any observed oracle non-conservatism causing an unsafe admission (A1 violation),
  \item any confirmed missed detection on a high-severity attack scenario (A2 FN violation),
  \item any evidence chain fork or unreconciled clock desync that invalidates audit integrity.
\end{itemize}

\footnote{This final section is the core governance claim: \emph{the system is allowed to be conservative and to
sacrifice compute}. It is not allowed to violate safety primacy or audit integrity. The Goodput PPA and the
interface contract are designed to make that stance economically and operationally coherent.}

\newpage

% =====================================================================
% APPENDIX E: DeepONet UQ bounds + conservative envelope proof obligations
% =====================================================================
\section{DeepONet UQ Bounds and Conservative Envelope Proof Obligations}
\label{app:deeponet_uq_conservative_envelope}

This appendix formalizes the \emph{uncertainty-quantified} DeepONet oracle used in Sequence A, and states
\emph{reviewer-proof} obligations under which the oracle yields a conservative feasibility envelope for sprint
admission. The deliverable is not “a good predictor,” but a predictor that supports \emph{auditable denials and
conservative admissions} with explicit confidence levels.

\subsection{Setup: coupled feasibility as a safety constraint}
\label{appF:setup}

Let $x(t)$ denote the (latent) plant thermal-hydraulic state and let $y(t)$ denote the safety-relevant outputs
(steam generator outlet temperature, primary/secondary pressures, level, etc.). Let $P_{\mathrm{AI}}(t)$ be the
aggregate campus load at the POI. We treat the plant-side dynamics abstractly as
\begin{equation}
  \dot{x}(t) = f\bigl(x(t),u(t),P_{\mathrm{AI}}(t)\bigr), \qquad y(t)=h\bigl(x(t)\bigr),
  \label{eq:plant_dyn_appF}
\end{equation}
where $u(t)$ is the supervisory control input (rod setpoints, feedwater setpoints, turbine governor settings,
etc.). The facility’s safety logic imposes a \emph{hard constraint set}
\begin{equation}
  y(t) \in \mathcal{Y}_{\mathrm{safe}} := \{y:\ g(y)\le 0\},
  \label{eq:safe_set_appF}
\end{equation}
where $g(\cdot)$ encodes scram thresholds and protection margins.

The admission problem (Sequence A) proposes an increment (or “sprint”) in $P_{\mathrm{AI}}$ over a horizon $H$ and
must decide whether that increment is admissible. Formally, a proposal is \emph{feasible} if the resulting
trajectory remains in $\mathcal{Y}_{\mathrm{safe}}$ for the horizon:
\begin{equation}
  \mathrm{FEASIBLE}(t) = \mathbf{1}\Bigl\{ y(\tau)\in\mathcal{Y}_{\mathrm{safe}} \ \forall \tau\in[t,t+H] \Bigr\}.
  \label{eq:feasible_def_appF}
\end{equation}

\paragraph{Oracle role.}
Because the true $f,h$ are expensive (and partially unobservable), the DeepONet is used as a fast operator surrogate
to forecast safety-relevant quantities and their uncertainty. The commissioning obligation is thus:
\emph{admit only when the oracle’s lower-confidence bound implies feasibility.}

\subsection{DeepONet operator model and forecasting target}
\label{appF:deeponet_operator}

Let $\xi_t$ denote the \emph{history bundle} available at decision time $t$, containing recent control and load
histories and measured outputs:
\begin{equation}
  \xi_t \;:=\;\bigl( u|_{[t-T,t]},\ P_{\mathrm{AI}}|_{[t-T,t]},\ y_{\mathrm{meas}}|_{[t-T,t]} \bigr).
  \label{eq:history_bundle_appF}
\end{equation}
Define the (unknown) history-to-future operator
\begin{equation}
  \mathcal{G}_H:\ \xi_t \mapsto y(\cdot)\big|_{[t,t+H]}.
  \label{eq:true_operator_appF}
\end{equation}
A DeepONet approximates $\mathcal{G}_H$ by learning a branch/trunk decomposition; we denote the learned surrogate by
$\widehat{\mathcal{G}}_H$. We focus on a scalar safety functional $z(\tau)$ extracted from $y(\tau)$ (e.g., outlet
temperature $T_{\mathrm{out}}(\tau)$) and define the predicted future path
\begin{equation}
  \widehat{z}(\tau) = \widehat{\mathcal{G}}_H(\xi_t)(\tau), \qquad \tau\in[t,t+H].
  \label{eq:z_hat_appF}
\end{equation}

\paragraph{Headroom variable.}
Let $z_{\mathrm{lim}}$ denote the relevant trip limit (e.g., $T_{\mathrm{scram}}$). Define true and predicted
\emph{headroom}:
\begin{align}
  \Delta z(\tau) &:= z_{\mathrm{lim}} - z(\tau), \\
  \widehat{\Delta z}(\tau) &:= z_{\mathrm{lim}} - \widehat{z}(\tau).
  \label{eq:headroom_defs_appF}
\end{align}
Safety over the horizon is equivalent to $\Delta z(\tau)\ge 0$ for all $\tau\in[t,t+H]$ (for a single constraint;
multiple constraints are handled by taking $z$ as the most binding margin).

\subsection{UQ goal: conservative lower bounds with finite-sample guarantees}
\label{appF:uq_goal}

We require a function $\underline{\Delta z}(\tau)$ such that, with high probability,
\begin{equation}
  \Delta z(\tau) \;\ge\; \underline{\Delta z}(\tau)\qquad \forall \tau\in[t,t+H].
  \label{eq:lb_goal_appF}
\end{equation}
Admissions are granted only when the lower bound remains nonnegative:
\begin{equation}
  \underline{\Delta z}(\tau)\ge 0\quad \forall \tau\in[t,t+H]\ \Rightarrow\ \texttt{THERMAL\_FEASIBLE}.
  \label{eq:admission_rule_appF}
\end{equation}
The remainder of the appendix constructs $\underline{\Delta z}$ and proves that \cref{eq:admission_rule_appF}
implies conservative feasibility at a chosen confidence level.

\subsection{Conformal calibration for pathwise lower bounds}
\label{appF:conformal}

We use a \emph{distribution-free calibration} approach that converts residuals on a calibration set into
prediction intervals with finite-sample coverage under exchangeability.%
\footnote{This is the cleanest “reviewer-proof” route because it does not require assuming Gaussian errors,
correct Bayesian posteriors, or perfectly specified dynamics. The trade is that guarantees are \emph{marginal}
and rely on exchangeability; Stage E commissioning should explicitly test for the kinds of distribution shifts
that break exchangeability.}

\subsubsection{Calibration data and residual definition}
\label{appF:cal_data}

Let $\mathcal{D}_{\mathrm{cal}}=\{(\xi^{(i)}, z^{(i)}(\cdot))\}_{i=1}^{n}$ be a calibration dataset drawn from the
same operating regime as intended deployment (pilot envelope), where $z^{(i)}(\tau)$ is the realized future path.
Define a nonconformity score for each calibration sample. Two options matter:

\paragraph{Pointwise residual score.}
For each $\tau$ in a discrete grid $\{\tau_j\}_{j=1}^{J}$ over $[t,t+H]$, define
\begin{equation}
  r^{(i)}(\tau_j) := \bigl| z^{(i)}(\tau_j) - \widehat{z}^{(i)}(\tau_j) \bigr|.
  \label{eq:point_resid_appF}
\end{equation}

\paragraph{Pathwise supremum score.}
Define a single score per sample:
\begin{equation}
  R^{(i)} := \max_{1\le j\le J}\ \bigl| z^{(i)}(\tau_j) - \widehat{z}^{(i)}(\tau_j) \bigr|.
  \label{eq:sup_resid_appF}
\end{equation}
The supremum score yields \emph{simultaneous} coverage across the horizon grid; it is conservative but simple.

\subsubsection{Quantile construction}
\label{appF:quantile}

Let $\{R^{(i)}\}_{i=1}^n$ be the calibration scores. Define the conformal quantile
\begin{equation}
  q_{1-\alpha} := \mathrm{Quantile}_{1-\alpha}\bigl(\{R^{(i)}\}_{i=1}^n\bigr)
  \;\;=\;\; \text{$\lceil (n+1)(1-\alpha)\rceil$-th order statistic}.
  \label{eq:conformal_quantile_appF}
\end{equation}
Then define the conservative lower bound on the headroom:
\begin{equation}
  \underline{\Delta z}(\tau_j) := \widehat{\Delta z}(\tau_j) - q_{1-\alpha}.
  \label{eq:lb_conformal_appF}
\end{equation}

\begin{theorem}[Finite-sample simultaneous coverage on the horizon grid]
\label{thm:conformal_simul}
Assume the calibration samples and the test sample are exchangeable.
Let $q_{1-\alpha}$ be defined by \cref{eq:conformal_quantile_appF} using the supremum score
\cref{eq:sup_resid_appF}. Then, for the next (test) trajectory,
\begin{equation}
  \Pr\!\left( \max_{1\le j\le J} \bigl|z(\tau_j)-\widehat{z}(\tau_j)\bigr|\ \le\ q_{1-\alpha} \right)\ \ge\ 1-\alpha.
  \label{eq:simul_cov_appF}
\end{equation}
Equivalently, with probability at least $1-\alpha$,
\begin{equation}
  z(\tau_j)\ \le\ \widehat{z}(\tau_j)+q_{1-\alpha}\quad \forall j
  \quad\Rightarrow\quad
  \Delta z(\tau_j)\ \ge\ \widehat{\Delta z}(\tau_j)-q_{1-\alpha}\quad \forall j.
  \label{eq:headroom_cov_appF}
\end{equation}
\end{theorem}

\begin{proof}
This is the standard split-conformal guarantee for exchangeable data with nonconformity scores given by
\cref{eq:sup_resid_appF}. By construction, the rank of the test score among the $n$ calibration scores plus itself is
uniform over $\{1,\dots,n+1\}$ under exchangeability. Choosing $q_{1-\alpha}$ as the $\lceil(n+1)(1-\alpha)\rceil$-th
order statistic yields $\Pr(R^{\mathrm{test}}\le q_{1-\alpha})\ge 1-\alpha$, which is exactly
\cref{eq:simul_cov_appF}. The headroom statement follows by rearrangement.
\end{proof}

\paragraph{Continuous-time note.}
The guarantee is on the discretized grid $\{\tau_j\}$. If continuous-time safety is required, you must either:
(i) refine the grid to a resolution justified by plant bandwidth, or
(ii) add a Lipschitz modulus bound to bridge between grid points (see \cref{subsec:lip_bridge_appF}).

\subsection{Conservative feasibility theorem (admission implies safety with probability)}
\label{appF:feasibility_thm}

Define the \emph{conformal-feasible} event
\[
\mathcal{F}_{\alpha}(t) := \left\{ \underline{\Delta z}(\tau_j)\ge 0\ \forall j \right\},
\]
where $\underline{\Delta z}$ is given by \cref{eq:lb_conformal_appF}. This is exactly what Sequence A checks.

\begin{theorem}[Conservative admission implies bounded violation probability (grid-horizon)]
\label{thm:admit_safe_prob}
Under the exchangeability assumptions of \cref{thm:conformal_simul}, if the system admits a sprint step only when
$\mathcal{F}_{\alpha}(t)$ holds, then the probability of violating the safety limit on the horizon grid is bounded:
\begin{equation}
  \Pr\!\left( \exists j\in\{1,\dots,J\}: z(\tau_j) > z_{\mathrm{lim}} \ \middle|\ \mathcal{F}_{\alpha}(t) \right)
  \le \alpha.
  \label{eq:violation_bound_appF}
\end{equation}
\end{theorem}

\begin{proof}
From \cref{thm:conformal_simul}, with probability at least $1-\alpha$ we have
$z(\tau_j)\le \widehat{z}(\tau_j)+q_{1-\alpha}$ for all $j$. If $\mathcal{F}_{\alpha}(t)$ holds then
$\widehat{\Delta z}(\tau_j)-q_{1-\alpha}\ge 0$, i.e., $\widehat{z}(\tau_j)+q_{1-\alpha}\le z_{\mathrm{lim}}$ for all $j$.
Thus on the $1-\alpha$ event we have $z(\tau_j)\le z_{\mathrm{lim}}$ for all $j$. The complement event has probability
at most $\alpha$, yielding \cref{eq:violation_bound_appF}.
\end{proof}

\paragraph{Multiple constraints.}
If there are $K$ independent safety margins $z_k(\cdot)$ (temperature, pressure, level, etc.), apply the procedure
to each and allocate a per-constraint risk budget $\alpha_k$ with $\sum_{k=1}^K \alpha_k \le \alpha_{\mathrm{tot}}$.
Then a union bound yields overall violation probability at most $\alpha_{\mathrm{tot}}$.%
\footnote{This “risk budgeting” is exactly what you want in the interface contract: it makes explicit which
constraints dominate admissions and how conservative you are being.}

\subsection{Lipschitz bridge for continuous-time safety}
\label{subsec:lip_bridge_appF}

If you must guarantee safety for all $\tau\in[t,t+H]$ rather than only at grid points, add a modulus condition:
assume $z(\tau)$ is $L$-Lipschitz over the horizon: $|z(\tau)-z(\tau')|\le L|\tau-\tau'|$. Then if the grid spacing
$\Delta\tau:=\max_j(\tau_{j+1}-\tau_j)$ satisfies $L\Delta\tau \le \varepsilon$, you obtain
\[
\max_{\tau\in[t,t+H]} z(\tau) \le \max_j z(\tau_j) + \varepsilon.
\]
Thus you can enforce a tightened limit $z_{\mathrm{lim}}-\varepsilon$ at the grid points. Concretely, replace
$z_{\mathrm{lim}}$ by $z_{\mathrm{lim}}-\varepsilon$ in the headroom definitions and theorems above.%
\footnote{Operationally: identify $L$ empirically from pilot traces (or conservatively upper-bound it by plant
bandwidth). This gives you a deterministic way to translate sampling rate into safety margin.}

\subsection{From headroom bounds to sprint cap \texorpdfstring{$\sigma_{\max}(t)$}{sigma_max(t)}}
\label{appF:sigma_max}

Sequence A requires a decision variable: the maximum admissible sprint factor $\sigma(t)\in[1,\sigma_{\mathrm{peak}}]$.

\subsubsection{Parameterized load proposal}
\label{appF:proposal}

Let the baseline profile be $P_{\mathrm{base}}(\tau)$ and a proposed sprint scale it:
\begin{equation}
  P_{\mathrm{AI}}^{\sigma}(\tau) := \sigma\,P_{\mathrm{base}}(\tau)\qquad \tau\in[t,t+H].
  \label{eq:proposal_sigma_appF}
\end{equation}
Run the oracle under the proposed profile and obtain $\widehat{z}^{\sigma}(\tau_j)$, hence
$\underline{\Delta z}^{\sigma}(\tau_j)$.

\subsubsection{Definition of conservative sprint cap}
\label{appF:sigma_def}

Define
\begin{equation}
  \sigma_{\max}(t) := \sup\Bigl\{\sigma \in [1,\sigma_{\mathrm{peak}}] :
    \underline{\Delta z}^{\sigma}(\tau_j)\ge 0\ \ \forall j=1,\dots,J
  \Bigr\}.
  \label{eq:sigma_max_def_appF}
\end{equation}
This is the “oracle-implied” sprint cap used in Sequence A.

\paragraph{Practical computation.}
If $\underline{\Delta z}^{\sigma}(\tau_j)$ is monotone decreasing in $\sigma$ (empirically true in most thermal
margins), compute $\sigma_{\max}$ by bisection on $\sigma$. Otherwise, compute by scanning candidate $\sigma$ values
and taking the largest feasible.%
\footnote{Commissioning obligation: you must \emph{empirically validate} monotonicity or else implement safe
non-monotone search with guard rails. Monotonicity is a convenience, not a theorem, unless you assume a monotone
plant response with respect to load.}

\begin{theorem}[Probabilistic safety of sprint cap]
\label{thm:sigma_safe}
Assume the conformal calibration conditions of \cref{thm:conformal_simul}.
If a sprint is admitted with factor $\sigma\le\sigma_{\max}(t)$, then the probability of violating the limit at any
grid point in the horizon is at most $\alpha$:
\[
\Pr\!\left(\exists j:\ z^{\sigma}(\tau_j) > z_{\mathrm{lim}}\right)\le \alpha.
\]
\end{theorem}

\begin{proof}
If $\sigma\le \sigma_{\max}(t)$, then by definition \cref{eq:sigma_max_def_appF} we have
$\underline{\Delta z}^{\sigma}(\tau_j)\ge 0$ for all $j$, i.e., $\mathcal{F}_{\alpha}(t)$ holds for the proposed
trajectory. Apply \cref{thm:admit_safe_prob}.
\end{proof}

\subsection{Energy-form conservative inequality (impulse robustness)}
\label{appF:energy_form}

For sub-second bursts, pointwise ramp constraints can be less meaningful than an energetic constraint.
Define a conservative headroom functional
\begin{equation}
  \underline{\Delta z}(t) := \min_{1\le j\le J} \underline{\Delta z}(\tau_j),
  \label{eq:min_headroom_appF}
\end{equation}
and define an effective thermal capacitance constant $C_{\mathrm{th}}>0$ (identified empirically). Enforce the
impulse inequality for any proposed burst of duration $\Delta t_{\mathrm{sprint}}$:
\begin{equation}
  \int_t^{t+\Delta t_{\mathrm{sprint}}} \dot{P}_{\mathrm{AI}}(\tau)\,d\tau
  \;\le\;
  C_{\mathrm{th}}\;\underline{\Delta z}(t).
  \label{eq:energy_ineq_appF}
\end{equation}
This is a conservative “low-pass filter” statement: bursts are allowed only if conservative headroom can absorb them.

\paragraph{Identification obligation.}
Commissioning must identify $C_{\mathrm{th}}$ and validate \cref{eq:energy_ineq_appF} on bounded stress tests,
otherwise the inequality is merely a heuristic.%
\footnote{If you cannot reliably identify $C_{\mathrm{th}}$, drop the energy inequality and enforce only
horizon feasibility via $\sigma_{\max}(t)$; do not pretend you have an energetic guarantee without evidence.}

\subsection{Proof obligations (what must be demonstrated, not asserted)}
\label{appF:proof_obligations}

This subsection turns the above theorems into concrete obligations that can be satisfied by pilot evidence,
tests, and logs. These are the items a skeptical reviewer (or auditor) will look for.

\subsubsection{PO1: Exchangeability regime specification}
\label{appF:po1}

You must specify the regime in which exchangeability is assumed for \cref{thm:conformal_simul}. At minimum:
\begin{itemize}
  \item the envelope bounds (hardware configs, cooling config, control modes),
  \item the workload class (training vs inference mix; tranche policy),
  \item telemetry sampling rates and channels included.
\end{itemize}
If the regime changes materially, you must recalibrate $q_{1-\alpha}$.

\subsubsection{PO2: Horizon discretization and Lipschitz bridge justification}
\label{appF:po2}

You must justify the choice of grid $\{\tau_j\}$:
\begin{itemize}
  \item either by plant bandwidth (Nyquist-style logic for the relevant modes),
  \item or by an explicit Lipschitz bound $L$ and margin $\varepsilon$ as in \cref{subsec:lip_bridge_appF}.
\end{itemize}
Absent this, your guarantee is \emph{only} at sample times.

\subsubsection{PO3: Residual stationarity and drift monitors}
\label{appF:po3}

You must define drift monitors that trigger recalibration:
\begin{itemize}
  \item residual control limits on $R^{(i)}$,
  \item rolling coverage checks (empirical violation rate vs $\alpha$),
  \item explicit incident-triggered recalibration after attacks or trips.
\end{itemize}

\subsubsection{PO4: Monotonicity validation (if using bisection for \pdfmath{$\sigma_{\max}$}{sigma_max})}
\label{appF:po4}

If you compute $\sigma_{\max}$ via bisection, you must validate (empirically) that the feasibility predicate
\[
\mathcal{F}_\alpha(t;\sigma)=\mathbf{1}\{\underline{\Delta z}^{\sigma}(\tau_j)\ge 0\ \forall j\}
\]
is monotone non-increasing in $\sigma$ over the envelope. If not, use safe search.

\subsubsection{PO5: Evidence binding (oracle outputs to admission logs)}
\label{appF:po5}

Each admission decision must log:
\begin{itemize}
  \item the quantile $q_{1-\alpha}$ (and calibration hash),
  \item the predicted path $\widehat{z}^{\sigma}(\tau_j)$ (or compressed representation),
  \item the lower bound $\underline{\Delta z}^{\sigma}(\tau_j)$ (or minimum headroom),
  \item the resulting $\sigma_{\max}(t)$ and the admitted $\sigma(t)$,
  \item the primary \texttt{reason\_code} if denied.
\end{itemize}
These fields must be linked to \texttt{ATTEST\_BUNDLE} evidence hashes (Appendix E).

\subsection{Implementation note: where this plugs into Sequence A}
\label{appF:seqA_plug}

Sequence A’s “thermal feasibility” step is concretely:
\begin{enumerate}[label=\textbf{F\arabic*.}]
  \item Query DeepONet for $\widehat{z}^{\sigma}(\tau_j)$ for candidate $\sigma$ values.
  \item Apply conformal quantile $q_{1-\alpha}$ (current envelope calibration) to compute
        $\underline{\Delta z}^{\sigma}(\tau_j)$ via \cref{eq:lb_conformal_appF}.
  \item Compute $\sigma_{\max}(t)$ via \cref{eq:sigma_max_def_appF}.
  \item Admit only if requested $\sigma(t)\le \sigma_{\max}(t)$, else deny with \texttt{THERMAL\_INFEASIBLE}.
\end{enumerate}
This produces an auditable “proof record” that the admission was conservative at level $\alpha$.

\newpage

% =====================================================================
% APPENDIX F — TELEMETRY & SAMPLING SPECIFICATIONS (OBSERVABILITY CONTRACT)
% =====================================================================

\section{Telemetry and Sampling Specifications: The Observability Contract}
\label{appF:observability_contract}

This appendix specifies the minimum telemetry set, sampling rates, synchronization requirements, and
anti-aliasing constraints required for the admission and safety gates (Sequence A), the scarcity regime
(Sequence B), and incident response (Sequence C) to be \emph{replayable, auditable, and physically meaningful}.
The core claim is simple: if the facility cannot \emph{observe} fast electrical transients and correlate them with
scheduler/EMS commands and plant state estimates, it cannot enforce a reviewer-proof coupling regime.%
\footnote{This is the control-theoretic version of ``you cannot secure what you cannot measure.''
It is also the practical boundary between a narrative and an enforceable interface contract.}

\subsection{Signal classes and the minimum viable sensor set}
\label{appF:signals_minset}

We partition the telemetry into three planes that must be time-aligned:

\begin{itemize}
  \item \textbf{Electrical plane (POI + distribution):} captures fast power transients, frequency/ROCOF, and
  protection-relevant events at the point of interconnection (POI) and within the campus distribution.
  \item \textbf{Compute plane (scheduler + rack/PDU):} captures job admissions, sprint commands, and the realized
  power trajectory at rack/PDU aggregation (where \emph{software intent} meets \emph{electrical reality}).
  \item \textbf{Plant physics plane (SMR + balance-of-plant):} captures the state that constrains feasibility:
  thermal headroom, steam generator level dynamics, valve states, governor state, etc., including DeepONet
  virtual sensing outputs when deployed \citep{Lu2021DeepONet,hossain2024virtualsensing}.
\end{itemize}

\paragraph{Minimum sensor set (hard requirement).}
At minimum, the facility must instrument:
\begin{enumerate}[label=\textbf{F.\arabic*}]
  \item \textbf{POI synchrophasor:} $V(t),I(t)$ phasors, $P(t),Q(t)$, frequency $f(t)$, and ROCOF $\dot{f}(t)$
  at the POI, compliant with synchrophasor measurement conventions \citep{ieee_c37118}.
  \item \textbf{POI waveform capture:} time-synchronized instantaneous voltage/current waveforms (or equivalent
  high-rate samples) sufficient to reconstruct sub-cycle events and validate $dP/dt$ spikes.%
  \footnote{Synchrophasors alone are not sufficient for microsecond–millisecond events; a waveform layer is
  required to eliminate blind spots and to support forensic replay.}
  \item \textbf{Campus distribution monitors:} PDU-level (or feeder-level) $P(t)$ at high rate, plus event logs
  from protective devices (breaker trips, relay operations).%
  \footnote{This is where you detect whether a transient was generated internally (distribution) or imposed at
  the POI (grid) and whether protection logic was stressed.}
  \item \textbf{Scheduler/EMS event stream:} signed job admission events, sprint factor commands $\sigma(t)$,
  tranche utilization commands $u_s(t),u_f(t)$, and policy state (scarcity lockout flags).
  \item \textbf{Rack/PDU power telemetry:} realized rack/PDU power at high rate (or sufficiently granular proxy)
  with per-interval maxima and $dP/dt$ estimates.
  \item \textbf{Plant and BOP telemetry:} at least the control-relevant subset: turbine/governor state, steam
  generator level signals, valve positions, steam dump actuation flags, and any internal margin alarms.
  \item \textbf{DeepONet outputs (if used):} the virtual-sensed state $\widehat{x}(t)$ and innovation/residual
  series $r(t)$ used by the HNN guardian \citep{Lu2021DeepONet,hossain2024virtualsensing}.
\end{enumerate}

\subsection{Sampling rates and latency budgets}
\label{appF:sampling_latency}

The gating logic assumes the ability to estimate (i) fast envelope violations (POI $dP/dt$) and (ii) structured
forcing (frequency content near sensitive bands). This forces a two-tier telemetry stack:

\paragraph{Tier 1 (synchrophasor):} low-to-medium rate, grid-aligned state.
Synchrophasors provide $V,I,P,Q,f,\dot{f}$ at standardized reporting rates (e.g., 30--120 frames/s)
\citep{ieee_c37118}. This tier supports \emph{grid-visible} adequacy/contingency analysis and
coarse control-state correlation.

\paragraph{Tier 2 (waveform / high-rate power):} high rate, protection- and sprint-relevant state.
To avoid blind spots on millisecond-scale compute transients, the facility must maintain a waveform
or high-rate sampling layer at the POI and (ideally) at distribution aggregation points.

\begin{definition}[Rise-time-driven sampling rule]
Let $\tau_r$ be the smallest rise time of interest (e.g., the fastest meaningful aggregate power transition).
A conservative sampling rule is
\begin{equation}
f_s \;\ge\; \frac{10}{\tau_r},
\label{eq:sampling_rule}
\end{equation}
so that step-like events are represented by at least $\sim 10$ samples over the rise interval.%
\footnote{This is a practical engineering rule, not a theorem of information theory. It prevents pathological
under-sampling where $dP/dt$ estimates are dominated by quantization and clock jitter.}
\end{definition}

If compute can swing materially over $\tau_r \sim 5$--$10$ ms at campus aggregation (as your sprint framing implies),
then \cref{eq:sampling_rule} implies $f_s \gtrsim 1$--$2$ kHz \emph{at the aggregation point}.
Waveform capture at 5--20 kHz at the POI is therefore a defensible minimum for sub-cycle visibility.

\paragraph{Latency budget.}
Admission gates (Sequence A) are only meaningful if the decision uses \emph{fresh} telemetry. Define:
\begin{equation}
\Delta t_{\text{E2E}} := \Delta t_{\text{measure}} + \Delta t_{\text{transport}} + \Delta t_{\text{compute}} + \Delta t_{\text{actuate}}.
\end{equation}
A conservative operational target is:
\begin{equation}
\Delta t_{\text{E2E}} \le 50\ \text{ms} \quad \text{(sprint gating loop)}, \qquad
\Delta t_{\text{E2E}} \le 500\ \text{ms} \quad \text{(scarcity / staged curtailment)}.
\label{eq:latency_targets}
\end{equation}
These are not nuclear control loop requirements; they are \emph{interface} requirements for compute admission and
buffer dispatch.

\subsection{Clock synchronization and time alignment (the audit invariant)}
\label{appF:clock_sync}

All three planes must share a common time base, with bounded relative error.

\paragraph{Synchronization mechanism.}
The recommended baseline is IEEE~1588 Precision Time Protocol (PTP) for LAN synchronization, backed by GNSS
(or equivalent) at the grandmaster and holdover discipline for loss-of-signal resilience \citep{ieee_1588}.%
\footnote{If you use IRIG-B in parts of the OT stack, that is fine; the key is an end-to-end measurable
time error bound and a procedure for handling GNSS loss (holdover + drift logging).}

\begin{definition}[Time alignment error]
Let $\varepsilon_t$ be the maximum relative timestamp error between the electrical plane and compute plane streams
after synchronization (including any resampling/aggregation).
\end{definition}

\begin{proposition}[Timestamp error bound needed for $dP/dt$ enforcement]
\label{prop:dt_error}
Suppose the gate enforces $|dP/dt|\le R_{\text{safe}}$ at the POI using finite differences over a window $\Delta$:
\begin{equation}
\widehat{\dot{P}}(t) := \frac{P(t)-P(t-\Delta)}{\Delta}.
\end{equation}
If timestamps incur an unknown relative error bounded by $|\delta|\le \varepsilon_t$, then the worst-case induced
error in the estimated derivative is bounded by:
\begin{equation}
\bigl|\widehat{\dot{P}}(t)-\dot{P}(t)\bigr|
\;\lesssim\;
\frac{2\,\varepsilon_t}{\Delta}\,\sup_{\tau\in[t-\Delta,t]}|\dot{P}(\tau)|
\;+\; O(\varepsilon_t^2).
\label{eq:dPdt_time_error}
\end{equation}
\end{proposition}

\begin{proof}
A timestamp skew perturbs the evaluation points by at most $\varepsilon_t$ on each endpoint; a first-order Taylor
expansion yields $P(t+\delta_1)-P(t-\Delta+\delta_2)=P(t)-P(t-\Delta)+\dot{P}(\xi_1)\delta_1-\dot{P}(\xi_2)\delta_2$.
Divide by $\Delta$ and bound $|\delta_i|\le\varepsilon_t$ to obtain \cref{eq:dPdt_time_error}. \qedhere
\end{proof}

\paragraph{Implication.}
If you want tight $dP/dt$ enforcement using small $\Delta$, you must bound $\varepsilon_t$ correspondingly.
This is why \emph{microsecond-class} synchronization is defensible at the POI waveform layer, and why you must log
time quality in the \texttt{ATTEST\_BUNDLE}.%
\footnote{Reviewer-proof claim: if time quality degrades (GNSS loss, PTP instability), the system must either
(i) increase $\Delta$ (less sharp enforcement) or (ii) enter a conservative mode (deny sprints).}

\subsection{Anti-aliasing and resampling constraints (no blind spots)}
\label{appF:anti_alias}

Any downsampling from waveform/high-rate to settlement or gate features must satisfy basic anti-aliasing.

\begin{definition}[Anti-aliasing condition]
Let $f_s$ be the sampling rate and $f_c$ be the effective low-pass cutoff of the anti-alias filter prior to
decimation. A conservative condition is:
\begin{equation}
f_c \le 0.4\,f_s,
\end{equation}
and after decimation by factor $M$, the effective cutoff must satisfy $f_c \le 0.4\,f_s/M$.
\end{definition}

\paragraph{No blind spots condition (operational).}
Define a set of sensitive bands $\Omega_0$ (including resonance-adjacent frequencies) and a maximum allowed
unobserved energy in those bands. In practice:
\begin{equation}
\int_{\omega\in\Omega_0} \bigl|\mathcal{F}[P_{\text{AI}}](\omega)\bigr|^2 d\omega
\quad \text{must be estimable from recorded telemetry with bounded error.}
\end{equation}
If the sampling/anti-alias chain makes this quantity non-identifiable, your resonance defenses are rhetorical.

\subsection{Minimum observability ledger fields (audit + replay)}
\label{appF:ledger_fields}

To make the interface contract replayable, log the following in addition to your settlement fields:

\begin{longtable}{@{}p{0.26\linewidth}p{0.69\linewidth}@{}}
\toprule
\textbf{Field} & \textbf{Definition / Notes} \\
\midrule
\texttt{time\_quality\_ptp, time\_quality\_gnss} & Time sync health indicators; include max skew estimate $\varepsilon_t$. \\
\texttt{poi\_phasor\_fps} & Synchrophasor reporting rate (frames/s). \\
\texttt{poi\_waveform\_fs} & Waveform sampling rate (Hz) or high-rate equivalent. \\
\texttt{pdu\_fs, rack\_fs} & Effective sampling rates for distribution/rack aggregation signals. \\
\texttt{anti\_alias\_fc} & Anti-alias cutoff used prior to any decimation. \\
\texttt{latency\_e2e\_ms} & End-to-end latency $\Delta t_{\text{E2E}}$ at decision time; log mean and max. \\
\texttt{dPdt\_estimator\_window} & $\Delta$ used for $dP/dt$ estimation; ties to \cref{prop:dt_error}. \\
\texttt{band\_Omega0} & The $\Omega_0$ band set active at the time (change-controlled); store as a versioned config ID. \\
\texttt{band\_weights\_W} & The spectral weight function $W(\omega)$ used in scoring (or an ID pointing to a stored curve). \\
\texttt{welch\_params} & PSD estimator parameters (window type/length, overlap, FFT length) used for $\mathcal{F}$-based features. \\
\texttt{quantization\_bits} & Effective ADC/measurement resolution (POI waveform and distribution meters), for noise floor audits. \\
\texttt{calibration\_stamp} & Calibration version for POI sensors/meters (gain/phase corrections, CT/PT ratios). \\
\texttt{missing\_data\_flags} & Explicit flags for gaps, dropouts, packet loss, and imputation (if any). \\
\texttt{event\_markers} & Protective device events (breaker/relay operations), time-stamped and time-quality tagged. \\
\texttt{aggregation\_map} & Mapping from rack/PDU signals to campus/feeder aggregates; include topology version. \\
\texttt{feature\_hash} & Hash of derived feature vectors used by the HNN gate to ensure replayability. \\
\texttt{raw\_trace\_pointers} & Content-addressable pointers (hashes/URIs) to raw waveform/phasor/log archives for forensic replay. \\
\bottomrule
\end{longtable}

\footnote{Practical rule: if any field required to reconstruct $dP/dt$, PSD energy in $\Omega_0$, or time-quality
$\varepsilon_t$ is missing, the gate must degrade to conservative mode (deny sprints / clamp $\sigma(t)\!\to\!1$).
That is the operational meaning of an ``observability contract.''}

% =====================================================================
% F.6 — Estimator obligations (what your gates implicitly assume)
% =====================================================================
\subsection{Estimator obligations for gating: derivative, spectral energy, and residual consistency}
\label{appF:estimators}

The admission and anomaly gates depend on three estimators. If these estimators are not well-defined under the
telemetry pipeline, the gates are not enforceable.

\subsubsection{$dP/dt$ estimation at the POI}
\label{appF:dpdt_estimation}

Let $P(t)$ be the POI real power trace. In implementation, the gate uses a discrete-time estimator at sampling rate
$f_s$ (or feature update interval). Let $\Delta$ be the effective differencing window.

\begin{definition}[Windowed derivative estimator]
For a chosen window $\Delta=k/f_s$, define
\begin{equation}
\widehat{\dot{P}}(t_i) := \frac{P(t_i)-P(t_{i-k})}{\Delta}.
\label{eq:dpdt_est}
\end{equation}
\end{definition}

\paragraph{Bias--variance tradeoff.}
Small $\Delta$ improves responsiveness but amplifies time jitter (\cref{prop:dt_error}) and measurement noise. Large
$\Delta$ smooths noise but can hide sub-window spikes. This is not a stylistic choice; it defines what you can
meaningfully claim about $R_{\text{safe}}$ enforcement.

\begin{proposition}[Detectability condition for a sprint impulse]
\label{prop:detectability}
Consider a step-like change $\Delta P$ with rise time $\tau_r$. Suppose the telemetry produces feature updates at
interval $\Delta$. If $\Delta \gg \tau_r$, then the estimator \cref{eq:dpdt_est} cannot reliably detect the peak
$\max|\dot{P}|$; it detects an averaged slope $\approx \Delta P/\Delta$. A necessary condition for peak detection is
\begin{equation}
\Delta \;\lesssim\; \tau_r.
\label{eq:detect_condition}
\end{equation}
\end{proposition}

\begin{proof}
If the change completes inside a single feature window, then $P(t_i)-P(t_{i-k})$ reflects only the net change,
not the intra-window peak rate. Thus the estimator upper bounds at $\Delta P/\Delta$ even if the true peak
$\Delta P/\tau_r$ is much larger. Condition \cref{eq:detect_condition} is therefore necessary for resolving the
peak. \qedhere
\end{proof}

\footnote{This proposition is why ``15-minute telemetry'' is fundamentally incompatible with sprint gating. Even
``1-second telemetry'' can be insufficient if the facility’s relevant $\tau_r$ is in the 5--50 ms range at
aggregation.}

\subsubsection{Spectral energy estimation in sensitive bands $\Omega_0$}
\label{appF:spectral_energy_est}

Your resonance defenses assume you can estimate energy in $\Omega_0$ from recorded telemetry. Define a
short-window PSD estimate $S_P(\omega;t)$ using Welch’s method (or an equivalent), computed on a window of length
$T_w$ with overlap.

\begin{definition}[Band energy feature]
Define the band energy feature
\begin{equation}
E_{\Omega_0}(t) := \int_{\omega\in\Omega_0} S_P(\omega;t)\,d\omega.
\label{eq:band_energy}
\end{equation}
\end{definition}

\paragraph{Resolution obligation.}
If your band of interest contains low-frequency plant modes, the PSD window must be long enough to resolve them.
Let $\Delta f \approx 1/T_w$ be the frequency resolution. If $\Omega_0$ contains features of width $\delta f$,
a conservative condition is:
\begin{equation}
T_w \;\gtrsim\; \frac{1}{\delta f}.
\label{eq:psd_resolution}
\end{equation}

\footnote{This creates a deliberate two-timescale design: high-rate sampling to avoid aliasing and to preserve
waveform events, plus long-enough windows for reliable low-frequency mode detection. The system can do both if it
stores raw data and computes multi-resolution features.}

\subsubsection{Residual consistency: linking DeepONet outputs to measured physics}
\label{appF:residual_consistency}

If DeepONet virtual sensing is used, then the cyber--physical score relies on innovations/residuals of the form
$r(t)=y_{\text{meas}}(t)-\widehat{y}(t)$ (or the vector analogue). To make residuals meaningful you must:
(i) time-align measured and predicted quantities; (ii) log the model/version; (iii) log uncertainty estimates used
for normalization; and (iv) maintain change control when models are updated.

\begin{definition}[Normalized innovation]
Let $\widehat{y}(t)$ be a DeepONet prediction and let $\widehat{\Sigma}(t)$ be its uncertainty proxy (from Appendix F
UQ). Define
\begin{equation}
z(t) := \widehat{\Sigma}(t)^{-1/2}\bigl(y_{\text{meas}}(t)-\widehat{y}(t)\bigr).
\label{eq:normalized_innovation}
\end{equation}
\end{definition}

\footnote{If you do not log $\widehat{\Sigma}(t)$ (or a defensible proxy), the threshold $\tau$ in your HNN gate is
not portable across operating regimes. A threshold on raw residuals is a hidden regime assumption.}

% =====================================================================
% F.7 — “No blind spots” conditions (what forces conservative fallback)
% =====================================================================
\subsection{No-blind-spots conditions and conservative fallback logic}
\label{appF:no_blind_spots}

The gating contract must explicitly state the conditions under which the system is \emph{not} allowed to sprint.

\begin{definition}[No-blind-spots conditions]
The facility is considered \emph{observable for sprint gating} at time $t$ only if all hold:
\begin{enumerate}[label=\textbf{NB\arabic*.}]
  \item \textbf{Time quality:} $\varepsilon_t \le \varepsilon_{\max}$ (bounded timestamp skew).
  \item \textbf{Sampling adequacy:} $f_s$ and differencing window $\Delta$ satisfy \cref{eq:sampling_rule} and
  \cref{eq:detect_condition} for the current $\tau_r$ envelope.
  \item \textbf{Anti-alias compliance:} decimation filters meet the anti-aliasing condition and the band energy
  \cref{eq:band_energy} remains identifiable.
  \item \textbf{Completeness:} missing data does not exceed a configured threshold (e.g., $<0.1\%$ over the last
  $T_w$ window), and no critical stream is stale beyond the latency budget \cref{eq:latency_targets}.
\end{enumerate}
\end{definition}

\begin{proposition}[Conservative fallback correctness]
\label{prop:fallback}
If any NB condition fails, then clamping $\sigma(t)\to 1$ and forcing $u_f(t)\to 0$ weakly reduces the probability
of violating $R_{\text{safe}}$ and of injecting high-energy oscillations into $\Omega_0$, relative to permitting
sprints under partial observability.
\end{proposition}

\begin{proof}
When observability fails, the gate cannot certify that proposed actions satisfy the envelope constraints. The
conservative action removes discretionary amplification sources: sprints (which increase high-frequency content and
$dP/dt$) and flexible tranche activity (which is the controllable swing component). Therefore the action weakly
reduces exposure to both constraint classes compared to an action that allows additional variability under unknown
state. \qedhere
\end{proof}

\footnote{This is the reviewer-proof argument for why sprint permissions must be conditional on telemetry health.
If measurement integrity degrades, the correct response is not ``keep sprinting and hope''; it is ``degrade to a
safe policy.''}

% =====================================================================
% F.8 — Practical deployment notes (compression, retention, and audit)
% =====================================================================
\subsection{Retention, compression, and audit replay requirements}
\label{appF:retention}

Waveforms are large. The solution is not to abandon them; it is to specify retention tiers.

\paragraph{Tiered retention.}
\begin{itemize}
  \item \textbf{Tier-0 (hot cache):} recent raw waveforms + event logs (e.g., 7--30 days) for rapid incident response.
  \item \textbf{Tier-1 (warm archive):} downsampled/feature-complete traces plus cryptographic hashes linking to
  immutable raw segments referenced by \texttt{ATTEST\_BUNDLE}.
  \item \textbf{Tier-2 (cold storage):} long-term retention of only (i) hashes, (ii) decision records, and (iii) a
  small subset of raw segments associated with denials, trips, or anomalies.
\end{itemize}

\paragraph{Audit replay invariant.}
For any \texttt{GRANT/DENY} decision, a third party must be able to reconstruct the input feature vector, the
thresholds $(R_{\text{safe}},\Omega_0,\tau)$, the time-quality state, and the oracle outputs used at decision time.
If that is not replayable, the contract is not enforceable.

% =====================================================================
% F.9 — Feature schema for HNN gating (definition, normalization, invariants)
% =====================================================================
\subsection{Feature schema for HNN gating: definitions, normalization, and invariants}
\label{appF:feature_schema}

This section specifies a minimum viable feature schema for the HNN guardian gate used in Sequence~A
(\texttt{HNN\_GATE}) and referenced by the physics-consistency score in \cref{eq:physics_score}. The goal is not
model novelty; it is \emph{auditability}: a reviewer (or regulator) must be able to reconstruct the feature vector
from raw telemetry and reproduce the accept/deny decision.

\subsubsection{Feature families (multi-resolution, three-plane)}
\label{appF:feature_families}

Let $\Delta$ denote the fast gating interval (e.g., 10--50 ms), and let $T_w$ denote the spectral window length
(e.g., 2--30 s) used for PSD features in \cref{eq:band_energy}. Define a feature map
\begin{equation}
\phi(t) \;:=\; \bigl[\phi_{\text{elec}}(t)\;\;\; \phi_{\text{compute}}(t)\;\;\; \phi_{\text{plant}}(t)\bigr],
\end{equation}
where each block is itself a concatenation of fast and slow features.

\paragraph{Electrical-plane features $\phi_{\text{elec}}(t)$.}
At minimum:
\begin{align}
\phi_{\text{elec}}^{\text{fast}}(t) &=
\bigl[P_{\text{avg}}(t),\,P_{\max}(t),\,Q_{\text{avg}}(t),\,|dP/dt|_{\max}(t),\,f(t),\,\dot{f}(t)\bigr],\\
\phi_{\text{elec}}^{\text{spec}}(t) &=
\bigl[E_{\Omega_0}(t),\,E_{\Omega_1}(t),\,\rho_{\Omega_0}(t)\bigr],
\end{align}
where $E_{\Omega_0}(t)$ is the sensitive-band energy from \cref{eq:band_energy}, $\Omega_1$ is a reference band
(non-sensitive, used as a baseline), and $\rho_{\Omega_0}(t):=E_{\Omega_0}(t)/(E_{\Omega_0}(t)+E_{\Omega_1}(t))$
is a normalized band ratio (more stable under gain drift).

\paragraph{Compute-plane features $\phi_{\text{compute}}(t)$.}
At minimum:
\begin{align}
\phi_{\text{compute}}(t) &=
\bigl[\sigma(t),\,u_s(t),\,u_f(t),\,\Delta\sigma(t),\,\Delta u_f(t),\,\texttt{job\_admit\_count}(t)\bigr],
\end{align}
where $\Delta\sigma(t)$ and $\Delta u_f(t)$ are command deltas within the last gating interval.

\paragraph{Plant-physics features $\phi_{\text{plant}}(t)$.}
At minimum (direct measurements and/or virtual sensing):
\begin{align}
\phi_{\text{plant}}(t) &=
\bigl[\Delta T_{\text{safe}}(t),\,\widehat{\sigma}_{\max}(t),\,\|z(t)\|_2^2,\,\texttt{bop\_margin\_flags}(t)\bigr],
\end{align}
where $z(t)$ is the normalized innovation from \cref{eq:normalized_innovation} and
$\widehat{\sigma}_{\max}(t)$ is the DeepONet-derived sprint cap used by Sequence~A.

\footnote{A common failure mode is to treat plant physics as ``slow'' and omit it from the gating feature vector.
That defeats the entire cyber--physical premise: an authenticated command can still be physically dangerous. The
feature schema must \emph{force} the model to see physics.}

\subsubsection{Normalization: make thresholds portable across regimes}
\label{appF:normalization}

To make anomaly thresholds and classifier outputs portable across operating conditions, normalize features to a
reference benign distribution and explicitly log the normalization parameters.

\begin{definition}[Robust normalization]
Let $\tilde{x}$ be a raw scalar feature (e.g., $|dP/dt|_{\max}$, $E_{\Omega_0}$). Define:
\begin{equation}
x \;:=\; \frac{\tilde{x}-\mathrm{med}(\tilde{x})}{\mathrm{MAD}(\tilde{x})+\epsilon},
\label{eq:robust_norm}
\end{equation}
where $\mathrm{med}$ is the median and $\mathrm{MAD}$ the median absolute deviation computed over a benign baseline
window, and $\epsilon$ is a small stabilizer.
\end{definition}

\paragraph{Why robust (median/MAD) matters.}
Benign telemetry can include occasional spikes (switching, breaker events, operator tests). Mean/variance scaling
can be brittle; median/MAD yields stable normalization and improves audit portability.%
\footnote{If you prefer z-score normalization, it is fine, but you must then define explicit outlier-handling and
drift policies. The key is not the choice; it is that the choice is logged and replayable.}

\subsubsection{Audit invariants: reproducibility of the feature vector}
\label{appF:audit_invariants}

The following must be logged (per interval, or per config version) to reconstruct $\phi(t)$ exactly:
\begin{itemize}
  \item window definitions: $\Delta$, $T_w$, overlap, FFT length;
  \item PSD estimator parameters (see \texttt{welch\_params});
  \item normalization parameters (median/MAD or mean/std) per feature;
  \item band definitions: $\Omega_0$, $\Omega_1$, and weight curve ID $W(\omega)$;
  \item time-quality state: $\varepsilon_t$, dropout flags, latency values.
\end{itemize}

\begin{proposition}[Feature replayability implies decision replayability]
\label{prop:feature_replay}
If (i) raw telemetry pointers are content-addressable (hash-stable), and (ii) all feature extraction parameters are
logged immutably, then the derived $\phi(t)$ is reproducible. If the HNN decision function is also versioned and
logged (model hash), then \texttt{GRANT/DENY} decisions are replayable from evidence.
\end{proposition}

\begin{proof}
Given content-addressable raw inputs, deterministic extraction plus logged parameters yields deterministic
features. Given a fixed model hash and threshold configuration, the decision is a deterministic function of the
features. \qedhere
\end{proof}

% =====================================================================
% F.10 — Test vectors and acceptance criteria (prove “no blind spots”)
% =====================================================================
\subsection{Test vectors and acceptance criteria: proving the observability contract}
\label{appF:test_vectors}

An observability contract is only real if it can be falsified in commissioning. This section defines test vectors
(synthetic and operational) and acceptance criteria that map directly to the gate assumptions in
\cref{appF:no_blind_spots} and the estimator obligations in \cref{appF:estimators}.

\subsubsection{Test class 1: sprint impulse detectability}
\label{appF:test_sprint_impulses}

\paragraph{Definition.}
Inject controlled step-like changes in campus load at known amplitudes and rise times:
\begin{equation}
P_{\text{test}}(t) = \bar{P} + \Delta P \cdot s\!\left(\frac{t-t_0}{\tau_r}\right),
\end{equation}
where $s(\cdot)$ is a smooth step approximation (e.g., sigmoid) and $\tau_r$ is configurable.

\paragraph{Acceptance criterion (peak-rate resolution).}
For each test $(\Delta P,\tau_r)$, the system must:
\begin{enumerate}[label=\textbf{T1.\arabic*}]
  \item record a waveform/high-rate trace at the POI and at distribution aggregation;
  \item estimate $|dP/dt|_{\max}$ within a specified tolerance of the known injected value $\Delta P/\tau_r$;
  \item not misclassify the event as benign if it violates the configured $R_{\text{safe}}$ constraint.
\end{enumerate}

A reviewer-proof minimum is:
\begin{equation}
\left|\widehat{|dP/dt|_{\max}} - \frac{\Delta P}{\tau_r}\right| \;\le\; \eta_{\dot{P}}\cdot \frac{\Delta P}{\tau_r},
\qquad \eta_{\dot{P}}\in[0.1,0.25],
\end{equation}
for all rise times inside the designed envelope.

\footnote{If you cannot meet this, you either (i) increase sampling and improve time quality, or (ii) admit that
your $R_{\text{safe}}$ constraint is not enforceable and must be replaced by slower envelope controls.}

\subsubsection{Test class 2: spectral-band observability (resonance defense)}
\label{appF:test_spectral}

\paragraph{Definition.}
Inject a sinusoidal forcing component into flexible load (or emulate via inverter dispatch):
\begin{equation}
P_{\text{test}}(t)=\bar{P} + A\sin(\omega t),
\end{equation}
with $\omega$ swept across $\Omega_0$ and nearby bands.

\paragraph{Acceptance criterion (band energy identification).}
For each $\omega$ and amplitude $A$, the PSD estimator must place energy in the correct band and produce a stable
estimate of $E_{\Omega_0}(t)$. Require:
\begin{equation}
\frac{E_{\Omega_0}(t)}{E_{\Omega_0}(t)+E_{\Omega_1}(t)} \;\ge\; 1-\eta_{\Omega},
\qquad \eta_{\Omega}\in[0.05,0.15],
\end{equation}
when $\omega\in\Omega_0$, and the reverse inequality when $\omega\notin\Omega_0$ (up to leakage tolerance).

\subsubsection{Test class 3: clock skew and dropout fault injection}
\label{appF:test_time_faults}

\paragraph{Definition.}
Artificially degrade time sync or introduce bounded timestamp offsets between planes (compute vs electrical), and
introduce controlled packet loss/dropouts in one telemetry stream.

\paragraph{Acceptance criterion (conservative fallback).}
When any NB condition fails, the system must:
\begin{enumerate}[label=\textbf{T3.\arabic*}]
  \item explicitly log the NB violation (e.g., $\varepsilon_t>\varepsilon_{\max}$, missing waveform);
  \item automatically clamp sprint permissions (deny $\sigma$ increases) and shed flexible tranche ($u_f\to 0$);
  \item refuse to produce a \texttt{GRANT} record that claims envelope certification without sufficient telemetry.
\end{enumerate}

This test operationalizes \cref{prop:fallback}. If the system continues sprinting under degraded observability, the
contract is violated.

\subsubsection{Test class 4: cyber--physical inconsistency scenarios (HNN guardian)}
\label{appF:test_hnn_inconsistency}

\paragraph{Definition.}
Construct scenarios where digital commands appear authenticated and economically valid but are physically unsafe:
\begin{itemize}
  \item replay previously valid signed commands at the wrong time (replay attack);
  \item inject plausible price signals while commanding oscillations in $\Omega_0$;
  \item poison a subset of plant telemetry so that naive monitoring would approve a sprint.
\end{itemize}

\paragraph{Acceptance criterion (low false negatives under structured attacks).}
Define a test suite $\mathcal{T}$ of attack-like scenarios and benign scenarios. Require:
\begin{equation}
\mathrm{FNR}_{\mathcal{T}} \le \epsilon_{\text{fn}}, \qquad \mathrm{FPR}_{\mathcal{T}} \le \epsilon_{\text{fp}},
\end{equation}
with explicit target values. A conservative first-pass is $\epsilon_{\text{fn}}\le 1\%$ and
$\epsilon_{\text{fp}}\le 5\%$ for the gating classifier, acknowledging that thresholds can be tuned as operations
mature.%
\footnote{A low FNR is more important than a low FPR for safety gating, because a false negative can authorize a
harmful command. However, excessive FPR can destroy throughput and induce operator bypass behaviors. The correct
engineering move is to define explicit thresholds and change-control them (see calibration appendix), not to
hand-wave.}

% =====================================================================
% F.11 — Commissioning checklist (telemetry proof obligations)
% =====================================================================
\subsection{Commissioning proof obligations for telemetry (what you must demonstrate)}
\label{appF:commissioning_obligations}

Before permitting sustained sprinting in production, demonstrate:

\begin{enumerate}[label=\textbf{FPO\arabic*.}]
  \item \textbf{Derivative enforceability:} $|dP/dt|$ constraint is measurable within tolerance across the designed
        $\tau_r$ envelope (Test class 1).
  \item \textbf{Band observability:} $E_{\Omega_0}(t)$ is identifiable with bounded error for the defined $\Omega_0$
        set (Test class 2).
  \item \textbf{Time-quality safety:} telemetry time quality degrades trigger conservative fallback and are logged
        as such (Test class 3).
  \item \textbf{Guardian sensitivity:} HNN gate detects cyber--physical inconsistency scenarios with acceptable
        false negative rate (Test class 4).
  \item \textbf{Replayability:} at least $N$ randomly sampled \texttt{GRANT/DENY} decisions can be replayed from
        \texttt{ATTEST\_BUNDLE} evidence end-to-end (raw inputs $\rightarrow$ features $\rightarrow$ decision).
\end{enumerate}

\footnote{These are not ``nice-to-haves.'' They are the proof obligations implied by the existence of Sequence~A
as a claimed safety/security mechanism. If they are not met, the honest conclusion is that sprinting must be
treated as unsafe/unverifiable and disabled by default.}

\newpage

% =====================================================================
% APPENDIX G — ECONOMIC KERNEL ALGORITHMS (SCHEDULER/EMS CO-OPTIMIZATION)
% =====================================================================

\section{Economic Kernel Algorithms: Scheduler/EMS Co-Optimization}
\label{appG:kernel_algorithms}

This appendix specifies the \emph{algorithmic} content of the interface contract: how the scheduler and EMS jointly
compute admissible admissions, checkpoint timing, and staged curtailment under switching penalties. The goal is
to convert Sequences A/B/C into (i) executable pseudocode, (ii) provable safety claims, and (iii) audit-ready
proof artifacts (\texttt{ATTEST\_BUNDLE}) consistent with zero-trust gating \citep{candler2026_computeascde,Lu2021DeepONet}.

\subsection{Notation and primitives (what the algorithms may assume)}
\label{appG:notation}

We assume the interface exports the following \emph{planner-visible} primitives at decision time $t$:

\begin{itemize}
  \item \textbf{Telemetry features:} $P_{\text{POI}}(t)$, $\widehat{\dot P}(t)$, band energy estimates over $\Omega_0$,
        time-quality indicators, and latency budget fields from Appendix~F.
  \item \textbf{DeepONet feasibility oracle:} conservative headroom estimate $\widehat{\Delta T}_{\text{safe}}(t)$ and a
        conservative admissible sprint cap $\sigma_{\max}(t)$ over horizon $H$.
  \item \textbf{HNN guardian score:} physics-informed anomaly score $S(t)$ and threshold $\tau$ (plus class label).
  \item \textbf{Policy state:} scarcity flags $\mathbb{1}_{\text{scar}}(t)$, restricted operating modes,
        and lockout timers.
  \item \textbf{Workload tranche state:} $(u_s(t),u_f(t))$, switching penalty parameters, and checkpoint cost model.
\end{itemize}

The algorithms below are written as \emph{receding-horizon} policies: they re-solve at each decision step using
fresh telemetry, but they only commit the next action (admission / checkpoint / curtailment) and record a proof log.

\subsection{Admission control with a provable safety envelope}
\label{appG:admission_control}

We formalize Sequence A as an \emph{admission controller} that produces an action $a(t)$ governing the next compute
transition (job start, sprint factor increase, or ramp command). Let $\sigma(t)\in[1,\sigma_{\text{peak}}]$ be the
requested sprint factor and $\sigma_{\text{allow}}(t)$ be the allowed sprint factor after gating.

\paragraph{Safe set.}
Let $x(t)$ denote the plant-relevant state (possibly latent) and define a safe set:
\begin{equation}
\mathcal{X}_{\text{safe}} := \{x:\; T_{\text{out}} \le T_{\text{scram}}-\Delta,\;\; \text{BOP constraints satisfied},\;\; \text{POI envelope satisfied}\},
\end{equation}
where $\Delta>0$ is an explicit margin (not a rhetorical one). The controller must guarantee forward invariance
of $\mathcal{X}_{\text{safe}}$ in closed loop, under stated oracle conservatism conditions.

\subsubsection{Kernel Admission Algorithm (KAA)}
\label{appG:kaa}

\begin{quote}\ttfamily\small
\textbf{Kernel Admission Algorithm (KAA)} \\
Inputs at time t: req\_sigma, policy\_state, scarcity\_flag, telemetry, time\_quality, \\
\hspace*{1.55cm} oracle(headroom, sigma\_max), HNN(score S, threshold tau) \\
Outputs: sigma\_allow, decision{GRANT/DENY}, reason\_code, ATTEST\_BUNDLE \\
\\
1. AUTH: verify signature/nonce/scope; if fail -> DENY(AUTH\_FAIL). \\
2. POLICY: if scarcity\_flag=1 or restricted\_mode=1 -> clamp req\_sigma:=1; (continue). \\
3. TIME-QUALITY: if time\_quality degraded -> tighten R\_safe, widen derivative window Delta; \\
\hspace*{1.35cm} optionally clamp req\_sigma:=min(req\_sigma, sigma\_conservative). \\
4. ORACLE: query DeepONet -> headroom\_hat, sigma\_max(t); \\
\hspace*{1.35cm} set sigma\_oracle := min(req\_sigma, sigma\_max(t)). \\
5. ELECTRICAL: estimate dPdt; if |dPdt| > R\_safe -> DENY(POI\_RAMP\_UNSAFE). \\
6. RESONANCE: compute band energy near Omega0; if risk > threshold -> DENY(RESONANCE\_RISK). \\
7. HNN: compute S(t); if S(t) > tau -> DENY(HNN\_ANOMALY). \\
8. GRANT: sigma\_allow := sigma\_oracle; decision=GRANT. \\
9. LOG: write ATTEST\_BUNDLE with inputs, thresholds, oracle outputs, decision + hashes. \\
\end{quote}

\subsubsection{Safety theorem (forward invariance under conservative oracle gating)}
\label{appG:theorem_safety}

We now state the reviewer-proof obligation: \emph{if} the oracle is conservative in a precise sense and the
controller enforces the associated bounds, then the safe set is forward invariant.

\begin{assumption}[Oracle conservatism]
\label{ass:oracle_conservative}
For each $t$, the oracle outputs $\sigma_{\max}(t)$ such that for any admissible compute trajectory with
$\sigma(\tau)\le\sigma_{\max}(t)$ for $\tau\in[t,t+H]$, the true plant trajectory satisfies
$x(\tau)\in\mathcal{X}_{\text{safe}}$ for $\tau\in[t,t+H]$, provided the initial state $x(t)\in\mathcal{X}_{\text{safe}}$.
\end{assumption}

\begin{assumption}[Bounded unmodeled disturbance]
\label{ass:disturbance}
Unmodeled disturbances (measurement noise, exogenous grid perturbations, small actuation delays) are bounded in a
norm that is dominated by the explicit safety margin $\Delta$ (i.e., they cannot instantaneously jump state outside
$\mathcal{X}_{\text{safe}}$ within one decision step).
\end{assumption}

\begin{theorem}[Forward invariance of the coupling envelope]
\label{thm:forward_invariance}
Suppose (i) $x(t_0)\in\mathcal{X}_{\text{safe}}$, (ii) Assumptions~\ref{ass:oracle_conservative}--\ref{ass:disturbance}
hold, and (iii) the Kernel Admission Algorithm (KAA) enforces $\sigma(t)\le\sigma_{\max}(t)$ whenever it grants an
admission step, and denies otherwise. Then the closed-loop trajectory satisfies
\begin{equation}
x(t)\in\mathcal{X}_{\text{safe}} \quad \text{for all } t\ge t_0,
\end{equation}
up to the stated disturbance margin and decision period.
\end{theorem}

\begin{proof}
Fix any decision time $t$. If KAA denies the requested step, then the compute action does not increase forcing beyond
the previously admitted envelope; by Assumption~\ref{ass:disturbance}, bounded disturbances cannot violate the safety
margin in one step. If KAA grants, it enforces $\sigma(t)\le\sigma_{\max}(t)$, and by Assumption~\ref{ass:oracle_conservative}
the resulting forcing cannot drive the state outside $\mathcal{X}_{\text{safe}}$ over $[t,t+H]$. Receding-horizon
re-application at each decision time extends the guarantee forward. \qedhere
\end{proof}

\paragraph{What this theorem forces you to prove operationally.}
The entire coupling regime reduces to verifying the conservatism property in
Assumption~\ref{ass:oracle_conservative} under calibration, drift, and change control (handled in your Appendix~F
proof obligations), plus demonstrating that your telemetry is sufficient to enforce the electrical and resonance
checks.

\subsection{Checkpoint timing under switching penalties (stiff vs.\ flexible)}
\label{appG:checkpoint_timing}

We formalize ``checkpoint timing'' as a decision rule that reduces expected restart amplification while respecting
switching costs. Let $\chi$ be the checkpoint overhead in time/energy and let $C_{\text{restart}}$ be the expected
restart cost (energy + lost progress) conditional on interruption.

\subsubsection{A minimal model}
\label{appG:checkpoint_model}

Let $t$ index discrete control intervals. Define:
\begin{itemize}
  \item $\pi_t \in [0,1]$: interruption probability (or hazard) over the next interval, potentially conditioned on
  scarcity flags, time-quality degradation, or elevated HNN score.
  \item $G_t$: expected goodput rate if uninterrupted.
  \item $\chi_t$: checkpoint cost (seconds or energy-equivalent) if checkpoint executed now.
  \item $C_{\text{restart}}(V_{\text{state}},\text{phase})$: expected restart penalty; typically increasing in state size
  and critical phase of training.
\end{itemize}

A one-step expected value comparison yields the canonical rule:

\begin{lemma}[Checkpoint-before-risk inequality]
\label{lem:checkpoint_rule}
If a checkpoint at time $t$ reduces expected restart penalty by $\Delta C_{\text{restart}}$ in the next interval, then
checkpointing at $t$ is weakly preferred (in expected cost) whenever
\begin{equation}
\pi_t \cdot \Delta C_{\text{restart}} \;\ge\; \chi_t,
\label{eq:checkpoint_ineq}
\end{equation}
holding fixed the stiff tranche continuity requirement and ignoring higher-order interactions.
\end{lemma}

\begin{proof}
If you do not checkpoint, expected incremental cost from restart exposure is $\pi_t\,C_{\text{restart}}$.
If you checkpoint, you pay $\chi_t$ and the restart exposure drops by $\pi_t\Delta C_{\text{restart}}$.
Checkpointing is weakly preferred when $\chi_t \le \pi_t\Delta C_{\text{restart}}$, which is \cref{eq:checkpoint_ineq}. \qedhere
\end{proof}

\paragraph{Interpretation.}
This is the correct place to connect ``stiffness'' to a quantitative scheduling rule: $\Delta C_{\text{restart}}$
is enormous for stiff training (large $V_{\text{state}}$), so the inequality triggers checkpointing earlier and more
often near predicted scarcity or high anomaly likelihood.

\subsubsection{Checkpoint MPC (receding horizon)}
\label{appG:checkpoint_mpc}

Over a horizon $H$, define a binary decision $c_t\in\{0,1\}$ for checkpointing and a staged curtailment decision for
flex load. A minimal objective is:
\begin{equation}
\min_{c_{t:t+H},\,u_f(\cdot)} \sum_{\tau=t}^{t+H}\Bigl(
\underbrace{\chi_\tau c_\tau}_{\text{checkpoint overhead}}
+\underbrace{\pi_\tau(u_f)\,C_{\text{restart}}}_{\text{expected restart}}
+\underbrace{C_{\text{sw}}(u_f)}_{\text{switching penalty}}
+\underbrace{\mathbb{1}_{\text{scar}}(\tau)\,\kappa\,u_f(\tau)}_{\text{scarcity discouragement}}
\Bigr),
\end{equation}
subject to the admission envelope constraints from KAA and the freeze constraint on $u_s(\tau)$.
The structure is intentionally simple: the point is \emph{auditability} and monotone safety, not solving a perfect
stochastic program.

\subsection{Staged curtailment under switching penalties (Sequence B as an optimal policy)}
\label{appG:staged_curtailment}

We now give a formal statement for why ``shed flexible first'' is not merely intuitive but optimal under mild
conditions.

\begin{proposition}[Optimal curtailment ordering]
\label{prop:curtail_order}
Assume (i) stiff load $u_s(t)$ is continuity-constrained except under hard trips; (ii) flexible load $u_f(t)$
incurs a switching penalty $C_{\text{sw}}$ that is nondecreasing in the magnitude of reduction; and (iii) the
reliability externality cost during scarcity is increasing in net load and separable between tranches.
Then during scarcity intervals, any optimal policy curtails flexible tranche before curtailing stiff tranche,
unless infeasibility forces stiff curtailment.
\end{proposition}

\begin{proof}
Under the assumptions, the marginal benefit of curtailment in scarcity is a reduction in reliability externality,
while the marginal cost is switching penalty plus (for stiff) restart amplification. Because stiff curtailment
contains an additional restart term absent from flexible curtailment, its marginal cost dominates.
Thus, for any feasible curtailment amount, reallocating curtailment from stiff to flexible weakly decreases total
cost while maintaining the same reduction in net load, until flexible is exhausted. \qedhere
\end{proof}

\paragraph{What this buys you.}
This proposition justifies Sequence B as a policy that can be defended in review: it is not an arbitrary operational
choice but the optimal structure under a reliability-externality objective consistent with Compute-ASCDE.

\subsection{Executable artifacts (what must be logged)}
\label{appG:kernel_evidence}

For Appendix~H compliance, each kernel decision must produce:
\begin{itemize}
  \item \textbf{\texttt{ATTEST\_BUNDLE}:} signed inputs, oracle outputs, HNN score, thresholds, decision, reason code,
  and hash pointers to raw waveform and event traces.
  \item \textbf{\texttt{POLICY\_STATE}:} scarcity flags, restricted mode, and lockout timers.
  \item \textbf{\texttt{MPC\_SUMMARY}:} if checkpoint/curtailment MPC used, log objective components (not only outputs)
  to support audit replay.
\end{itemize}

\newpage

% =====================================================================
% APPENDIX H — SECURITY COMPLIANCE MAPPING (CROSSWALK TABLE)
% =====================================================================

\section{Security Compliance Mapping: Evidence Crosswalk for ZTA and OT Standards}
\label{appH:compliance_crosswalk}

This appendix provides a reviewer/auditor-facing crosswalk from the facility’s controls and logs (Sequences A/B/C,
Appendix F observability contract, and Appendix G kernel algorithms) to compliance artifacts typically expected under:
(i) NIST SP~800-207 Zero Trust Architecture \citep{NIST800207},
(ii) NERC CIP reliability standards (for utility-adjacent cyber regimes) \citep{NERC_CIP},
(iii) IEC~62443 OT security requirements framework \citep{IEC62443},
and (iv) NRC cyber security guidance for nuclear facilities \citep{NRC_RG571}.%
\footnote{The point is not that a single campus must always comply with every regime. The point is that your
controls produce \emph{evidence objects} that map cleanly onto the common structure of these regimes:
identity + access control, segmentation, change control, monitoring, incident response, and auditability.}

\subsection{Evidence objects (the ``what you hand an auditor'')}
\label{appH:evidence_objects}

We define the minimum evidence objects produced by the architecture:

\begin{itemize}
  \item \textbf{E1: \texttt{ATTEST\_BUNDLE}} — immutable record of each GRANT/DENY decision, including signatures,
  telemetry hashes, oracle outputs, HNN score, and reason codes.
  \item \textbf{E2: \texttt{TELEM\_PACK}} — time-synchronized telemetry bundle (phasors, waveforms, rack/PDU),
  including time-quality indicators and anti-alias metadata.
  \item \textbf{E3: \texttt{SEGMENT\_POLICY}} — micro-segmentation config snapshots, allow-lists, firewall rules,
  and identity policy (least privilege).
  \item \textbf{E4: \texttt{CHANGE\_CONTROL}} — versioned thresholds $(\tau,\Omega_0,R_{\text{safe}})$, DeepONet model
  hashes, training data provenance, and approval workflow.
  \item \textbf{E5: \texttt{IR\_CASEFILE}} — incident response package: isolation actions, safe-mode actions,
  forensic captures, recovery approvals.
\end{itemize}

\subsection{Crosswalk table (controls $\rightarrow$ evidence $\rightarrow$ regimes)}
\label{appH:crosswalk_table}

\begin{longtable}{@{}p{0.25\linewidth}p{0.26\linewidth}p{0.42\linewidth}@{}}
\toprule
\textbf{Control / Requirement} & \textbf{Your Control Primitive} & \textbf{Audit Evidence Produced (E1--E5)} \\
\midrule
\endfirsthead
\toprule
\textbf{Control / Requirement} & \textbf{Your Control Primitive} & \textbf{Audit Evidence Produced (E1--E5)} \\
\midrule
\endhead
\bottomrule
\endfoot

\textbf{Zero Trust: continuous verification; policy enforcement} \citep{NIST800207}
&
Sequence A gating (Authenticate, Policy screen, Oracle feasibility, HNN gate)
&
E1 \texttt{ATTEST\_BUNDLE} per admission; E3 policy + identities; E2 telemetry hashes referenced in E1 \\

\textbf{Zero Trust: segmentation and least privilege} \citep{NIST800207}
&
Micro-segmentation between scheduler, EMS, OT telemetry, and plant actuation planes
&
E3 \texttt{SEGMENT\_POLICY} snapshots; E1 denial reasons when segmentation prevents command path \\

\textbf{Monitoring / anomaly detection (OT)} \citep{IEC62443}
&
HNN guardian (physics-informed score $S(t)$; resonance band checks)
&
E1 includes $S(t),\tau,\Omega_0$; E2 includes waveforms/phasors + band-energy features; E5 for events \\

\textbf{Incident response and safe-state transitions} \citep{NIST800207,IEC62443}
&
Sequence C: isolate nodes, clamp $\sigma\to 1$, set $u_f\to 0$, forensic capture, dual-auth recovery
&
E5 \texttt{IR\_CASEFILE}; E1 shows immediate clamp actions; E2 forensic waveform bundles; E4 recovery approval \\

\textbf{Change control / configuration management} \citep{NERC_CIP,IEC62443}
&
Change control for $(\tau,\Omega_0,R_{\text{safe}})$, DeepONet model hash, and policy state machine
&
E4 \texttt{CHANGE\_CONTROL} with approvals + hashes; linkage from E1 to active versions at decision time \\

\textbf{Access control / authentication for critical cyber assets} \citep{NERC_CIP,NRC_RG571}
&
Signed commands + nonce + scope; allow-listed APIs; rate limits; replay protection
&
E1 signature verification logs; E3 identity policy; E5 if access anomalies triggered incident response \\

\textbf{Electronic security perimeter / boundary protections} \citep{NERC_CIP}
&
Segmentation of ESP-equivalent zones (control plane vs telemetry vs actuation)
&
E3 boundary configs + rule sets; E2 time-synced logs showing flows; E5 for boundary violations \\

\textbf{Malicious communications / monitoring of security events} \citep{NERC_CIP}
&
HNN guardian + network telemetry correlation with physical residuals $r(t)$
&
E2 network traces + residual series; E1 anomaly denials; E5 cases with captures \\

\textbf{Nuclear cyber guidance: defense-in-depth; monitoring; audit} \citep{NRC_RG571}
&
Plant-first supremacy; safety/feasibility supremacy clause; immutable decision logs
&
E1 replayable GRANT/DENY evidence; E5 safe-mode + plant-first actions; E4 documented margins and model changes \\

\textbf{Resource availability (DoS resilience)} \citep{IEC62443}
&
Rate limiting; safe-mode clamp; staged curtailment as controllable shock absorber
&
E3 configs; E1 logs showing throttling/clamps; E5 DoS casefiles; E2 telemetry proving impact containment \\

\end{longtable}

\subsection{``Proof of compliance'' playbook (how to answer the auditor)}
\label{appH:auditor_playbook}

For each compliance question, the facility should respond with a \emph{bundle} that is already produced by design:

\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{Show continuous verification:} provide a random sample of E1 bundles and replay the decision logic.
  \item \textbf{Show segmentation:} provide E3 snapshots + a diagram of allowed flows, tied to identities.
  \item \textbf{Show monitoring:} provide E2 + the feature extraction summary used by HNN/resonance checks.
  \item \textbf{Show change control:} provide E4 for the currently active thresholds and model versions.
  \item \textbf{Show incident response:} provide E5 for a red-team or simulated event, including recovery approvals.
\end{enumerate}

\paragraph{Key audit invariant.}
Every denial or clamp must be attributable to an explicit reason code that is supported by logged evidence:
\texttt{AUTH\_FAIL}, \texttt{THERMAL\_INFEASIBLE}, \texttt{POI\_RAMP\_UNSAFE}, \texttt{RESONANCE\_RISK}, \texttt{HNN\_ANOMALY}.
That is the difference between “we think it’s safe” and “we can prove it was safe.”

\newpage

% =====================================================================
% APPENDIX I — VALIDATION PROTOCOL AND RED-TEAM TEST BATTERY
% =====================================================================

\section{Validation Protocol and Red-Team Test Battery}
\label{appJ:validation_redteam}

This appendix specifies an auditable validation protocol for the coupled SMR--AI interface,
with an explicit red-team test battery designed to falsify the system under adversarial forcing.
The objective is not to ``demonstrate performance'' but to make the interface contract
\emph{reviewer-proof}: the facility must be able to (i) reproduce gate decisions from evidence logs,
(ii) bound the probability of safety violations under the declared operating envelope, and
(iii) quantify false-positive/false-negative tradeoffs for the HNN guardian and the feasibility oracle.

\subsection{Validation objectives and acceptance criteria}
\label{appJ:objectives_acceptance}

We separate three classes of requirements.

\paragraph{Safety invariants (non-negotiable).}
Define the set of safety violations over a validation run horizon as:
\begin{equation}
\mathcal{V}_{\text{safe}} :=
\Bigl\{
\texttt{THERMAL\_LIMIT\_BREACH},\;
\texttt{POI\_RAMP\_BREACH},\;
\texttt{RESONANCE\_BAND\_BREACH},\;
\texttt{PROTECTION\_MISOP}
\Bigr\}.
\end{equation}
A validation campaign is acceptable only if:
\begin{equation}
\Pr(\mathcal{V}_{\text{safe}})\le \alpha_{\text{safe}}
\quad\text{and}\quad
\widehat{\Pr}(\mathcal{V}_{\text{safe}})=0
\;\;\text{over the declared envelope tests,}
\label{eq:J_safe_accept}
\end{equation}
where $\alpha_{\text{safe}}$ is the facility’s declared residual risk target.\footnote{
For pilot-scale demonstrations, you can take the strict stance $\widehat{\Pr}(\mathcal{V}_{\text{safe}})=0$ on the
entire battery; at scale, the correct posture is to track an empirical upper confidence bound and require it to
remain below $\alpha_{\text{safe}}$.}

\paragraph{Decision replayability (audit invariant).}
Every \texttt{GRANT/DENY} decision in Sequences A/B/C must be replayable from linked evidence:
POI telemetry, rack/PDU power telemetry, signed scheduler/EMS events, DeepONet outputs/residuals (if deployed),
and HNN score outputs.\footnote{
Replayability is the line between ``we tested it'' and ``we can prove it later.'' It also forces time-alignment,
anti-aliasing, and log completeness to be treated as first-class engineering constraints.}

\paragraph{Detector performance under an explicit error budget.}
Let $D(t)\in\{0,1\}$ denote the HNN guardian alarm (1 = alarm) over an interval.
We define:
\begin{align}
p_{\text{FP}} &:= \Pr(D(t)=1 \mid \text{benign}), \\
p_{\text{FN}} &:= \Pr(D(t)=0 \mid \text{attack-like forcing in battery}).
\end{align}
Acceptance requires:
\begin{equation}
p_{\text{FP}} \le \beta_{\text{FP}}
\quad\text{and}\quad
p_{\text{FN}} \le \beta_{\text{FN}},
\label{eq:J_detector_accept}
\end{equation}
for declared budgets $\beta_{\text{FP}},\beta_{\text{FN}}$, with the key nuance that
$\beta_{\text{FN}}$ for attack-like forcing should be \emph{tighter} than $\beta_{\text{FP}}$.\footnote{
This is the correct asymmetry for a facility where compute is a sacrificial actuator: you tolerate more false
positives (lost sprint opportunities) than false negatives (unsafe admissions).}

\subsection{Threat-informed test taxonomy}
\label{appJ:taxonomy}

The battery is partitioned by the mechanism it stresses:

\begin{enumerate}[label=\textbf{J.\arabic*}]
\item \textbf{Transient stress:} step drops/steps up; burst trains; ramp-rate spikes.
\item \textbf{Spectral stress:} oscillatory forcing near sensitive bands $\Omega_0$ (including $\omega_0$).
\item \textbf{Telemetry integrity:} poisoning, delay/jitter injection, channel dropout, replay.
\item \textbf{Command-plane attacks:} spoofed price/scarcity flags, malicious job submissions, privilege misuse.
\item \textbf{Compound scenarios:} attacks that combine (i) spectral forcing and (ii) telemetry manipulation.
\end{enumerate}

Each test case yields:
(i) a ground-truth label (benign vs attack-like),
(ii) a safety outcome label (any $\mathcal{V}_{\text{safe}}$ event),
(iii) a gate outcome (grant/deny + reason codes),
and (iv) a replay bundle hash linking the decision to evidence.

\subsection{Stress tests: definitions and construction}
\label{appJ:stress_tests}

Let $P_{\text{AI}}(t)$ be the POI aggregate load and let $u_f(t),u_s(t)$ be the tranche controls.
Let the test harness emit workload commands (scheduler plane), while the observability contract records realized
power (electrical plane) and plant state (physics plane).

\subsubsection{J1: Step-drop / step-up transients (fast $dP/dt$)}
\label{appJ:step_tests}

Construct step transients:
\begin{equation}
P_{\text{AI}}(t)=\bar{P} + \Delta P \cdot \mathbf{1}\{t\ge t_0\},
\end{equation}
with $\Delta P$ spanning a test grid (e.g., $\pm 5\%, \pm 10\%, \pm 25\%, \pm 50\%$ of $\bar{P}$),
and with rise times spanning the feasible range of the campus actuation stack.\footnote{
The important variable is not only $\Delta P$ but the realized rise time $\tau_r$ (Appendix F). You should treat
``software step'' and ``electrical step'' as different until proven aligned by telemetry.}

\paragraph{Objective.}
Verify Sequence A denies steps that violate $R_{\text{safe}}$ or feasibility,
and verify the buffer dispatch layer absorbs admissible steps without triggering
any $\mathcal{V}_{\text{safe}}$ events.

\subsubsection{J2: Oscillatory forcing near \pdfmath{$\omega_0$}{omega0} (resonance targeting)}
\label{appJ:osc_tests}

Construct sinusoidal forcing with controlled amplitude and frequency:
\begin{equation}
P_{\text{AI}}(t)=\bar{P} + A\sin(\omega t),
\qquad \omega \in \Omega_0,
\end{equation}
where $\Omega_0$ is the facility’s sensitive band set (from calibration/change control).
Test a frequency sweep with $\omega$ stepping across $\Omega_0$ at multiple amplitudes $A$.

\paragraph{Objective.}
Verify the spectral guard ($W(\omega)$ weighting in your score logic) triggers either:
(i) staged curtailment / buffer response, or (ii) denial of admissions that would inject energy into $\Omega_0$.
Acceptance requires zero \texttt{RESONANCE\_BAND\_BREACH} events in the battery.

\subsubsection{J3: Burst trains (sprint impulse emulation)}
\label{appJ:burst_trains}

Construct burst trains:
\begin{equation}
P_{\text{AI}}(t)=\bar{P} + \sum_{k=1}^{K} A_k \cdot \mathbf{1}\{t\in[t_k,t_k+\Delta t_k]\},
\end{equation}
with randomized $\{A_k,\Delta t_k\}$ subject to plausible sprint policies,
including worst-case aligned bursts (high $A_k$ and short $\Delta t_k$).

\paragraph{Objective.}
Verify the admission gate respects $\sigma_{\max}(t)$ (or its proxy constraints),
and verify the buffer allocation layer avoids protection misoperations under high-frequency burst trains.

\subsubsection{J4: Telemetry poisoning and time skew (observability attack)}
\label{appJ:telemetry_poison}

Inject controlled telemetry faults:
\begin{itemize}
\item \textbf{Bias poisoning:} $y(t)\leftarrow y(t)+b$ on selected channels (e.g., temperature or power channels).
\item \textbf{Delay/jitter:} timestamps perturbed within bounded $\varepsilon_t$ (Appendix F), including worst-case
phase offsets between compute events and POI measurements.
\item \textbf{Dropout:} channel loss for $\Delta t$ windows; verify conservative mode engages.
\item \textbf{Replay:} old valid telemetry segments replayed with valid formatting but stale content.
\end{itemize}

\paragraph{Objective.}
The system must fail safe: if time quality degrades, admissions tighten or halt; if telemetry is inconsistent,
HNN scores should rise and denial/curtailment should occur.

\subsection{Acceptance thresholds and false-positive budgeting}
\label{appJ:thresholds_fp_budget}

Because red-team tests are finite, acceptance must be phrased in a way that is meaningful for auditors.

\subsubsection{A finite-sample acceptance rule}
\label{appJ:finite_sample_rule}

Let $n$ be the number of independent battery trials of a given test family and let $k$ be the number of failures
(either safety violations or required detections missed). A conservative one-sided (Clopper--Pearson) upper bound
for the true failure probability $p$ is:
\begin{equation}
p \le \mathrm{UCB}_{\delta}(k;n),
\end{equation}
where $\delta$ is a confidence parameter. For the strict ``zero failures'' case ($k=0$),
\begin{equation}
p \le 1-\delta^{1/n}.
\label{eq:J_zero_fail_ucb}
\end{equation}

\paragraph{Operational interpretation.}
If you demand $p\le \alpha_{\text{safe}}$ with confidence $1-\delta$, you must select $n$ large enough that
$1-\delta^{1/n}\le \alpha_{\text{safe}}$. This yields a direct sizing rule for the battery depth.\footnote{
This is why ``we ran a few tests'' is never a safety argument. You either quantify a bound, or you state you do not
have one yet.}

\subsubsection{False-positive budgeting (lost goodput accounting)}
\label{appJ:false_positive_budget}

False positives cost goodput. To prevent the guardian from degenerating into permanent denial, define a monthly
false-positive budget:
\begin{equation}
\sum_{t\in m}\mathbf{1}\{D(t)=1 \ \&\ \text{benign}\} \;\le\; B_{\text{FP}}(m),
\end{equation}
and require tuning such that \cref{eq:J_detector_accept} is satisfied while staying within $B_{\text{FP}}(m)$.\footnote{
This is the correct place to negotiate operator preferences: the security posture should not be smuggled in by
ad hoc threshold tweaks. It is a declared trade between sprint throughput and attack miss probability.}

\subsection{``What would fail this system'' (explicit falsification conditions)}
\label{appJ:failure_conditions}

A system that cannot be falsified cannot be trusted. The following conditions are explicit failures:

\begin{enumerate}[label=\textbf{\arabic*.}]
\item Any occurrence of $\mathcal{V}_{\text{safe}}$ during a test that the gate should have prevented
(e.g., admitted sprint leading to thermal breach).
\item Any successful telemetry replay/poisoning event that causes admissions inconsistent with physical reality
(i.e., \texttt{GRANT} when feasibility would be \texttt{DENY} under true signals).
\item Any inability to replay a \texttt{GRANT/DENY} decision from recorded evidence (missing logs, time misalignment,
or ambiguous threshold state).
\item Any nontrivial safety-relevant mode that is not observable under Appendix F telemetry requirements
(i.e., the system has blind spots but pretends it does not).
\item Any demonstrated non-stationarity/drift that invalidates calibration (e.g., $\Omega_0$ moved materially)
without triggering change control.
\end{enumerate}

\subsection{Validation reporting template (minimum deliverable)}
\label{appJ:report_template}

Each battery execution should output:
\begin{itemize}
\item Declared envelope: hardware config, cooling config, plant mode, policy state.
\item Test family and parameter grid (step sizes, $\omega$ sweep, burst durations).
\item Trial count $n$, failure count $k$, and upper bound \cref{eq:J_zero_fail_ucb} (or general UCB).
\item Confusion matrix for HNN (TP/FP/TN/FN) and realized $p_{\text{FP}},p_{\text{FN}}$ estimates.
\item A list of any \texttt{DENY} reason codes with frequencies (to diagnose over-conservatism).
\item Hash list of \texttt{ATTEST\_BUNDLE} artifacts for a sample of trials (audit sampling).
\end{itemize}

\newpage
% =====================================================================
% APPENDIX J — ATTESTATION AND ANTI-GAMING FOR GOODPUT PPA
% =====================================================================

\section{Attestation and Anti-Gaming for the Goodput PPA}
\label{appK:attestation_antigaming}

This appendix specifies an implementable measurement and verification scheme for the Goodput PPA
(settling on verified productive compute output, not MWh).
The key requirement is \emph{anti-gaming}: goodput must be difficult to inflate, easy to audit,
and reconcilable against physical counters (energy and performance telemetry).

\subsection{Threat model (how goodput can be gamed)}
\label{appK:threat_model}

Assume the buyer (compute operator) could attempt to inflate $G(t)$ by:
\begin{itemize}
\item \textbf{Replay:} resubmitting old attestations from prior intervals.
\item \textbf{Double counting:} claiming the same training work under multiple job IDs.
\item \textbf{Junk tokens/steps:} generating ``tokens'' not actually accepted by the training pipeline.
\item \textbf{Counter mismatch:} claiming goodput inconsistent with measured utilization/energy.
\item \textbf{Dispute shaping:} withholding logs or providing partial evidence to force settlement ambiguity.
\end{itemize}
Assume the seller (energy/operator) could attempt to degrade service or manipulate scarcity flags to extract
scarcity credits improperly; therefore both sides must have audit rights and evidence symmetry.

\subsection{A concrete attestation primitive: \texttt{ATTEST\_BUNDLE}}
\label{appK:attest_bundle}

For each settlement interval $t$, define an immutable evidence record:
\begin{equation}
\texttt{ATTEST\_BUNDLE}(t) :=
\Bigl(
t,\;
\mathcal{J}(t),\;
G(t),\;
\mathcal{H}(t),\;
\mathcal{C}(t),\;
\mathcal{E}(t),\;
\mathrm{Sig}_{\text{Buyer}}(t),\;
\mathrm{Sig}_{\text{Seller}}(t)
\Bigr),
\end{equation}
where:
\begin{itemize}
\item $\mathcal{J}(t)$ is the set of job IDs contributing to $G(t)$, with per-job digests.
\item $G(t)$ is the claimed goodput (tokens/steps) for the interval.
\item $\mathcal{H}(t)$ is a hash chain pointer to prior interval bundles (replay resistance by construction).
\item $\mathcal{C}(t)$ are compute counters (e.g., accelerator utilization, completed steps, checkpoint events).
\item $\mathcal{E}(t)$ are electrical/energy counters (PDU/rack energy, POI energy) for reconciliation.
\item $\mathrm{Sig}_{\text{Buyer}}(t)$ signs the bundle content; $\mathrm{Sig}_{\text{Seller}}(t)$ co-signs after
verification (or signs a dispute notice).
\end{itemize}

\paragraph{Hash chaining (anti-replay backbone).}
Define:
\begin{equation}
\mathcal{H}(t) := \mathrm{Hash}\!\left(\texttt{ATTEST\_BUNDLE}(t-1)\right),
\end{equation}
so that any replayed or reordered bundle breaks the chain.

\subsection{Goodput measurement definition (what counts as $G(t)$)}
\label{appK:goodput_definition}

To be audit-stable, $G(t)$ must be defined as \emph{accepted} work, not attempted work.

\paragraph{Training tokens (example definition).}
Let $\mathcal{T}(t)$ be the multiset of tokens that the training pipeline \emph{accepts} (after validation and
deduplication) during interval $t$. Define:
\begin{equation}
G(t) := |\mathcal{T}(t)|.
\end{equation}
Alternatively, for step-based definitions:
\begin{equation}
G(t) := \sum_{j\in\mathcal{J}(t)} \mathbf{1}\{\text{step } j \text{ committed}\},
\end{equation}
where ``committed'' means the optimizer step is written to an append-only training log and survives restart
reconciliation.\footnote{
The design principle is: if a restart invalidates work, it should not count. This aligns settlement with
continuity: the PPA pays for productive progress, not for churn.}

\subsection{Verification procedure (seller-side checks)}
\label{appK:verification_procedure}

For each interval $t$, the seller verifies:

\begin{enumerate}[label=\textbf{\arabic*}]
\item \textbf{Bundle integrity:} validate signatures, hash chain pointer $\mathcal{H}(t)$, and time window.
\item \textbf{No double count:} ensure job IDs in $\mathcal{J}(t)$ are unique and not previously settled.
\item \textbf{Counter reconciliation:} verify $G(t)$ is consistent with compute counters $\mathcal{C}(t)$
(utilization, step counters, checkpoint events) within declared tolerances.
\item \textbf{Energy reconciliation:} verify $G(t)$ is consistent with $\mathcal{E}(t)$ (rack/PDU energy and POI energy),
again within declared tolerances.
\item \textbf{Dispute branching:} if any check fails, the seller issues a signed \texttt{DISPUTE\_BUNDLE}(t)
containing the failing predicate and the evidence pointers.
\end{enumerate}

\subsubsection{A minimal reconciliation inequality (anti-inflation constraint)}
\label{appK:reconciliation_inequality}

Let $E_{\text{IT}}(t)$ be the IT energy (rack/PDU) over interval $t$ and let $g(t)$ be realized goodput.
Even without modeling, an anti-inflation constraint can be stated as:
\begin{equation}
\frac{G(t)}{E_{\text{IT}}(t)} \le \Gamma_{\max},
\label{eq:K_energy_goodput_cap}
\end{equation}
where $\Gamma_{\max}$ is a declared upper bound under the current hardware/software envelope.\footnote{
This is not claiming a universal constant; it is a change-controlled envelope bound. If the buyer upgrades hardware
or changes the workload mix, they can propose a new $\Gamma_{\max}$ with evidence. The point is: a claimed spike in
$G(t)$ must be physically explainable.}

\subsection{Replay protection and audit rights}
\label{appK:replay_audit}

\paragraph{Replay protection.}
Replay is blocked by:
(i) the hash chain $\mathcal{H}(t)$,
(ii) interval-specific nonces in the signed job digests,
and (iii) a settlement ledger that rejects re-used job IDs.

\paragraph{Audit rights.}
The contract should grant:
\begin{itemize}
\item \textbf{Routine audit:} seller can sample intervals and request raw per-job digests and counter snapshots.
\item \textbf{Triggered audit:} any material discrepancy triggers expanded audit scope for a rolling window.
\item \textbf{Third-party audit option:} mutually agreed auditor can inspect bundles under confidentiality.
\end{itemize}

\subsection{Dispute resolution logic (deterministic outcome)}
\label{appK:dispute_logic}

A dispute procedure must converge deterministically, not via negotiation.

\paragraph{Rule 1: evidence supremacy.}
If \texttt{ATTEST\_BUNDLE}(t) is missing required fields, settlement for that interval defaults to:
\begin{equation}
G(t)\leftarrow 0
\quad\text{until evidence is produced.}
\end{equation}

\paragraph{Rule 2: bounded adjustment.}
If the only failing predicate is reconciliation against energy/counters, and the evidence indicates over-claim,
settlement uses the conservative cap:
\begin{equation}
G_{\text{settle}}(t) := \min\Bigl(G_{\text{claim}}(t),\;\Gamma_{\max} E_{\text{IT}}(t)\Bigr).
\label{eq:K_conservative_settle}
\end{equation}

\paragraph{Rule 3: tamper indication triggers incident response coupling.}
If a dispute indicates tamper (replay attempts, forged signatures, inconsistent chain),
then the facility must treat it as a security incident:
Sequence C is triggered (safe-mode compute), and the audit window expands until cleared.

\subsection{Soundness properties (what this scheme guarantees)}
\label{appK:soundness}

We can state two reviewer-proof claims.

\begin{theorem}[Replay resistance under hash chaining]
\label{thm:K_replay_resistance}
Assume collision-resistant hashing and unforgeable signatures.
Then an attacker cannot replay a prior interval’s valid \texttt{ATTEST\_BUNDLE} as a new interval’s bundle
without detection, except with negligible probability.
\end{theorem}

\begin{proof}
A replayed bundle either (i) duplicates the interval timestamp $t$ (rejected by the settlement ledger), or
(ii) alters $t$ while retaining the old content, which invalidates signatures, or (iii) alters content to match $t$,
which breaks the hash chain $\mathcal{H}(t)$ unless a hash collision is found.
\end{proof}

\begin{theorem}[Conservative settlement under reconciliation cap]
\label{thm:K_conservative}
If \cref{eq:K_energy_goodput_cap} is valid for the declared envelope, then \cref{eq:K_conservative_settle}
guarantees that settled goodput does not exceed physically plausible output under that envelope.
\end{theorem}

\begin{proof}
Immediate from the definition: $G_{\text{settle}}(t)\le \Gamma_{\max}E_{\text{IT}}(t)$.
\end{proof}

\subsection{Implementation checklist (minimum viable deployment)}
\label{appK:impl_checklist}

Before using a Goodput PPA in production:
\begin{enumerate}[label=\textbf{\arabic*.}]
\item Define $G(t)$ precisely (tokens accepted vs steps committed) and instrument it.
\item Implement \texttt{ATTEST\_BUNDLE} creation with hash chaining and dual signatures.
\item Implement the verification checks and the deterministic dispute rules.
\item Establish $\Gamma_{\max}$ as a change-controlled envelope parameter (with evidence).
\item Bind disputes to security posture: tamper triggers Sequence C and tightened thresholds.
\end{enumerate}

\newpage

% =====================================================================
% APPENDIX K — PRICING MODEL IMPERFECTION (UQ TAX, FP BUDGET, REGULATORY STACK)
% =====================================================================

\section{Pricing Model Imperfection: Uncertainty Tax, False-Positive Budget, and the Regulatory Stack}
\label{appL:pricing_imperfection}

This appendix formalizes a reviewer-proof correction to the ``oracle contract'' narrative:
\emph{the DeepONet oracle and HNN guardian are not deterministic instruments.}
Their imperfection must be (i) explicitly bounded, (ii) conservatively derated into admissible sprint capacity,
and (iii) priced into the economic layer (survival and switching cost) so that model quality directly maps to
revenue and reliability risk \citep{candler2026_computeascde}.%
\footnote{In the Compute-ASCDE framing, reliability economics are tail-dominated and discontinuous in interruptions
(checkpoint/restart amplification). A control layer that ignores model error is therefore not merely ``optimistic'';
it is structurally mispriced \citep{candler2026_computeascde}.}

\subsection{DeepONet uncertainty as an explicit derating of admissible sprint capacity}
\label{appL:uq_derating}

In the main text, sprinting is feasible if DeepONet predicts sufficient thermal headroom over horizon $H$.
Let the relevant predicted state (or safety margin functional) be denoted
\begin{equation}
\widehat{h}(t;H) \;\; \text{(predicted headroom metric over horizon $H$)} ,
\end{equation}
with an uncertainty quantification (UQ) statistic $U(t;H)$ that upper-bounds prediction error at the
relevant confidence level (e.g., via ensembles, conformal calibration, or conservative residual envelopes)
\citep{Lu2021DeepONet,hossain2024virtualsensing,vovk2005_conformal,angelopoulos2023_conformal}.
We define a \textbf{confidence-discounted headroom}:
\begin{equation}
h_{\text{cons}}(t;H) := \widehat{h}(t;H) - \kappa\,U(t;H),
\label{eq:cons_headroom}
\end{equation}
where $\kappa \ge 1$ is a safety factor aligned to the chosen confidence level.%
\footnote{This is the bridge from ``AI approximates physics'' to ``AI is contractible under safety.'' The derating in
\cref{eq:cons_headroom} makes \emph{model uncertainty a first-class state variable} that reduces admissible sprint
capacity. Better model $\Rightarrow$ smaller $U(t;H)$ $\Rightarrow$ less derating $\Rightarrow$ more revenue
under the Goodput PPA structure \citep{candler2026_computeascde}.}

Let $\sigma_{\text{phys}}(t)$ be the physical sprint limit implied by plant constraints (valves, ramp limits,
thermal inertia) absent model uncertainty. Define the \textbf{admissible sprint cap}:
\begin{equation}
\sigma_{\max}(t) := \Bigl[\sigma_{\text{phys}}(t) - \kappa_\sigma\,U_\sigma(t)\Bigr]_+,
\label{eq:sigma_uq_tax}
\end{equation}
where $U_\sigma(t)$ is the uncertainty mapped into the sprint domain (via sensitivity of predicted headroom to
power trajectory), $\kappa_\sigma$ is the sprint-specific safety factor, and $[\cdot]_+$ is the positive-part
operator.%
\footnote{Operationally: the oracle should not output $\{\texttt{GRANT},\texttt{DENY}\}$ as if it were deterministic;
it should output $\sigma_{\max}(t)$ as the \emph{uncertainty-discounted} feasible sprint envelope.
This is consistent with DeepONet’s role as a fast operator surrogate \citep{Lu2021DeepONet,hossain2024virtualsensing}
and with the conservative envelope proof obligations in your interface contract (Appendix~F).}

\paragraph{Implementation constraint (gate semantics).}
Sequence A becomes mechanically ``grant if and only if $\sigma_{\text{request}}(t)\le\sigma_{\max}(t)$,'' where
$\sigma_{\max}(t)$ already embeds UQ via \cref{eq:sigma_uq_tax}. This moves uncertainty handling out of prose and
into an auditable scalar that is logged per \texttt{ATTEST\_BUNDLE} (and therefore becomes settlement-relevant under
the Goodput PPA ledger) \citep{candler2026_computeascde}.

\subsection{Mapping oracle imperfection into job survival and valuation}
\label{appL:uq_to_survival}

Compute-ASCDE’s economics are dominated by tail events for stiff workloads (interruptions, trips, restart cascades)
\citep{candler2026_computeascde}. The key correction is: \textbf{oracle uncertainty increases trip probability, which
reduces job survival.} Therefore, UQ must appear as a degradation factor in the survival term.\footnote{Project repository (Compute-ASCDE companion materials): \url{https://github.com/nousentllc/Compute-ASCDE-SMR---A-Reliability-Valuation-Planning-Interface}.}

Let $S_0(m)$ be the baseline survival probability over month $m$ absent oracle imperfection (or with a nominal
model quality). Define an additive trip hazard contribution induced by model imperfection:
\begin{equation}
\lambda_{\text{UQ}}(t) := \lambda_0 \, \phi\!\bigl(U(t;H)\bigr),
\qquad \phi(\cdot)\ \text{nondecreasing}, \ \lambda_0>0.
\label{eq:uq_hazard}
\end{equation}
Then a conservative survival adjustment is:
\begin{equation}
S(m) \;\le\; S_0(m)\,\exp\!\Bigl(-\int_{t\in m}\lambda_{\text{UQ}}(t)\,dt\Bigr).
\label{eq:survival_uq}
\end{equation}
\footnote{You do not need to claim this is the ``true'' hazard model. The reviewer-proof point is monotonicity:
larger UQ should not weakly increase survival. \cref{eq:survival_uq} enforces that property and makes the pricing
consequence immediate under any survival-sensitive valuation rule \citep{candler2026_computeascde}.}

\paragraph{Pricing consequence (direct).}
Any valuation expression that scales inversely with survival (or penalizes expected interruptions) now inherits an
\textbf{uncertainty premium}: higher $U(\cdot)$ lowers $S(m)$ and increases the implied cost per unit goodput. This
is the missing bridge between ``physics oracle'' and ``finance kernel'': \emph{model quality is a priced asset},
not a qualitative flourish \citep{candler2026_computeascde}.

\subsection{HNN as a tri-state guardian (false-positive budgeting and soft landing)}
\label{appL:hnn_tristate}

The HNN guardian is economically and operationally constrained by a hard truth: for stiff workloads, a
\textbf{false positive} (benign behavior flagged as attack) can be as damaging as a real attack because it forces
shutdowns/restarts \citep{candler2026_computeascde}.%
\footnote{Reviewer-proof framing: a security system that ``wins'' by constant shutdowns is a denial-of-service
policy. The correct abstraction is a detector-controller with explicit false-positive budgeting and a soft-landing
mode \citep{talukder2023_zerotrust,NIST800207}.}

We therefore specify a tri-state classifier output:
\begin{equation}
z(t) \in \{\texttt{GREEN},\texttt{YELLOW},\texttt{RED}\},
\end{equation}
with semantics:
\begin{itemize}
  \item \texttt{GREEN}: admit requested action if physical/UQ gates pass.
  \item \texttt{YELLOW}: anomaly suspected but thermally safe $\Rightarrow$ \emph{degrade} to baseline (clamp sprint),
        preserve checkpoint continuity.
  \item \texttt{RED}: attack/poisoning suspected $\Rightarrow$ isolate + safe-mode + incident sequence.
\end{itemize}

\paragraph{Soft-landing control law.}
On \texttt{YELLOW}, impose:
\begin{equation}
\sigma(t)\leftarrow \min\{\sigma(t),\sigma_{\text{safe}}\}, \qquad
u_f(t)\leftarrow \max\{0, u_f(t)-\Delta u\},
\label{eq:soft_landing}
\end{equation}
where $\sigma_{\text{safe}}$ is the conservative operating point (e.g., $\sigma_{\text{safe}}=1$) and $\Delta u$ is a
staged flex reduction step. This avoids ``kill the job'' behavior while still reducing actuation authority, which
is consistent with zero-trust continuous verification and least-privilege actuation \citep{NIST800207}.

\paragraph{False-positive budget as a contractible spec.}
Let $\alpha_{\text{FP}}$ be the tolerated false-positive rate at the facility level for stiff-window operations.
Then the HNN threshold policy must satisfy:
\begin{equation}
\mathbb{P}\!\left[z(t)=\texttt{RED}\mid \text{benign},\ \text{stiff window}\right] \;\le\; \alpha_{\text{FP}}.
\label{eq:fp_budget}
\end{equation}
\footnote{This forces the security story to become economic: if $\alpha_{\text{FP}}$ is too large, the expected
restart/curtailment cost dominates and destroys stiff-window goodput economics \citep{candler2026_computeascde}.}

\subsection{Pricing false positives into switching cost}
\label{appL:fp_to_switching}

Compute-ASCDE treats switching/restart as a dominant penalty for stiff loads \citep{candler2026_computeascde}.
We therefore decompose monthly switching cost into exogenous and security-induced components:
\begin{equation}
C_{\text{switch}}(m) \;=\; C_{\text{grid}}(m) + C_{\text{sec}}(m),
\end{equation}
where $C_{\text{sec}}(m)$ captures HNN-triggered interruptions (including false positives). A minimal executable form is:
\begin{equation}
C_{\text{sec}}(m) := \sum_{j=1}^{N_{\text{sec}}(m)} w_j^{\text{sec}} \cdot \Delta \tau_j,
\label{eq:security_switch_cost}
\end{equation}
with $w_j^{\text{sec}}$ scaling by phase criticality (stiff windows weighted higher).%
\footnote{This explicitly prices the benefit of tri-state logic: \texttt{YELLOW} events should usually not increment
$N_{\text{sec}}(m)$ because they degrade rather than interrupt, thereby reducing $C_{\text{sec}}(m)$ relative to a
binary ``trip or ignore'' detector \citep{candler2026_computeascde}.}

\subsection{Regulatory stack clarification: DeepONet is control, not safety}
\label{appL:reg_stack}

A clean regulatory defense requires an explicit separation:
\begin{itemize}
  \item \textbf{Reactor Protection System (RPS):} the hard-deck safety system. If physical limits are exceeded,
  it trips/scrams. This remains authoritative and non-ML.
  \item \textbf{DeepONet + gating:} a limiting control/coordination layer that operates \emph{below} the hard deck to
  manage coupling with compute. Its failure mode is revert-to-conservative (deny sprints), not safety violation.
\end{itemize}

This separation is consistent with defense-in-depth and strict boundary controls emphasized in nuclear cyber and
industrial security guidance \citep{NRC_RG571,IEC62443,NIST800207}.%
\footnote{Even if a reviewer argues that RG 5.71 is ``cyber'' and not ``safety,'' the structural point stands:
the ML layer is not permitted to be a single point of safety failure. Appendix~F already makes the practical
consequence enforceable: loss of time quality / observability forces conservative denial behavior, not risk-taking.}

\subsection{Optional extension: coolant/siting arbitrage as a cost inequality}
\label{appL:coolant_inequality}

If the manuscript retains an ``exotic coolant'' or ``nanofluid'' angle, it should be expressed as an inequality
rather than aspiration. Let $\Delta C_{\text{water}}$ be the monetized value of water savings / siting enablement
(e.g., water rights, permitting, or avoided curtailment), and let $\Delta C_{\text{nano}}$ be the premium and
risk-adjusted O\&M penalty (sedimentation/clogging risk, filtration, replacement). Then the adoption condition is:
\begin{equation}
\Delta C_{\text{water}} \;\ge\; \Delta C_{\text{nano}}.
\label{eq:nanofluid_ineq}
\end{equation}
\footnote{This forces the same discipline as the Goodput PPA: pay for what creates value, penalize what creates risk.
If you later decide to keep this section, cite exactly one strong coolant review plus one reliability/O\&M source;
otherwise this stays as an optional inequality stub.}

\subsection{Executive ``what changes'' summary (reviewer-proof)}
\label{appL:what_changes_summary}

This appendix introduces three enforceable upgrades:
\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{Uncertainty tax:} admissible sprint capacity is explicitly derated by UQ
        (\cref{eq:sigma_uq_tax}), making model quality a priced lever \citep{candler2026_computeascde}.
  \item \textbf{False-positive budgeting:} the HNN is tri-state with a specified false-positive constraint
        (\cref{eq:fp_budget}), avoiding economics-killing ``secure but unusable'' behavior
        \citep{talukder2023_zerotrust,NIST800207,candler2026_computeascde}.
  \item \textbf{Regulatory stack:} DeepONet is a limiting control layer, not a safety system; its failure mode is
        revert-to-conservative, consistent with defense-in-depth principles \citep{NIST800207,IEC62443,NRC_RG571}.
\end{enumerate}

\newpage

% =====================================================================
% APPENDIX L — OPERATIONAL HARDENING: STOCHASTIC COLLATERAL,
%              MANIFOLD PROJECTIONS, AND OTOC CHAOS METRICS
% =====================================================================

% ---------------------------------------------------------------------
% L.0 (NEW) — Change Control / Contract Stability
% ---------------------------------------------------------------------
\subsection{Model and Policy Change Control: Hash-Locked Contracts and Freeze Windows}
\label{appM:change_control}

The collateral layer (MCA) and the replay-audit layer (M.6) are contractible only if the decision policy is
\emph{stable under audit}. Therefore, any admissibility decision must be bound to immutable identifiers for the
model, feature schema, thresholds, and replay code.

\paragraph{Definition (Decision bundle identifiers).}
Each decision window $t$ emits an identifier tuple:
\begin{equation}
\mathsf{ID}(t)
:=
\langle
h_{\text{model}},\ h_{\text{weights}},\ h_{\text{features}},\ h_{\text{thresholds}},\ h_{\text{replay}}
\rangle,
\end{equation}
where each component is a cryptographic hash of (respectively) the model class, parameter weights, feature schema,
threshold set, and replay script implementation.

\paragraph{Freeze-window rule.}
Let $\mathcal{W}_{\text{sprint}}$ denote the set of active sprint windows. During $\mathcal{W}_{\text{sprint}}$,
\emph{no} updates to $\mathsf{ID}(t)$ are permitted:
\begin{equation}
t\in\mathcal{W}_{\text{sprint}} \ \implies\ \mathsf{ID}(t+\delta)=\mathsf{ID}(t),
\end{equation}
unless an emergency rollback is invoked by the degradation ladder (L.10).

\paragraph{Two-key change control.}
Any policy update outside sprint windows requires a dual authorization signature:
\begin{equation}
\texttt{UPDATE\_APPLY} \iff \texttt{SIG}_{\text{Ops}}=1 \ \land\ \texttt{SIG}_{\text{Safety}}=1,
\end{equation}
with the signed update record stored as part of the audit trail.

\paragraph{Rollback obligation.}
Define a post-deployment verification horizon $\tau_{\text{verify}}$ and a performance envelope
$\mathcal{E}_{\text{perf}}$ (false-positive budget, missed-detection limit, and ramp safety). If observed metrics
violate $\mathcal{E}_{\text{perf}}$ within $\tau_{\text{verify}}$, the system must revert to the last stable policy:
\begin{equation}
\texttt{VIOLATE}(\mathcal{E}_{\text{perf}})\ \Rightarrow\ \texttt{ROLLBACK}(\mathsf{ID}_{\text{stable}}).
\end{equation}

\paragraph{Contractible artifact.}
All gating decisions and premiums are bound to $\mathsf{ID}(t)$ in \texttt{ATTEST\_BUNDLE}, ensuring an auditor can
reconstruct the exact logic and thresholds used at decision time.


\section{Operational Hardening: Stochastic Collateral, Manifold Projections, and OTOC Chaos Metrics}
\label{appM:operational_hardening}

This appendix hardens the manuscript’s \emph{physics-to-finance interface} into contractible primitives.
The main text establishes (i) an oracle-gated admission interface (Sequences A/B/C), and (ii) a reliability-complete
economic layer (Compute-ASCDE) for stiff workloads. Here we make the remaining step explicit:
\emph{oracle and guardian imperfections are not narrative caveats; they are priced state variables.}
We provide three upgrades:
\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{Stochastic collateral:} a dynamic model-collateral account (MCA) whose premium is derived from the oracle’s
        hazard rate and whose liquidation covers switching/restart and reliability externalities.
  \item \textbf{Manifold projection:} a physically-consistent projection operator that prevents the oracle from emitting
        off-manifold (non-conservative) state trajectories, reducing “black-box” risk in the admissibility gate.
  \item \textbf{OTOC-style chaos proxy:} a leading indicator for instability that triggers \texttt{YELLOW} degradation
        \emph{before} thermal margin is consumed (thermal is a lagging indicator).
\end{enumerate}
These upgrades are designed to be directly auditable through the same evidence skeleton used by the Goodput PPA
(attestation bundles + telemetry), and to feed directly into the valuation terms (survival and switching)
in Compute-ASCDE \citep{candler2026_computeascde}.

% ---------------------------------------------------------------------
% L.1
% ---------------------------------------------------------------------
\subsection{Stochastic modeling of model collateral (MCA)}
\label{appM:collateral}

The “high-confidence sprint” is economically meaningful only if the tail risk of oracle failure is both (i) priced
ex ante and (ii) allocated ex post. We therefore define a \emph{Model Collateral Account (MCA)} whose role is to
internalize the incremental hazard of admitting sprints under a probabilistic oracle.\footnote{This is mechanism
design applied to cyber-physical control: if the admitted action raises the probability of a costly tail event, you
either (i) deny it, or (ii) price the marginal hazard into the contract and escrow the proceeds. The point is not
to “blame the model,” but to make the interface enforceable under imperfect inference.}

\begin{definition}[Covered Oracle Failure]
A \emph{Covered Oracle Failure} is an interruption or plant protection actuation (trip, forced derate, or forced
load rejection) that occurs while executing a \emph{previously admitted} sprint action under Sequence A, and that is
attributed (under the incident taxonomy) to oracle/guardian imperfection rather than exogenous grid/plant faults.
\end{definition}

\paragraph{Hazard-rate primitive.}
Let $\{\mathcal{H}_t\}_{t\ge 0}$ be the filtration generated by all admissibility decisions, attestation bundles,
and aligned telemetry streams up to time $t$. Define the instantaneous hazard rate of a covered failure:
\begin{equation}
\lambda(t) \;=\; \lim_{\Delta t \to 0}
\frac{\mathbb{P}(\text{Covered Failure in }[t,t+\Delta t]\mid \text{admitted sprint at }t,\ \mathcal{H}_t)}{\Delta t}.
\label{eq:m_hazard}
\end{equation}
Let $U(t)$ denote a calibrated uncertainty proxy exported by the oracle (e.g., conformal radius, ensemble variance,
or conservative residual bound). We assume:
\begin{assumption}[Monotone hazard proxy]
\label{assump:monotone_hazard_proxy}
There exists a nondecreasing function $\phi(\cdot)$ and $\lambda_{\min}\ge 0$ such that
\begin{equation}
\lambda(t)\;\ge\;\lambda_{\min} + \phi\!\bigl(U(t)\bigr).
\label{eq:m_hazard_proxy}
\end{equation}
\end{assumption}
\footnote{The contractible requirement is monotonicity: higher uncertainty must not weakly \emph{reduce} the priced hazard.
This aligns with the derating logic in Compute-ASCDE \citep{candler2026_computeascde}.}

\paragraph{Collateral premium and solvency constraint.}
Let $C_{\text{trip}}^{(k)}$ be the (monetized) cost of the $k$-th covered failure: restart/switching penalty,
lost goodput, and any reliability/market penalties triggered by the resulting discontinuity (as structured in
Compute-ASCDE’s stiff-load economics) \citep{candler2026_computeascde}. Let $N(T)$ be the failure counting process
over horizon $T$. Define the MCA premium rate $\rho(t)$ charged per unit \emph{excess sprint authority} $(\sigma(t)-1)_+$.
A conservative solvency constraint is:
\begin{equation}
\int_0^T \rho(t)\,(\sigma(t)-1)_+\,dt
\;\ge\;
\mathrm{CVaR}_{\alpha}\!\left(\sum_{k=1}^{N(T)} C_{\text{trip}}^{(k)}\right),
\label{eq:m_cvar_solvency}
\end{equation}
for a chosen tail level $\alpha\in(0,1)$.

\begin{proposition}[Sufficient premium rule]
\label{prop:m_premium_rule}
If $C_{\text{trip}}^{(k)}\le \bar{C}$ almost surely and $N(T)$ is dominated by an inhomogeneous Poisson process with
intensity $\lambda(t)$, then a sufficient condition for \cref{eq:m_cvar_solvency} is
\begin{equation}
\rho(t)\;\ge\;\bar{C}\cdot \lambda(t)\cdot \zeta_{\alpha}
\qquad\text{for all }t\in[0,T],
\label{eq:m_premium_sufficient}
\end{equation}
where $\zeta_{\alpha}\ge 1$ is a conservative tail multiplier chosen to upper-bound $\mathrm{CVaR}_{\alpha}$ relative
to the mean under the adopted counting model.
\end{proposition}

\begin{proof}
Under the stated domination, $\mathbb{E}\!\left[\sum_{k=1}^{N(T)}C_{\text{trip}}^{(k)}\right]\le
\bar{C}\int_0^T \lambda(t)\,dt$. A conservative $\mathrm{CVaR}_{\alpha}$ bound is achieved by multiplying the mean by a
tail factor $\zeta_{\alpha}$. Choosing $\rho(t)$ to satisfy \cref{eq:m_premium_sufficient} yields a sufficient
actuarial rule. \qedhere
\end{proof}

\paragraph{MCA as a computable ledger (balance dynamics).}
To eliminate ambiguity in “who pays when wrong,” define the MCA balance $B_{\mathrm{MCA}}(t)$ as a contract ledger:
\begin{equation}
dB_{\mathrm{MCA}}(t)
=
\rho(t)\,(\sigma(t)-1)_+\,dt
-
\sum_{k} C_{\text{trip}}^{(k)}\,\delta(t-t_k),
\label{eq:m_mca_balance}
\end{equation}
where $\{t_k\}$ are covered-failure times (incident-taxonomy labeled).%
\footnote{This makes liquidation auditable: an external reviewer can reconstruct $B_{\mathrm{MCA}}(t)$ from logged
$\rho(t)$, $\sigma(t)$, and incident tags, without model-weight access.}

\paragraph{Contract semantics (who pays when wrong).}
If a covered failure occurs while executing an admitted sprint, the MCA liquidates according to the cost taxonomy
already present in Compute-ASCDE (switching/restart + reliability externality) \citep{candler2026_computeascde}.
The buyer is purchasing not just energy, but \emph{inference quality}.
If inference quality degrades (higher $U(t)$), sprinting becomes economically self-limiting before safety limits
are threatened.

% ---------------------------------------------------------------------
% L.2 (NEW) — explicit Yellow degrade logic
% ---------------------------------------------------------------------
\subsection{\texttt{YELLOW}-state degradation: ramp-controlled soft landings}
\label{appM:yellow_degradation}

The \texttt{YELLOW} state must specify a \emph{physically safe trajectory} rather than a label. “Shed load” is not
contractible unless the ramp itself is bounded, since aggressive step-down can induce its own transients (POI stress,
steam/valve excursions, or level swell). We therefore define \texttt{YELLOW} as a bounded-rate policy over sprint
authority $\sigma(t)$ and compute power $P_{\mathrm{AI}}(t)$.

\paragraph{Ramp control law.}
For a control step $\delta>0$:
\begin{align}
\sigma(t+\delta) &:= \max\{\sigma_{\mathrm{safe}},\ \sigma(t) - r_{\sigma}\,\delta\}, \\
P_{\mathrm{AI}}(t+\delta) &:= \max\{P_{\mathrm{base}},\ P_{\mathrm{AI}}(t) - r_{P}\,\delta\},
\label{eq:m_yellow_ramp}
\end{align}
with $r_P \le R_{\mathrm{safe}}$ enforcing a POI-safe and BOP-safe ramp envelope.%
\footnote{Design requirement: $(r_\sigma,r_P)$ must satisfy simultaneously (i) POI ramp/flicker bounds, (ii) plant/BOP
actuation-rate limits, and (iii) workload checkpoint cadence so \texttt{YELLOW} is never a step transient. All rate limits
and the chosen envelope are logged in the \texttt{ATTEST\_BUNDLE}.}

\paragraph{Semantic linkage.}
All anomaly gates in this appendix (\cref{eq:m_yellow_trigger,eq:geom_gate}) produce \texttt{YELLOW}=1, which invokes
the \emph{same} ramp profile \cref{eq:m_yellow_ramp}. This makes “degradation” a single auditable primitive.

% ---------------------------------------------------------------------
% L.3
% ---------------------------------------------------------------------
\subsection{Manifold-constrained DeepONet (Mc-DeepONet) via projection}
\label{appM:manifold_constraints}

A standard neural operator can generate off-distribution outputs that violate conservation structure (``physical
hallucination''). This is fatal to contractibility: you cannot defend a gate whose oracle can emit non-physical
states under perturbation. The hardening move is architectural: enforce that the oracle output is projected to a
physically-consistent set before it becomes admissibility evidence.\footnote{We keep the projection abstract so it
covers several implementations: constrained residual minimization, physics-regularized proximal steps, or manifold
filters embedded as post-processing. The only requirement is an auditable projection certificate.}

\begin{definition}[Solution manifold]
Let $\mathcal{D}$ denote the coupled plant operator (e.g., heat + hydraulics + relevant balance-of-plant dynamics)
on a state space $\mathcal{V}$. Define the
\emph{approximate solution manifold} at tolerance $\epsilon_{\mathrm{tol}}$ as
\begin{equation}
\mathcal{M}_{\epsilon_{\mathrm{tol}}}
:=\left\{u\in\mathcal{V}:\ \|\mathcal{D}(u)\|\le \epsilon_{\mathrm{tol}}\right\}.
\label{eq:m_manifold}
\end{equation}
\end{definition}

\paragraph{Projection operator.}
Let $\hat{u}_{\mathrm{raw}}$ be the DeepONet (or operator surrogate) output. Define the projected output:
\begin{equation}
\hat{u}_{\mathrm{safe}}
:=\mathcal{P}_{\mathcal{M}}(\hat{u}_{\mathrm{raw}})
=\arg\min_{u\in\mathcal{V}} \|u-\hat{u}_{\mathrm{raw}}\|^2
\quad\text{s.t.}\quad \|\mathcal{D}(u)\|\le \epsilon_{\mathrm{tol}}.
\label{eq:m_projection}
\end{equation}
We cite the manifold-constraint idea as an architectural hardening direction \citep{deepseek2024_mhc}.%
\footnote{Contractible artifact: store $\|\mathcal{D}(\hat{u}_{\mathrm{safe}})\|$ and solver tolerance/exit status in
\texttt{ATTEST\_BUNDLE}. If projection is infeasible, the conservative fallback is deny sprints / revert to baseload.}

\begin{proposition}[Projection-based physical consistency]
\label{prop:m_projection_consistency}
If \cref{eq:m_projection} is solved to feasibility, then $\hat{u}_{\mathrm{safe}}\in\mathcal{M}_{\epsilon_{\mathrm{tol}}}$.
Consequently, any admissibility decision that uses $\hat{u}_{\mathrm{safe}}$ as evidence can be accompanied by an
explicit physical-consistency certificate $\|\mathcal{D}(\hat{u}_{\mathrm{safe}})\|\le\epsilon_{\mathrm{tol}}$.
\end{proposition}

\begin{proof}
Immediate from the constraint in \cref{eq:m_projection}. \qedhere
\end{proof}

% ---------------------------------------------------------------------
% L.4
% ---------------------------------------------------------------------
\subsection{OTOC-style stability proxy (leading indicator for the \texttt{YELLOW} trigger)}
\label{appM:otoc_stability}

Thermal margin is lagging: by the time $T$ rises, unstable forcing may already be amplifying. We therefore add a
leading instability proxy inspired by OTOC/echo logic (scrambling / sensitivity growth) \citep{abanin2025_otoc2,google2025constructive,candler2025_otoc_echoes}.%
\footnote{We are \emph{not} claiming the reactor is a quantum system operationally. We import the mathematical idea:
echo-based sensitivity diagnostics can expose \emph{hidden correlations} and early onset of divergence. Google’s OTOC(2)
result highlights that multi-echo constructions can remain sensitive even when first-order correlators saturate
(``edge of ergodicity''), motivating a second-order operational proxy.}

\paragraph{Classical sensitivity functional (first-order echo proxy).}
Let $x(t)$ be a vector of control-relevant plant variables and $u(t)$ be the actuation. Consider a small perturbation
$\delta u$ applied to an admitted sprint trajectory. Define a finite-horizon sensitivity growth functional:
\begin{equation}
\Gamma_1(t;\Delta)
:= \log\frac{\|x(t+\Delta;u+\delta u)-x(t+\Delta;u)\|}{\|\delta u\|}.
\label{eq:m_sensitivity_growth}
\end{equation}
Operationally, $\Gamma_1$ is computed from (i) high-rate telemetry replay, (ii) a shadow model / digital twin, or
(iii) a local linearization around the operating point; the computation path is logged in the \texttt{ATTEST\_BUNDLE}.

\paragraph{Second-order (OTOC(2)-analogue) amplification probe.}
To emulate the ``multi-echo'' sensitivity gain of OTOC(2) without requiring time-reversal of plant physics, we add a
second-order finite-difference proxy that detects curvature in the input--response map (often elevated near resonance
bands / bifurcation boundaries):
\begin{equation}
\Gamma_2(t;\Delta)
:= \log\frac{\|x(t+\Delta;u+\delta u)-2x(t+\Delta;u)+x(t+\Delta;u-\delta u)\|}{\|\delta u\|^2}.
\label{eq:m_sensitivity_growth2}
\end{equation}
Interpretation: $\Gamma_2$ behaves like a ``high-gain'' detector for latent nonlinear mode-coupling. In benign regimes,
$\Gamma_2$ remains bounded; near destabilizing manifolds it spikes even when $\Gamma_1$ is only modestly elevated.

\begin{definition}[Operational scrambling thresholds and escalation]
Let $(\Gamma_{1,\max},\Gamma_{2,\max})$ be policy thresholds chosen such that exceedance implies unacceptable
amplification risk within the reaction time of the ramp-controlled degradation profile. Define:
\begin{align}
\texttt{YELLOW} &\iff \Gamma_1(t;\Delta) \ge \Gamma_{1,\max} \ \ \lor\ \ \Gamma_2(t;\Delta) \ge \Gamma_{2,\max},
\label{eq:m_yellow_trigger}\\
\texttt{RED} &\iff \Gamma_2(t;\Delta) \ge \Gamma_{2,\mathrm{crit}} \ \ \text{persistently over } n \text{ windows.}
\label{eq:m_red_trigger}
\end{align}
\end{definition}

\paragraph{Contractible interpretation.}
If \cref{eq:m_yellow_trigger} fires, the interface enters the ramp-controlled degradation profile in
\cref{eq:m_yellow_ramp} (ramp-down, not step-down), preserving continuity where possible.%
\footnote{Contract hook: log $(\Gamma_1,\Gamma_2,\Delta,\delta u)$, the replay path (telemetry/shadow/linearization),
and the applied ramp parameters. This makes the trigger defensible as an evidence-based early-warning mechanism rather
than a discretionary ML heuristic.}

\paragraph{Calibration note (reviewer-proof).}
$(\Gamma_{1,\max},\Gamma_{2,\max},\Gamma_{2,\mathrm{crit}})$ are set to cap false positives on a held-out benign dataset
and then stress-tested under injected oscillatory forcing / resonance-shaped load profiles. This mirrors the same
``replayable evidence'' posture used by the Goodput PPA and the admissibility gate.

% ---------------------------------------------------------------------
% L.4.5
% ---------------------------------------------------------------------
\subsection{Thermodynamic checksum for attested goodput (anti-gaming anchor)}
\label{appM:thermo_checksum}

The Goodput PPA is vulnerable if “goodput” is purely digital. The hardening move is a \emph{physics-of-work}
consistency check: goodput claims must reconcile against measured energy (and optionally heat-rejection proxies)
within calibration tolerance \citep{candler2026_computeascde}.%
\footnote{This does not require exotic calorimetry. It requires coherent attestation and telemetry: signed job claims,
measured electrical energy, and (when available) heat-rejection proxies from plant/BOP telemetry (Appendix F).}

\begin{proposition}[Landauer lower bound (as a non-gameable floor)]
Any irreversible information processing implies heat dissipation bounded below by $k_BT\ln 2$ per bit erased
(Landauer). Therefore, a goodput claim that implies \emph{less} dissipated work than this floor is physically
impossible \citep{landauer1961}.
\end{proposition}

\begin{remark}[Why Landauer is used here]
Landauer is not tight for modern silicon; it is used as an anti-fraud floor and rhetorical anchor.
The enforceable check uses architecture-calibrated work curves (tokens/J, steps/J) plus tolerances.
\end{remark}

\paragraph{Executable consistency inequality.}
Let $E(t)$ be measured electrical energy into compute over interval $t$, and let $G(t)$ be attested goodput. Let
$\underline{\mathcal{F}}_{\mathrm{arch}},\overline{\mathcal{F}}_{\mathrm{arch}}$ be conservative envelopes mapping
energy to expected goodput at the current operating point. Require:
\begin{equation}
G(t) \;\le\; \overline{\mathcal{F}}_{\mathrm{arch}}\!\bigl(E(t)\bigr) + \epsilon_G,
\label{eq:m_goodput_energy_upper}
\end{equation}
and (optionally) a lower-consistency condition for anti-spinning detection:
\begin{equation}
G(t) \;\ge\; \underline{\mathcal{F}}_{\mathrm{arch}}\!\bigl(E(t)\bigr) - \epsilon_G.
\label{eq:m_goodput_energy_lower}
\end{equation}

% ---------------------------------------------------------------------
% Proof obligations (UPDATED: include Yellow ramp + MCA balance)
% ---------------------------------------------------------------------
\subsection{Proof obligations and required log artifacts (reviewer-proof checklist)}
\label{appM:proof_obligations}

To make Appendix M operationally binding (not aspirational), the following obligations must be satisfiable from logs:

\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{Collateral solvency proof:} show $\rho(t)$ and MCA balance $B_{\mathrm{MCA}}(t)$ satisfy a published
        solvency rule (e.g., \cref{eq:m_cvar_solvency} or \cref{eq:m_premium_sufficient}) and reconstruct
        $B_{\mathrm{MCA}}(t)$ via \cref{eq:m_mca_balance}.
  \item \textbf{Projection certificate:} for each admitted action, log $\|\mathcal{D}(\hat{u}_{\mathrm{safe}})\|$
        and $\epsilon_{\mathrm{tol}}$ (or solver exit status) as admissibility evidence.
  \item \textbf{\texttt{YELLOW} ramp replay:} demonstrate the anomaly trigger (OTOC/geometry) and that the resulting
        action follows the bounded-rate profile \cref{eq:m_yellow_ramp} (no unsafe step-down).
  \item \textbf{Goodput reconciliation:} show that goodput claims reconcile against $E(t)$ via
        \cref{eq:m_goodput_energy_upper} (and optionally \cref{eq:m_goodput_energy_lower}) under audit tolerances.
\end{enumerate}

% =====================================================================
% CONTINUATION OF APPENDIX M
% L.5: GEOMETRIC PHASE-SPACE DEFENSE
% L.6: RECURSIVE CAUSAL ATTESTATION
% L.7: BAYESIAN ADAPTIVE PREMIUMS
% =====================================================================

% ---------------------------------------------------------------------
% L.5 (UPGRADED: add Takens justification + optional Fisher metric)
% ---------------------------------------------------------------------
\subsection{Geometric Phase-Space Defense: Topological Detection of Kinetic Attacks}
\label{appM:geometric_defense}

Scalar threshold protection (e.g., $P_{\text{load}} \le P_{\max}$) does not detect adversarial \emph{shape} attacks:
inputs that remain within amplitude limits while exciting sensitive modes (e.g., level swell, xenon-induced oscillation,
or steam/valve limit cycles). We therefore add a \emph{trajectory geometry} gate that detects departures from the
benign operational manifold \emph{before} scalar limits are breached.

\paragraph{Theoretical basis (delay embedding).}
We assume the plant’s effective dynamics concentrate on a low-dimensional attractor in a high-dimensional observation
space. By Takens-style delay embedding, a time-delay map of observed features preserves the attractor topology under
mild generic conditions \citep{takens1981}.%
\footnote{Contractible meaning: the gate depends only on logged measurements $z(t)$ and fixed hyperparameters $(m,\Delta)$,
so it is reconstructible by replay (Appendix F).}

\paragraph{State and embedding.}
Let $x(t)\in\mathbb{R}^n$ denote the control-relevant plant state, and let $\tilde{x}(t)\in\mathbb{R}^d$ denote a
time-delay embedding of measured features:
\begin{equation}
\tilde{x}(t) := \bigl[z(t), z(t-\Delta), \ldots, z(t-(m-1)\Delta)\bigr],
\end{equation}
where $z(t)$ is the measured feature vector (Appendix F) and $(m,\Delta)$ are fixed embedding hyperparameters.%
\footnote{In practice, $\Delta$ can be selected using the first minimum of mutual information \citep{fraser1986}.}

\paragraph{Definition L.3 (Nominal operational manifold).}
Let $\mathcal{M}_{\text{nom}}\subset\mathbb{R}^d$ denote the set of embeddings generated by benign operations under
approved policies:
\begin{equation}
\mathcal{M}_{\text{nom}} := \mathrm{supp}\bigl(\tilde{x}(t)\mid \text{benign policy class}\bigr).
\end{equation}
In implementation, $\mathcal{M}_{\text{nom}}$ is represented by a compact model (diffusion map coordinates,
local PCA charts, or a calibrated autoencoder) trained only on approved operating regimes.

\paragraph{Metric choice (contractible default + optional information metric).}
Define a metric-weighted norm $\|v\|_{W} := \sqrt{v^\top W v}$ with $W\succeq 0$ chosen from physics scaling and/or
empirical covariance. Optionally, set $W$ to a Fisher-information metric induced by the calibrated innovation model:
\begin{equation}
W(\tilde{x})
:= \mathbb{E}\!\left[\nabla_{\tilde{x}}\log p(r\mid \tilde{x})\,\nabla_{\tilde{x}}\log p(r\mid \tilde{x})^\top\right],
\end{equation}
where $r$ is the residual/innovation vector from the state estimator (Appendix F).%
\footnote{This avoids “quantum metric” claims; it is a classical distinguishability metric over residual statistics.}

\paragraph{Local deviation score (contractible).}
Define the \emph{geometric deviation} of the current embedding from the nominal manifold:
\begin{equation}
\delta_g(t) := \min_{y\in\mathcal{M}_{\text{nom}}} \|\tilde{x}(t)-y\|_{W}.
\label{eq:geom_deviation}
\end{equation}

\paragraph{Curvature / turning penalty.}
Define a discrete curvature proxy:
\begin{equation}
\kappa(t) := \frac{\|\tilde{x}(t+\Delta)-2\tilde{x}(t)+\tilde{x}(t-\Delta)\|_{W}}{\Delta^2}.
\label{eq:curvature_proxy}
\end{equation}

\paragraph{Geometric anomaly gate (early warning).}
Declare a \texttt{YELLOW} geometric anomaly if either deviation or curvature exceeds calibrated thresholds:
\begin{equation}
\texttt{YELLOW}_{\text{geom}}(t)
\iff
\left(\delta_g(t)>\epsilon_g\right)\ \ \lor\ \ \left(\kappa(t)>\kappa_{\text{crit}}\right).
\label{eq:geom_gate}
\end{equation}

\paragraph{Control law.}
On \texttt{YELLOW}$_{\text{geom}}$, invoke the ramp-controlled soft landing in \cref{eq:m_yellow_ramp}. All values
$(\delta_g,\kappa,\epsilon_g,\kappa_{\text{crit}},r_\sigma,r_P)$ are logged in the \texttt{ATTEST\_BUNDLE}.

% ---------------------------------------------------------------------
% L.6 (UNCHANGED, but now explicitly tied to Yellow + manifold + geometry)
% ---------------------------------------------------------------------
\subsection{Recursive Causal Attestation: Decision-Level ``Why'' Proofs}
\label{appM:recursive_attestation}

A contractible controller must be \emph{auditable}: for each gating decision, it must produce a replayable chain of
facts showing which constraints were active and why a grant/reject occurred. This appendix does \emph{not} require the
neural network to be transparent; it requires the \emph{decision} to be reproducible from signed evidence.

\paragraph{Definition L.4 (Causal trace record).}
For each decision time $t$, the system emits a signed causal trace record:
\begin{equation}
\mathcal{T}(t) := \langle \mathcal{S}_{\mathrm{in}}(t),\ \mathcal{C}(t),\ \mathcal{R}(t),\ \Pi(t)\rangle,
\end{equation}
where
\begin{itemize}
  \item $\mathcal{S}_{\mathrm{in}}(t)$ is the signed telemetry snapshot and policy state (Appendix F; includes time-quality fields).
  \item $\mathcal{C}(t)$ is the set of constraint evaluations at $t$ (e.g., $\sigma_{\max}(t)$, $\delta_g(t)$,
        $\Gamma(t;\Delta)$, manifold residual certificate $\|\mathcal{D}(\hat{u}_{\mathrm{safe}})\|$, ramp limits).
  \item $\mathcal{R}(t)$ is the rule ID / decision predicate activated.
  \item $\Pi(t)$ is a minimal replay script sufficient for an external auditor to recompute $\mathcal{C}(t)$ from
        $\mathcal{S}_{\mathrm{in}}(t)$ and verify $\mathcal{R}(t)$.
\end{itemize}

\paragraph{Decision predicate (explicit).}
\begin{equation}
D(t)=\texttt{GRANT}
\iff
\Bigl(\sigma_{\mathrm{req}}(t)\le \sigma_{\max}(t)\Bigr)\ \land\
\Bigl(\texttt{YELLOW}(t)=0\Bigr)\ \land\
\Bigl(\texttt{RPS\_margin}(t)=1\Bigr),
\label{eq:decision_predicate}
\end{equation}
where \texttt{YELLOW} aggregates anomaly gates (OTOC/geometry/manifold infeasibility) and
\texttt{RPS\_margin} is the non-ML hard-deck predicate.

\begin{theorem}[Replay auditability]
\label{thm:replay_auditability}
If $\mathcal{S}_{\mathrm{in}}(t)$ is complete and time-aligned per Appendix F, and $\Pi(t)$ specifies deterministic
feature extraction for $\mathcal{C}(t)$, then an external auditor can recompute $\mathcal{C}(t)$ and verify the truth value
of \cref{eq:decision_predicate} without access to internal model weights. Therefore the gating decision is legally and
technically auditable as an \emph{interface contract}.
\end{theorem}

\begin{proof}
By construction, $\Pi(t)$ defines a deterministic mapping from signed inputs $\mathcal{S}_{\mathrm{in}}(t)$ to constraint
evaluations $\mathcal{C}(t)$, and \cref{eq:decision_predicate} is deterministic over $\mathcal{C}(t)$. \qedhere
\end{proof}

% ---------------------------------------------------------------------
% L.7 (UPGRADED: keep your regime-Beta; add hierarchical pooling add-on)
% ---------------------------------------------------------------------
\subsection{Bayesian Adaptive Premiums: Learning Oracle Reliability in the Collateral Layer}
\label{appM:bayesian_premiums}

The collateral premium should adapt to realized oracle performance. Static pricing misaligns incentives. We maintain a Bayesian
belief over the oracle’s \emph{covered-failure probability} and price premiums from a conservative posterior quantile.

\paragraph{Reliability parameterization.}
Let $Y_k\in\{0,1\}$ denote the outcome of sprint window $k$, where $Y_k=1$ indicates a \emph{covered failure}.
Let $p$ denote the covered-failure probability under the current operating regime.

\begin{assumption}[Conditional exchangeability within regime]
\label{assump:exchangeable}
Within a fixed regime class (same plant mode, same sprint band, same telemetry quality class), $\{Y_k\}$ are conditionally
i.i.d.\ Bernoulli$(p)$ given $p$.
\end{assumption}

\paragraph{Posterior update.}
Use a Beta prior $p\sim \mathrm{Beta}(a_0,b_0)$ and update after observing $k$ windows with $s$ failures:
\begin{equation}
p \mid \{Y_i\}_{i=1}^k \sim \mathrm{Beta}(a_0+s,\ b_0+k-s).
\label{eq:beta_posterior}
\end{equation}

\paragraph{Premium rule (quantile pricing).}
Let $C_{\text{trip}}$ be the contractual liquidation amount per covered failure. Define the premium for the next window as:
\begin{equation}
\rho_{k+1} := C_{\text{trip}} \cdot q_{1-\epsilon}\!\left(p \mid a_0+s,\ b_0+k-s\right),
\label{eq:quantile_premium}
\end{equation}
where $q_{1-\epsilon}(\cdot)$ is the $(1-\epsilon)$ posterior quantile and $\epsilon$ is the target insolvency probability.

\paragraph{Regime conditioning and drift.}
Maintain separate posteriors by regime label $r$:
\begin{equation}
p_r \sim \mathrm{Beta}(a_{0,r},b_{0,r}),\qquad
\rho_{k+1} = C_{\text{trip}} \cdot q_{1-\epsilon}\!\left(p_{r(k)} \mid \text{data in regime }r(k)\right).
\end{equation}

\paragraph{Hierarchical pooling (rare-regime hardening).}
To avoid “cold start” uninsurability in sparse regimes, impose partial pooling via a shared hyper-prior:
\begin{align}
p_r &\sim \mathrm{Beta}(\alpha,\beta), \\
\alpha,\beta &\sim \mathrm{Gamma}(\mu,\nu),
\end{align}
so that a new regime inherits a conservative baseline from global performance while still updating as regime-specific
evidence accumulates.%
\footnote{Operationally: default premiums for rare regimes are driven by posterior uncertainty (wide tails), and decline as
regime history grows. This is the finance-grade version of “unknown modes cost more.” See \citet{gelman2013bayesian}.}

\paragraph{Economic interpretation.}
This makes model quality tradable inside the Goodput PPA: improved reliability reduces the premium, increases admissible
utilization, and improves net goodput value under the Compute-ASCDE interface \citep{candler2026_computeascde}

% ---------------------------------------------------------------------
% L.8 (NEW) — Incident Taxonomy + Attribution (Covered vs Not Covered)
% ---------------------------------------------------------------------
\subsection{Incident Taxonomy and Causal Attribution: Deterministic Coverage Classification}
\label{appM:incident_attribution}

A contractible collateral mechanism requires a deterministic classification rule for whether a trip/derate event is
\emph{covered} (oracle/guardian imperfection) versus exogenous (grid/plant/telemetry/operator).

\paragraph{Incident taxonomy.}
Each adverse event $e_k$ is assigned a primary class label:
\begin{equation}
\mathsf{Class}(e_k)\in\{
\texttt{ORACLE},\texttt{GUARDIAN},\texttt{TELEMETRY},\texttt{PLANT},\texttt{GRID},\texttt{OPERATOR}
\},
\end{equation}
with supporting evidence hashes and replay references.

\paragraph{Replay-based attribution test.}
Let $\mathcal{S}_{\mathrm{in}}(t_k)$ denote the signed telemetry snapshot at the decision boundary, and let
$\Pi(t_k)$ denote the replay script (L.6). Define the deterministic replay function:
\begin{equation}
\widehat{D}(t_k) := \Pi(t_k)\bigl(\mathcal{S}_{\mathrm{in}}(t_k)\bigr).
\end{equation}
An attribution is \emph{admissible} only if the replay reproduces the decision and the associated constraint set
$\mathcal{C}(t_k)$.

\paragraph{Coverage predicate (contract definition).}
Event $e_k$ at time $t_k$ is a \emph{Covered Oracle Failure} iff:
\begin{equation}
\texttt{COVER}(e_k)=1
\iff
\Bigl(D(t_k)=\texttt{GRANT}\Bigr)
\land
\Bigl(\texttt{Trip}(e_k)=1\Bigr)
\land
\Bigl(\texttt{RPS\_margin}(t_k)=1\Bigr)
\land
\Bigl(\texttt{TelemOK}(t_k)=1\Bigr)
\land
\Bigl(\widehat{D}(t_k)=D(t_k)\Bigr).
\label{eq:m_cover_predicate}
\end{equation}
If $\texttt{TelemOK}(t_k)=0$ or replay fails due to missing/unaligned inputs, the event is classified as
\texttt{TELEMETRY} (not covered) unless an operator override record proves otherwise.

\paragraph{Counterfactual downgrade check (anti-dispute primitive).}
To separate policy failure from telemetry failure, define a telemetry-degraded replay $\mathcal{S}^{-}$ obtained by
dropping packets, jittering timestamps, and downsampling per Appendix F. If the decision flips only under
$\mathcal{S}^{-}$, classify as \texttt{TELEMETRY}; if it flips under full-quality telemetry, classify as
\texttt{ORACLE}/\texttt{GUARDIAN} depending on the active constraint in $\mathcal{R}(t_k)$.

% ---------------------------------------------------------------------
% L.9 (NEW) — Telemetry Time-Quality Classes + Anti-Alias Gate
% ---------------------------------------------------------------------
\subsection{Telemetry Time-Quality Classes: Anti-Alias Guarantees as a Hard-Deck Predicate}
\label{appM:telemetry_qos}

All geometry/OTOC-style gates are sampling-sensitive. Therefore, admissibility must be conditional on a discrete
telemetry time-quality class $q_t$ that is itself replayable from logs.

\paragraph{Definition (Time-quality class).}
Define $q_t \in \{0,1,2,3\}$ from the tuple:
\begin{equation}
q_t := \mathsf{Q}\Bigl(\Delta_{\text{sync}}(t),\ p_{\text{loss}}(t),\ f_s(t),\ \texttt{AA}(t)\Bigr),
\end{equation}
where $\Delta_{\text{sync}}$ is time alignment error, $p_{\text{loss}}$ packet loss, $f_s$ sampling rate, and
\texttt{AA} is an anti-alias / filtering status bit.

\paragraph{Hard-deck predicate.}
Let $q_{\min}$ be the minimum class required for sprint admissibility. Then:
\begin{equation}
\texttt{TelemOK}(t)=1 \iff q_t \ge q_{\min}.
\end{equation}
If $q_t < q_{\min}$, the system must deny new sprints and/or force \texttt{YELLOW} ramp entry, since the decision is
not legally replayable at the required fidelity.

\paragraph{Anti-alias requirement (engineering form).}
For each gate requiring bandwidth $B_{\text{req}}$, enforce:
\begin{equation}
f_s(t) \ge 2 B_{\text{req}}, \qquad \texttt{AA}(t)=1,
\end{equation}
else the gate is considered invalid and the system de-rates authority (fail-closed semantics).

% ---------------------------------------------------------------------
% L.10 (NEW) — Degradation Ladder (Fail-Closed)
% ---------------------------------------------------------------------
\subsection{Fail-Closed Degradation Ladder: \texttt{GREEN}/\texttt{YELLOW}/\texttt{ORANGE}/\texttt{RED}}
\label{appM:degradation_ladder}

To avoid ambiguity in operational response, we define a discrete ladder of degradation states, each with an explicit,
auditable control action.

\paragraph{State definitions.}
\begin{align}
\texttt{GREEN} &: \text{All hard-decks satisfied; sprints allowed under } \sigma_{\max}(t). \\
\texttt{YELLOW} &: \text{Anomaly detected; invoke ramp-controlled soft landing (L.2).} \\
\texttt{ORANGE} &: \text{Hold state; deny \emph{new} sprints, preserve checkpoint continuity, await confirmation.} \\
\texttt{RED} &: \text{Fail-closed; deny all sprints, revert to baseload, lock incident, require operator re-arm.}
\end{align}

\paragraph{Transition predicates (examples; keep minimal).}
\begin{align}
\texttt{YELLOW} &\Leftarrow \texttt{YELLOW}_{\text{geom}} \lor \texttt{YELLOW}_{\text{otoc}} \lor (\texttt{TelemOK}=0), \\
\texttt{ORANGE} &\Leftarrow \texttt{YELLOW}\ \text{persists for } \tau_{\text{hold}} \ \text{or repeated triggers}, \\
\texttt{RED} &\Leftarrow \text{projection infeasible} \lor \text{ramp envelope violated} \lor \text{manual E-stop}.
\end{align}

\paragraph{Contractible requirement.}
Each state transition must emit a trace record (L.6) and include $\mathsf{ID}(t)$ (L.0) and $q_t$ (L.9).

% ---------------------------------------------------------------------
% L.11 (NEW) — Adversarial Evaluation Protocol + Detection SLA
% ---------------------------------------------------------------------
\subsection{Adversarial Evaluation Protocol: Attack Families, Metrics, and Detection SLAs}
\label{appM:adversarial_eval}

Defenses are contractible only if their performance can be demonstrated under reproducible stress tests.

\paragraph{Attack family registry.}
Define injected test families $\mathcal{A}_j$ including at minimum:
\begin{enumerate}[label=\textbf{\arabic*.}]
  \item \textbf{Iso-amplitude resonance shaping:} bounded $P(t)$ with phase-locked oscillatory forcing.
  \item \textbf{Slow-burn drift:} sub-threshold deviations accumulating toward instability.
  \item \textbf{Goodput spoofing:} valid signatures with inconsistent energy/performance counters.
  \item \textbf{Evasion attempts:} perturbations targeting anomaly gate decision boundaries.
\end{enumerate}

\paragraph{Metrics.}
For each family, report:
\[
\{\text{FNR}_{\text{attack}},\ \text{FPR}_{\text{benign}},\ \text{TTD},\ \text{RampSafety},\ \Delta \sigma_{\max}\}.
\]

\paragraph{Detection SLA (contract form).}
A minimal service level claim:
\begin{equation}
\mathbb{P}\bigl(\text{Detect}(\mathcal{A}_j)\ \text{within}\ \tau_j\bigr)\ \ge\ 1-\delta_j,
\end{equation}
evaluated over a published replay corpus (hash-identified). This is an empirical contract claim, not a theoretical
guarantee, and must be re-validated on policy updates (L.0).

% ---------------------------------------------------------------------
% L.12 (NEW) — Economic Coupling: Premium ↔ Authority (Self-Stabilizing)
% ---------------------------------------------------------------------
\subsection{Economic Coupling: Premium-to-Authority Link as a Self-Stabilizing Safety Envelope}
\label{appM:premium_authority_coupling}

To ensure that rising risk not only raises price but also \emph{mechanically reduces actuation}, couple the collateral
premium to sprint authority.

\paragraph{Definition (Coupled sprint cap).}
Let $\rho(t)$ be the premium rate (L.1/L.7). Define the authority multiplier $\chi(t)\in(0,1]$:
\begin{equation}
\chi(t) := \min\left\{1,\ \left(\frac{\rho_{\mathrm{ref}}}{\rho(t)}\right)^{\gamma}\right\},
\qquad \gamma>0,
\end{equation}
and set the coupled sprint cap:
\begin{equation}
\sigma_{\max}^{\mathrm{coupled}}(t) := 1 + \chi(t)\cdot\bigl(\sigma_{\max}(t)-1\bigr).
\label{eq:m_coupled_sprint_cap}
\end{equation}

\paragraph{Interpretation.}
If oracle reliability degrades, $\rho(t)$ rises via posterior quantile pricing, which reduces $\chi(t)$ and shrinks
the admissible sprint authority \emph{even before} the safety gates fire. This makes the interface economically
self-regulating: risk increases both the marginal price and the feasible control authority.

\paragraph{Contractible artifact.}
Log $\rho(t)$, $\chi(t)$, and $\sigma_{\max}^{\mathrm{coupled}}(t)$ in the \texttt{ATTEST\_BUNDLE} for replay.


\end{document}